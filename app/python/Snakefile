import os, sys
sys.path.insert(0, os.path.join(os.getcwd(), "python"))
import variables
import create_SQL_tables_snakemake as cst
import download_resources_snakemake as drs
import tools

import socket
hostname = socket.gethostname()

DOWNLOADS_DIR = variables.DOWNLOADS_DIR_SNAKEMAKE
TABLES_DIR = variables.TABLES_DIR_SNAKEMAKE
PYTHON_DIR = variables.PYTHON_DIR
TABLES_DICT = variables.TABLES_DICT_SNAKEMAKE
NUMBER_OF_PROCESSES = variables.NUMBER_OF_PROCESSES
if NUMBER_OF_PROCESSES > 10:
    NUMBER_OF_PROCESSES_sorting = 10
else:
    NUMBER_OF_PROCESSES_sorting = NUMBER_OF_PROCESSES
verbose = variables.VERBOSE
TABLES_DICT_SNAKEMAKE = variables.TABLES_DICT_SNAKEMAKE

log_snakemake = os.path.join(variables.LOG_DIRECTORY, "log_snakemake.log")

# ToDo
# - check global_enrichment_lineage /hierarchy --> that lineage still exists also for terms that were obsolete
# - profile code --> maybe change ast.literal_eval, and or flat file style from "{...}" to simple ";" as delimiter
# - fix bug: after running pipeline DF should be updated and also transferred to where pytest runs

### Parameters
max_len_description = 250
min_count = 1 # Function_2_Proteins_table: minimum number of Proteins per TaxID for a each functional_association

### weekly downloads # Sunday ~ 14h done --> start cronjob at 20h to be on the safe side
URL_protein_2_function_PMID = r"http://download.jensenlab.org/aGOtool/documents_protein2function.tsv.gz"
URL_Function_2_Description_PMID = r"http://download.jensenlab.org/aGOtool/documents_function2description.tsv.gz"
Functions_table_PMID_all = os.path.join(DOWNLOADS_DIR, "Functions_table_PMID_all.txt.gz")
Functions_table_PMID = os.path.join(TABLES_DIR, "Functions_table_PMID.txt")
Protein_2_Function_table_PMID = os.path.join(DOWNLOADS_DIR, "Protein_2_Function_table_PMID.txt")

### static files from STRING v11
Entity_types_table_STRING = os.path.join(TABLES_DIR, "Entity_types_table_STRING.txt")
Functions_table_STRING_all_but_PMID = os.path.join(TABLES_DIR, "Functions_table_STRING_all_but_PMID.txt")
Protein_2_Function_table_STRING_all_but_PMID = os.path.join(TABLES_DIR, "Protein_2_Function_table_STRING_all_but_PMID.txt")
# Taxid_2_Proteins_table_STRING = os.path.join(TABLES_DIR, "Taxid_2_Proteins_table_STRING.txt")
Taxid_2_Proteins_table_STRING = TABLES_DICT_SNAKEMAKE["Taxid_2_Proteins_table_STRING"]
KEGG_Taxid_2_acronym_table = TABLES_DICT_SNAKEMAKE["kegg_taxid_2_acronym_table"]
Protein_shorthands = os.path.join(DOWNLOADS_DIR, "protein.shorthands.v11.txt")
GO_basic_obo = os.path.join(DOWNLOADS_DIR, "go-basic.obo")
UPK_obo = os.path.join(DOWNLOADS_DIR, "keywords-all.obo")
RCTM_hierarchy = os.path.join(DOWNLOADS_DIR, "RCTM_hierarchy.tsv")
interpro_parent_2_child_tree = os.path.join(DOWNLOADS_DIR, "interpro_parent_2_child_tree.txt")
fn_tree_STRING_clusters = os.path.join(DOWNLOADS_DIR, "clusters.tree.v11.0.txt.gz")


### static files frozen on 2021 March 29
# Protein_2_Function_table_WikiPathways_STS = os.path.join(TABLES_DIR,"Protein_2_Function_table_WikiPathways_STS.txt") --> integrated into Protein_2_Function_table_STRING_all_but_PMID.txt
# Functions_table_WikiPathways = os.path.join(TABLES_DIR,"Functions_table_WikiPathways.txt") --> integrated into Functions_table_STRING_all_but_PMID.txt

### STRING_clusters
Protein_2_Function_table_STRING_clusters = os.path.join(TABLES_DIR, "Protein_2_Function_table_STRING_clusters.txt")
Functions_table_STRING_clusters = os.path.join(TABLES_DIR, "Functions_table_STRING_clusters.txt")
Lineage_table_STRING_hr = os.path.join(TABLES_DIR, "Lineage_table_STRING_hr.txt")
Lineage_table_STRING_no_translation = os.path.join(TABLES_DIR, "Lineage_table_STRING_no_translation.txt")

### intermediate temp files
Functions_table_STRING_all = os.path.join(TABLES_DIR, "Functions_table_STRING_all.txt")
Functions_table_STRING_removed = os.path.join(TABLES_DIR, "Functions_table_STRING_removed.txt")
Function_2_ENSP_table_STRING_all = os.path.join(TABLES_DIR, "Function_2_ENSP_table_STRING_all.txt")
Function_2_ENSP_table_STRING_removed = os.path.join(TABLES_DIR, "Function_2_ENSP_table_STRING_removed.txt")
Protein_2_Function_table_STRING_all = os.path.join(TABLES_DIR, "Protein_2_Function_table_STRING_all.txt")
Protein_2_Function_table_STRING_removed = os.path.join(TABLES_DIR, "Protein_2_Function_table_STRING_removed.txt")

# AFC_KS_DIR = directory(os.path.join(TABLES_DIR, "global_enrichment_data/"))
# global_enrichment_data_DIR = TABLES_DICT_SNAKEMAKE["global_enrichment_data_DIR"]
global_enrichment_data_current_tar_gz = TABLES_DICT_SNAKEMAKE["global_enrichment_data_current_tar_gz"]
populate_classification_schema_current_sql_gz = TABLES_DICT_SNAKEMAKE["populate_classification_schema_current_sql_gz"]

Function_2_ENSP_table_STRING_reduced = os.path.join(TABLES_DIR, "Function_2_ENSP_table_STRING.txt")
Protein_2_Function_table_STRING_reduced = os.path.join(TABLES_DIR, "Protein_2_Function_table_STRING.txt")

### final files needed for app, STRING final, STS_FIN
# Taxid_2_Proteins_table_STRING --> defined above, since static file
Functions_table_STRING_reduced = TABLES_DICT_SNAKEMAKE["Functions_table_STRING"]
Lineage_table_STRING = TABLES_DICT_SNAKEMAKE["Lineage_table_STRING"]
Protein_2_FunctionEnum_table_STRING = TABLES_DICT_SNAKEMAKE["Protein_2_FunctionEnum_table_STRING"]
Taxid_2_FunctionCountArray_table_STRING = TABLES_DICT_SNAKEMAKE["Taxid_2_FunctionCountArray_table_STRING"]



### pickled results
# taxid_2_proteome_count_dict = TABLES_DICT_SNAKEMAKE["taxid_2_proteome_count_dict"]
# kegg_taxid_2_acronym_dict = TABLES_DICT_SNAKEMAKE["kegg_taxid_2_acronym_dict"]
# year_arr = TABLES_DICT_SNAKEMAKE["year_arr"]
# hierlevel_arr = TABLES_DICT_SNAKEMAKE["hierlevel_arr"]
# entitytype_arr = TABLES_DICT_SNAKEMAKE["entitytype_arr"]
# functionalterm_arr = TABLES_DICT_SNAKEMAKE["functionalterm_arr"]
# indices_arr = TABLES_DICT_SNAKEMAKE["indices_arr"]
# description_arr = TABLES_DICT_SNAKEMAKE["description_arr"]
# category_arr = TABLES_DICT_SNAKEMAKE["category_arr"]
# lineage_dict_enum = TABLES_DICT_SNAKEMAKE["lineage_dict_enum"]
# blacklisted_terms_bool_arr = TABLES_DICT_SNAKEMAKE["blacklisted_terms_bool_arr"]
# ENSP_2_functionEnumArray_dict = TABLES_DICT_SNAKEMAKE["ENSP_2_functionEnumArray_dict"]
# taxid_2_tuple_funcEnum_index_2_associations_counts = TABLES_DICT_SNAKEMAKE["taxid_2_tuple_funcEnum_index_2_associations_counts"]
# etype_2_minmax_funcEnum = TABLES_DICT_SNAKEMAKE["etype_2_minmax_funcEnum"]
# etype_cond_dict = TABLES_DICT_SNAKEMAKE["etype_cond_dict"]
# cond_etypes_with_ontology = TABLES_DICT_SNAKEMAKE["cond_etypes_with_ontology"]
# cond_etypes_rem_foreground_ids = TABLES_DICT_SNAKEMAKE["cond_etypes_rem_foreground_ids"]

LOG_DF_FILE_DIMENSIONS = variables.LOG_DF_FILE_DIMENSIONS
LOG_DF_FILE_DIMENSIONS_GLOBAL_ENRICHMENT = variables.LOG_DF_FILE_DIMENSIONS_GLOBAL_ENRICHMENT


rule download_Protein_2_Function_PMID:
    output:
        Protein_2_Function_table_PMID_STS_gz = Protein_2_Function_table_PMID + ".gz",
        Protein_2_Function_table_PMID = Protein_2_Function_table_PMID
    params:
        URL_protein_2_function_PMID = URL_protein_2_function_PMID,
        verbose = verbose
    log: log_snakemake
    run:
        drs.download_requests(params.URL_protein_2_function_PMID, output.Protein_2_Function_table_PMID_STS_gz, params.verbose)
        tools.gunzip_file(output.Protein_2_Function_table_PMID_STS_gz, output.Protein_2_Function_table_PMID)

rule download_Functions_2_Descriptions_PMID:
    output:
        Functions_table_PMID_all = Functions_table_PMID_all
    params:
        URL_Function_2_Description_PMID = URL_Function_2_Description_PMID,
        verbose = verbose
    log: log_snakemake
    run:
        drs.download_requests(params.URL_Function_2_Description_PMID, output.Functions_table_PMID_all, params.verbose)

rule r_Functions_table_PMID_cleanup:
    input:
        Functions_table_PMID_all = Functions_table_PMID_all
    params:
        max_len_description = max_len_description
    output:
        Functions_table_PMID = Functions_table_PMID
    log: log_snakemake
    run:
        cst.Functions_table_PMID_cleanup(input.Functions_table_PMID_all, params.max_len_description, output.Functions_table_PMID)

rule r_Functions_table_STRING_all:
    input:
        Functions_table_STRING_all_but_PMID = Functions_table_STRING_all_but_PMID,
        Functions_table_PMID = Functions_table_PMID
    output:
        Functions_table_STRING_all = Functions_table_STRING_all
    threads: NUMBER_OF_PROCESSES_sorting
    log: log_snakemake
    run:
        cst.concatenate_Functions_tables(input, output.Functions_table_STRING_all, threads)

rule r_Protein_2_Function_table_STRING_all:
    input:
        Taxid_2_Proteins_table_STRING = Taxid_2_Proteins_table_STRING,
        fn_list_str = [Protein_2_Function_table_STRING_all_but_PMID,
                       Protein_2_Function_table_PMID]
    output:
        Protein_2_Function_table_STRING_all = Protein_2_Function_table_STRING_all
    threads: NUMBER_OF_PROCESSES_sorting
    log: log_snakemake
    run:
        cst.Protein_2_Function_table_STRING(input.fn_list_str, input.Taxid_2_Proteins_table_STRING, output.Protein_2_Function_table_STRING_all, threads)

rule r_Function_2_ENSP_table:
    input:
        Protein_2_Function_table_STRING_all = Protein_2_Function_table_STRING_all,
        Taxid_2_Proteins_table_STRING = Taxid_2_Proteins_table_STRING,
        Functions_table_STRING_all = Functions_table_STRING_all,
    output:
        Function_2_ENSP_table_STRING_all = Function_2_ENSP_table_STRING_all,
        Function_2_ENSP_table_STRING_reduced = Function_2_ENSP_table_STRING_reduced,
        Function_2_ENSP_table_STRING_removed = Function_2_ENSP_table_STRING_removed,
    params:
        min_count = min_count,
        verbose = verbose
    log: log_snakemake
    run:
        cst.Function_2_ENSP_table(input.Protein_2_Function_table_STRING_all, input.Taxid_2_Proteins_table_STRING, input.Functions_table_STRING_all, output.Function_2_ENSP_table_STRING_all, output.Function_2_ENSP_table_STRING_reduced, output.Function_2_ENSP_table_STRING_removed, min_count=params.min_count, verbose=params.verbose)

rule r_Functions_table_STRING: # reduce to relevant part
    input:
        Functions_table_STRING_all = Functions_table_STRING_all,
        Function_2_ENSP_table_STRING_reduced = Function_2_ENSP_table_STRING_reduced
    output:
        Functions_table_STRING_removed = Functions_table_STRING_removed,
        Functions_table_STRING_reduced = Functions_table_STRING_reduced
    log: log_snakemake
    run:
        cst.Functions_table_STRING_reduced(input.Functions_table_STRING_all, input.Function_2_ENSP_table_STRING_reduced, output.Functions_table_STRING_removed, output.Functions_table_STRING_reduced)

rule r_Protein_2_Function_table_reduced:
    input:
        Protein_2_Function_table_STRING_all = Protein_2_Function_table_STRING_all,
        Function_2_ENSP_table_STRING_removed = Function_2_ENSP_table_STRING_removed,
        Functions_table_STRING_reduced = Functions_table_STRING_reduced
    output:
        Protein_2_Function_table_STRING_reduced = Protein_2_Function_table_STRING_reduced,
        Protein_2_Function_table_STRING_removed = Protein_2_Function_table_STRING_removed
    log: log_snakemake
    run:
        cst.reduce_Protein_2_Function_table(input.Protein_2_Function_table_STRING_all, input.Function_2_ENSP_table_STRING_removed, input.Functions_table_STRING_reduced, output.Protein_2_Function_table_STRING_reduced, output.Protein_2_Function_table_STRING_removed)

rule r_Protein_2_FunctionEnum_table_STRING:
    input:
        Protein_2_Function_table_STRING_reduced = Protein_2_Function_table_STRING_reduced,
        Functions_table_STRING_reduced = Functions_table_STRING_reduced
    output:
        Protein_2_FunctionEnum_table_STRING = Protein_2_FunctionEnum_table_STRING
    threads: NUMBER_OF_PROCESSES_sorting
    log: log_snakemake
    run:
        cst.Protein_2_FunctionEnum_table_STRING(input.Functions_table_STRING_reduced, input.Protein_2_Function_table_STRING_reduced, output.Protein_2_FunctionEnum_table_STRING, threads)

rule r_Taxid_2_FunctionCountArray_table_STRING:
    input:
        Protein_2_FunctionEnum_table_STRING = Protein_2_FunctionEnum_table_STRING,
        Functions_table_STRING_reduced = Functions_table_STRING_reduced,
        Taxid_2_Proteins_table_STRING = Taxid_2_Proteins_table_STRING
    output:
        Taxid_2_FunctionCountArray_table_STRING = Taxid_2_FunctionCountArray_table_STRING
    threads: NUMBER_OF_PROCESSES_sorting
    params:
        verbose = verbose
    log: log_snakemake
    run:
        cst.Taxid_2_FunctionCountArray_table_STRING(input.Protein_2_FunctionEnum_table_STRING, input.Functions_table_STRING_reduced, input.Taxid_2_Proteins_table_STRING, output.Taxid_2_FunctionCountArray_table_STRING, threads)

rule r_Lineage_table_STRING:
    input:
        GO_basic_obo = GO_basic_obo,
        UPK_obo = UPK_obo,
        RCTM_hierarchy = RCTM_hierarchy,
        interpro_parent_2_child_tree = interpro_parent_2_child_tree,
        Functions_table_STRING_reduced = Functions_table_STRING_reduced,
        fn_tree_STRING_clusters = fn_tree_STRING_clusters
    output:
        Lineage_table_STRING = Lineage_table_STRING,
        Lineage_table_STRING_hr = Lineage_table_STRING_hr,
        Lineage_table_STRING_no_translation = Lineage_table_STRING_no_translation
    log: log_snakemake
    run:
        cst.Lineage_table_STRING_v2_STRING_clusters(input.GO_basic_obo, input.UPK_obo, input.RCTM_hierarchy, input.interpro_parent_2_child_tree, input.Functions_table_STRING_reduced, input.fn_tree_STRING_clusters, output.Lineage_table_STRING, output.Lineage_table_STRING_hr, output.Lineage_table_STRING_no_translation)

# rule r_pickle_final_results:
#     input:
#         Lineage_table_STRING = Lineage_table_STRING,
#         Taxid_2_FunctionCountArray_table_STRING = Taxid_2_FunctionCountArray_table_STRING
#     output:
#         taxid_2_proteome_count_dict = taxid_2_proteome_count_dict,
#         kegg_taxid_2_acronym_dict = kegg_taxid_2_acronym_dict,
#         year_arr = year_arr,
#         hierlevel_arr = hierlevel_arr,
#         entitytype_arr = entitytype_arr,
#         functionalterm_arr = functionalterm_arr,
#         indices_arr = indices_arr,
#         description_arr = description_arr,
#         category_arr = category_arr,
#         lineage_dict_enum = lineage_dict_enum,
#         blacklisted_terms_bool_arr = blacklisted_terms_bool_arr,
#         ENSP_2_functionEnumArray_dict = ENSP_2_functionEnumArray_dict,
#         taxid_2_tuple_funcEnum_index_2_associations_counts = taxid_2_tuple_funcEnum_index_2_associations_counts,
#         etype_2_minmax_funcEnum = etype_2_minmax_funcEnum,
#         etype_cond_dict = etype_cond_dict,
#     log: log_snakemake
#     run:
#         cst.pickle_PMID_autoupdates(input.Lineage_table_STRING, input.Taxid_2_FunctionCountArray_table_STRING, output)

rule r_AFC_KS_enrichment_terms_flat_files:
    input:
        Functions_table_STRING_reduced = Functions_table_STRING_reduced,
        Protein_shorthands = Protein_shorthands,
        KEGG_Taxid_2_acronym_table = KEGG_Taxid_2_acronym_table,
        Function_2_ENSP_table_STRING_reduced = Function_2_ENSP_table_STRING_reduced,
        GO_basic_obo = GO_basic_obo,
        UPK_obo = UPK_obo,
        RCTM_hierarchy = RCTM_hierarchy,
        interpro_parent_2_child_tree = interpro_parent_2_child_tree,
        fn_tree_STRING_clusters = fn_tree_STRING_clusters
    output:
        global_enrichment_data_current_tar_gz = global_enrichment_data_current_tar_gz,
        populate_classification_schema_current_sql_gz = populate_classification_schema_current_sql_gz
    log: log_snakemake
    run:
        cst.AFC_KS_enrichment_terms_flat_files(input.Functions_table_STRING_reduced, input.Protein_shorthands, input.KEGG_Taxid_2_acronym_table, input.Function_2_ENSP_table_STRING_reduced,input.GO_basic_obo, input.UPK_obo, input.RCTM_hierarchy, input.interpro_parent_2_child_tree, input.fn_tree_STRING_clusters, output.global_enrichment_data_current_tar_gz, output.populate_classification_schema_current_sql_gz)

rule r_add_2_DF_file_dimensions_log:
    input:
        LOG_DF_FILE_DIMENSIONS = LOG_DF_FILE_DIMENSIONS,
        LOG_DF_FILE_DIMENSIONS_GLOBAL_ENRICHMENT = LOG_DF_FILE_DIMENSIONS_GLOBAL_ENRICHMENT,
        # taxid_2_proteome_count_dict = taxid_2_proteome_count_dict,
        global_enrichment_data_current_tar_gz = global_enrichment_data_current_tar_gz,
        populate_classification_schema_current_sql_gz = populate_classification_schema_current_sql_gz
    log: log_snakemake
    run:
        cst.add_2_DF_file_dimensions_log(input.LOG_DF_FILE_DIMENSIONS, input.LOG_DF_FILE_DIMENSIONS_GLOBAL_ENRICHMENT, input.global_enrichment_data_current_tar_gz, input.populate_classification_schema_current_sql_gz)
