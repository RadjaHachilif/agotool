{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/dblyon/modules/cpr/agotool'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/dblyon/modules/cpr/agotool/app/python\n"
     ]
    }
   ],
   "source": [
    "cd app/python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, socket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('3.8.2 | packaged by conda-forge | (default, Apr 24 2020, 07:56:27) \\n[Clang 9.0.1 ]',\n",
       " '/Users/dblyon/anaconda3/envs/agotool2/bin/python')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.version, sys.executable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import query, variables, userinput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext Cython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################################################\n",
      "initializing PQO\n",
      "getting taxid_2_proteome_count\n",
      "getting taxid_2_proteins_dict\n",
      "getting NCBI_taxonomy and TaxidSpecies_2_TaxidProteome_dict\n",
      "getting lookup arrays\n",
      "getting cond arrays\n",
      "getting lineage dict\n",
      "getting blacklisted terms\n",
      "getting taxid_2_tuple_funcEnum_index_2_associations_counts\n",
      "getting preloaded objects per analysis\n",
      "finished with PQO init\n",
      "go go GO and fly like the wind\n",
      "################################################################################\n"
     ]
    }
   ],
   "source": [
    "import query, variables\n",
    "from importlib import reload\n",
    "reload(query)\n",
    "reload(variables)\n",
    "variables.DB_DOCKER = False\n",
    "variables.DOCKER = False\n",
    "# taxid_2_funcEnum_index_2_associations --> taxid_2_tuple_funcEnum_index_2_associations_counts\n",
    "low_memory = True\n",
    "### preload\n",
    "pqo = query.PersistentQueryObject_STRING(low_memory)\n",
    "static_preloaded_objects = pqo.get_static_preloaded_objects(low_memory)\n",
    "### needed for scipy comparison, but otherwise deprecated\n",
    "# ENSP_2_tuple_funcEnum_score_dict = query.get_proteinAN_2_tuple_funcEnum_score_dict(read_from_flat_files=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_arr, hierlevel_arr, entitytype_arr, functionalterm_arr, indices_arr, description_arr, category_arr, etype_2_minmax_funcEnum, function_enumeration_len, etype_cond_dict, etype_2_num_functions_dict, taxid_2_proteome_count, taxid_2_tuple_funcEnum_index_2_associations_counts, lineage_dict_enum, blacklisted_terms_bool_arr, cond_etypes_with_ontology, cond_etypes_rem_foreground_ids, kegg_taxid_2_acronym_dict, goslimtype_2_cond_dict = static_preloaded_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # DEBUG no background_counts for Ecoli\n",
    "# taxid = 592\n",
    "# funcEnum_index_2_associations = taxid_2_tuple_funcEnum_index_2_associations_counts[taxid]\n",
    "# # funcEnum_index_positions_arr, counts_arr = funcEnum_index_2_associations\n",
    "# # create_funcEnum_count_background_v3(funcEnum_count_background, funcEnum_index_positions_arr, counts_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taxid = 511145 # 562\n",
    "# taxid = 562\n",
    "# taxid = 9606\n",
    "# taxid = 83334\n",
    "# taxid in taxid_2_tuple_funcEnum_index_2_associations_counts.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###############################################################################################\n",
    "# ###############################################################################################\n",
    "# ### example of CSR and CSC row and column slicing. DON'T DELETE\n",
    "# from scipy.sparse import random\n",
    "# m = random(5, 5, format='csr', density=0.25)\n",
    "# m.data[:] = np.arange(1, m.data.shape[0]+1)\n",
    "# csr = m.copy()\n",
    "# print(\"### CSR matrix###\")\n",
    "# print(\"the data as an array\")\n",
    "# print(m.toarray())\n",
    "# print()\n",
    "# print(\"values only\") # in row major order !!\n",
    "# print(m.data)\n",
    "# print()\n",
    "# print(\"indices\")\n",
    "# print(m.indices) # index positions within each row that contains values\n",
    "# print()\n",
    "# print(\"indptr\")\n",
    "# print(m.indptr) # index positions of row start\n",
    "# print()\n",
    "# print(\"get row index and values (only if not empty)\")\n",
    "# for i in range(len(m.indptr[:-1])): # get row values\n",
    "#     index_row_start = m.indptr[i]\n",
    "#     index_row_stop = m.indptr[i+1]\n",
    "#     if index_row_start == index_row_stop:\n",
    "#         continue\n",
    "#     print(i, m.data[index_row_start:index_row_stop])\n",
    "# print()\n",
    "\n",
    "# print(\"### now CSC ###\")\n",
    "# m = m.tocsc()\n",
    "# csc = m.copy()\n",
    "# print(\"the data as an array\")\n",
    "# print(m.toarray())\n",
    "# print()\n",
    "# print(\"values only\") # now changed in column major order !!!\n",
    "# print(m.data)\n",
    "# print()\n",
    "# print(\"indices\")\n",
    "# print(m.indices) # index positions within each column that contains values\n",
    "# print()\n",
    "# print(\"indptr\")\n",
    "# print(m.indptr) # index positions of column start and stop\n",
    "# print()\n",
    "# print(\"get column values\")\n",
    "# for i in range(len(m.indptr[:-1])): # get column values\n",
    "#     index_row_start = m.indptr[i]\n",
    "#     index_row_stop = m.indptr[i+1]\n",
    "#     print(m.data[index_row_start:index_row_stop])\n",
    "    \n",
    "# print(\"get column values and column indices (only if not empty)\") # column indices is correct since column data is returned and indexed\n",
    "# for i in range(len(m.indptr[:-1])): # get column values\n",
    "#     index_row_start = m.indptr[i]\n",
    "#     index_row_stop = m.indptr[i+1]\n",
    "#     if index_row_start == index_row_stop:\n",
    "#         continue\n",
    "#     print(i, m.data[index_row_start:index_row_stop])\n",
    "    \n",
    "    \n",
    "# print(\"-\"*50)    \n",
    "# print(\"for each row that is not empty, get row index and column indices (not values)\")\n",
    "# for rowIndex in range(len(csr.indptr[:-1])): # get row values\n",
    "#     index_row_start = csr.indptr[rowIndex]\n",
    "#     index_row_stop = csr.indptr[rowIndex+1]\n",
    "#     if index_row_start == index_row_stop:\n",
    "#         continue\n",
    "#     print(rowIndex, csr[rowIndex].indices)\n",
    "# print()\n",
    "\n",
    "# print(\"-\"*50)    \n",
    "# print(\"for each column that is not empty, get column index (funcEnum), values of column, and row indices within column (translate to ENSPs)\")\n",
    "# # use row_indices_per_column for tranlation from bg_val (score) to bg_rank\n",
    "# # row_indices_per_column = csc.indices[index_row_start:index_row_stop]\n",
    "# for colIndex in range(len(csc.indptr[:-1])): # get column values\n",
    "#     index_row_start = csc.indptr[colIndex]\n",
    "#     index_row_stop = csc.indptr[colIndex+1]\n",
    "#     if index_row_start == index_row_stop:\n",
    "#         continue\n",
    "#     print(colIndex, csc.data[index_row_start:index_row_stop], csc.indices[index_row_start:index_row_stop])\n",
    "#     print(csc[:, colIndex].todense())\n",
    "#     print()\n",
    "# print()\n",
    "\n",
    "# # rowIndex = 1\n",
    "# # csr[rowIndex].data, csr[rowIndex].indices, csr[rowIndex].indptr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "%%cython -f --compile-args=-DCYTHON_TRACE=1\n",
    "\n",
    "import Cython\n",
    "######################################\n",
    "### profiling # Set compiler directives (cf. http://docs.cython.org/src/reference/compilation.html)\n",
    "import line_profiler\n",
    "directive_defaults = Cython.Compiler.Options.get_directive_defaults() ### from Cython.Compiler.Options import directive_defaults # deprecated\n",
    "directive_defaults['linetrace'] = True\n",
    "directive_defaults['binding'] = True\n",
    "######################################\n",
    "from functools import reduce\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from cython cimport boundscheck, wraparound, cdivision, nonecheck\n",
    "cimport cython\n",
    "cimport numpy as np\n",
    "ctypedef np.uint8_t uint8\n",
    "from collections import defaultdict\n",
    "from fisher import pvalue\n",
    "from scipy import stats\n",
    "import variables, query\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "def run_enrichment_cy(ncbi, ui, preloaded_objects_per_analysis, static_preloaded_objects, low_memory=False, debug=False): #, KS_method=\"sparse_scipy\", ENSP_2_tuple_funcEnum_score_dict=None, KS_etypes_FG_IDs=True):\n",
    "    if not low_memory:\n",
    "        ENSP_2_functionEnumArray_dict, year_arr, hierlevel_arr, entitytype_arr, functionalterm_arr, indices_arr, description_arr, category_arr, etype_2_minmax_funcEnum, function_enumeration_len, etype_cond_dict, etype_2_num_functions_dict, taxid_2_proteome_count, taxid_2_tuple_funcEnum_index_2_associations_counts, lineage_dict_enum, blacklisted_terms_bool_arr, cond_etypes_with_ontology, cond_etypes_rem_foreground_ids, kegg_taxid_2_acronym_dict, goslimtype_2_cond_dict = static_preloaded_objects\n",
    "    else:  # missing: ENSP_2_functionEnumArray_dict\n",
    "        year_arr, hierlevel_arr, entitytype_arr, functionalterm_arr, indices_arr, description_arr, category_arr, etype_2_minmax_funcEnum, function_enumeration_len, etype_cond_dict, etype_2_num_functions_dict, taxid_2_proteome_count, taxid_2_tuple_funcEnum_index_2_associations_counts, lineage_dict_enum, blacklisted_terms_bool_arr, cond_etypes_with_ontology, cond_etypes_rem_foreground_ids, kegg_taxid_2_acronym_dict, goslimtype_2_cond_dict = static_preloaded_objects\n",
    "    foreground_ids_arr_of_string, background_ids_arr_of_string, funcEnum_count_foreground, funcEnum_count_background, p_values, p_values_corrected, cond_multitest, blacklisted_terms_bool_arr_temp, cond_terms_reduced_with_ontology, cond_filter, cond_PMIDs, effectSizes, over_under_int_arr, over_under_arr_of_string = preloaded_objects_per_analysis\n",
    "    em = ui.enrichment_method\n",
    "    foreground_n = ui.get_foreground_n()\n",
    "    args_dict = ui.args_dict\n",
    "    simplified_output = args_dict[\"simplified_output\"]\n",
    "    background_n = ui.get_background_n()\n",
    "    protein_ans_fg = ui.get_foreground_an_set()\n",
    "    taxid = args_dict[\"taxid\"]\n",
    "    filter_foreground_count_one = args_dict[\"filter_foreground_count_one\"]\n",
    "    p_value_cutoff = args_dict[\"p_value_cutoff\"]\n",
    "    cols_2_return_sort_order = variables.cols_2_return_sort_order[:]\n",
    "\n",
    "    if ui.enrichment_method in {\"abundance_correction\", \"compare_samples\"}: # , \"compare_groups\"\n",
    "        protein_ans_bg = ui.get_background_an_set()\n",
    "    if low_memory:\n",
    "        ENSP_2_functionEnumArray_dict = query.get_functionEnumArray_from_proteins(ui.get_all_individual_AN(), dict_2_array=True)\n",
    "    ### add protein groups to ENSP_2_functionEnumArray_dict\n",
    "    ENSP_2_functionEnumArray_dict = add_protein_groups_to_ENSP_2_functionEnumArray_dict(ENSP_2_functionEnumArray_dict, ui.get_all_unique_proteinGroups())\n",
    "\n",
    "    count_all_terms(ENSP_2_functionEnumArray_dict, protein_ans_fg, funcEnum_count_foreground)\n",
    "\n",
    "    ### count background\n",
    "    if em == \"genome\":\n",
    "        funcEnum_index_2_associations = taxid_2_tuple_funcEnum_index_2_associations_counts[taxid]\n",
    "        funcEnum_index_positions_arr, counts_arr = funcEnum_index_2_associations\n",
    "        create_funcEnum_count_background_v3(funcEnum_count_background, funcEnum_index_positions_arr, counts_arr)\n",
    "    elif em == \"abundance_correction\":\n",
    "        funcEnum_count_background = count_all_term_abundance_corrected(ui, ENSP_2_functionEnumArray_dict, funcEnum_count_background)\n",
    "        background_n = foreground_n\n",
    "    elif em == \"compare_samples\":\n",
    "        count_all_terms(ENSP_2_functionEnumArray_dict, protein_ans_bg, funcEnum_count_background)\n",
    "    else:\n",
    "        args_dict[\"ERROR enrichment_method\"] = \"The 'enrichment_method' you've provided: '{}' doesn't exist / isn't implemented.\".format(args_dict[\"enrichment_method\"])\n",
    "        return args_dict\n",
    "\n",
    "    ## limit to given entity types\n",
    "    cond_limit_2_entity_type = limit_to_entity_types(args_dict[\"limit_2_entity_type\"], function_enumeration_len, etype_cond_dict, funcEnum_count_foreground)\n",
    "    limit_to_go_subset(etype_cond_dict, args_dict[\"go_slim_subset\"], goslimtype_2_cond_dict, funcEnum_count_foreground)\n",
    "    o_or_u_or_both_encoding = args_dict[\"o_or_u_or_both_encoding\"]\n",
    "\n",
    "    ### calculate Fisher p-values and get bool array for multiple testing\n",
    "    calc_pvalues(funcEnum_count_foreground, funcEnum_count_background, foreground_n, background_n, p_values, cond_multitest, effectSizes, over_under_int_arr, o_or_u_or_both_encoding)\n",
    "\n",
    "    ######################################################################################################################################################\n",
    "    ### Jensenlab Scores KS test\n",
    "#     cond_KS_etypes = etype_cond_dict[\"cond_25\"] | etype_cond_dict[\"cond_26\"] | etype_cond_dict[\"cond_20\"]\n",
    "\n",
    "#     fg_scores_matrix, list_of_rowIndices_fg = slice_ScoresMatrix_for_given_ENSP(protein_ans_fg, ENSP_2_rowIndex_dict, CSC_ENSPencoding_2_FuncEnum)\n",
    "#     fg_scores_matrix_data = fg_scores_matrix.data\n",
    "#     fg_scores_matrix_indptr = fg_scores_matrix.indptr\n",
    "#     if fg_scores_matrix_data.size > 0:\n",
    "#         if em == \"genome\": # \"genome\" has 2 possible KS methods KolmogorovSmirnov_sparse_cy (if fg not a proper subset of bg but comparing to precomputed bg) and KolmogorovSmirnov_sparse_cy_genome.\n",
    "#             if KS_method in {\"cy\", \"sparse_scipy\"}:\n",
    "#                 bg_scores_matrix_data = None\n",
    "#                 bg_scores_matrix_indptr = None\n",
    "#                 try:\n",
    "#                     funcEnum_2_scores_dict_bg = Taxid_2_FunctionEnum_2_Scores_dict[taxid] # taxid is an Integer\n",
    "#                 except KeyError: # no text mining information for this taxon, try to translate to species level and try again. e.g. user provides 559292 (Saccharomyces cerevisiae S288C, UniProt Reference Proteome), but Jensenlab Textmining supports 4932 (Saccharomyces cerevisiae, rank species)\n",
    "#                     funcEnum_2_scores_dict_bg = {} # TaxID check is already done in runserver.py and userinput.py\n",
    "#                 if KS_method == \"sparse_scipy\":\n",
    "#                     KolmogorovSmirnov_sparse_scipy(funcEnum_2_scores_dict_bg, foreground_n, background_n, fg_scores_matrix_data, fg_scores_matrix_indptr, bg_scores_matrix_data, bg_scores_matrix_indptr, p_values, cond_multitest, effectSizes, p_value_cutoff, funcEnum_count_foreground, funcEnum_count_background, over_under_int_arr, o_or_u_or_both_encoding, em, filter_foreground_count_one)\n",
    "#                 elif KS_method == \"cy\":\n",
    "#                     KolmogorovSmirnov_sparse_cy(funcEnum_2_scores_dict_bg, foreground_n, background_n, fg_scores_matrix_data, fg_scores_matrix_indptr, bg_scores_matrix_data, bg_scores_matrix_indptr, p_values, cond_multitest, effectSizes, p_value_cutoff, funcEnum_count_foreground, funcEnum_count_background, over_under_int_arr, o_or_u_or_both_encoding, em, filter_foreground_count_one)\n",
    "#                 else:\n",
    "#                     print(\"KS_method {} unknown\".format(KS_method))\n",
    "#                     return None\n",
    "\n",
    "#             elif KS_method == \"scipy\":\n",
    "#                 funcEnums_2_include_set = set(indices_arr[cond_KS_etypes & cond_limit_2_entity_type])\n",
    "#                 funcEnum_2_scores_dict_fg = collect_scores_per_term_limit_2_inclusionTerms(protein_ans_fg, ENSP_2_tuple_funcEnum_score_dict, funcEnums_2_include_set, list_2_array=True)\n",
    "#                 funcEnum_2_scores_dict_bg = Taxid_2_FunctionEnum_2_Scores_dict[taxid]\n",
    "#                 if debug:\n",
    "#                     return foreground_n, background_n, funcEnum_2_scores_dict_fg, funcEnum_2_scores_dict_bg, p_values, cond_multitest, effectSizes, p_value_cutoff, funcEnum_count_foreground, funcEnum_count_background, over_under_int_arr, o_or_u_or_both_encoding, True\n",
    "#                 print(\"running KolmogorovSmirnov_scipy\")\n",
    "#                 KolmogorovSmirnov_scipy(foreground_n, background_n, funcEnum_2_scores_dict_fg, funcEnum_2_scores_dict_bg, p_values, cond_multitest, effectSizes, p_value_cutoff, funcEnum_count_foreground, funcEnum_count_background, over_under_int_arr, o_or_u_or_both_encoding, fill_zeros=True)\n",
    "#             else:\n",
    "#                 print(\"KS_method {} not implemented\".format(KS_method))\n",
    "#                 return None\n",
    "#         elif em in {\"compare_samples\", \"abundance_correction\"}: # abundance_correction calculated the same way as compare_samples, background_n will differ from non-KS etypes\n",
    "#             if KS_method in {\"cy\", \"sparse_scipy\"}:\n",
    "#                 bg_scores_matrix, list_of_rowIndices_bg = slice_ScoresMatrix_for_given_ENSP(protein_ans_bg, ENSP_2_rowIndex_dict, CSC_ENSPencoding_2_FuncEnum)\n",
    "#                 bg_scores_matrix_data = bg_scores_matrix.data\n",
    "#                 bg_scores_matrix_indptr = bg_scores_matrix.indptr\n",
    "#                 funcEnum_2_scores_dict_bg = None\n",
    "#                 if em == \"abundance_correction\":\n",
    "#                     background_n_temp = ui.background.shape[0]\n",
    "#                 else:\n",
    "#                     background_n_temp = background_n\n",
    "#                 if debug:\n",
    "#                     return funcEnum_2_scores_dict_bg, foreground_n, background_n_temp, fg_scores_matrix_data, fg_scores_matrix_indptr, bg_scores_matrix_data, bg_scores_matrix_indptr, p_values, cond_multitest, effectSizes, p_value_cutoff, funcEnum_count_foreground, funcEnum_count_background, over_under_int_arr, o_or_u_or_both_encoding, em, filter_foreground_count_one\n",
    "#                 if KS_method == \"cy\":\n",
    "#                     print(\"running KolmogorovSmirnov_sparse_cy\")\n",
    "#                     KolmogorovSmirnov_sparse_cy(funcEnum_2_scores_dict_bg, foreground_n, background_n_temp, fg_scores_matrix_data, fg_scores_matrix_indptr, bg_scores_matrix_data, bg_scores_matrix_indptr, p_values, cond_multitest, effectSizes, p_value_cutoff, funcEnum_count_foreground, funcEnum_count_background, over_under_int_arr, o_or_u_or_both_encoding, em, filter_foreground_count_one)\n",
    "#                 elif KS_method == \"sparse_scipy\":\n",
    "#                     print(\"running KolmogorovSmirnov_sparse_scipy\")\n",
    "#                     KolmogorovSmirnov_sparse_scipy(funcEnum_2_scores_dict_bg, foreground_n, background_n_temp, fg_scores_matrix_data, fg_scores_matrix_indptr, bg_scores_matrix_data, bg_scores_matrix_indptr, p_values, cond_multitest, effectSizes, p_value_cutoff, funcEnum_count_foreground, funcEnum_count_background, over_under_int_arr, o_or_u_or_both_encoding, em, filter_foreground_count_one)\n",
    "#                 else:\n",
    "#                     print(\"KS_method {} unknown\".format(KS_method))\n",
    "#                     return None\n",
    "#             elif KS_method == \"scipy\":\n",
    "#                 funcEnums_2_include_set = set(indices_arr[cond_KS_etypes & cond_limit_2_entity_type])\n",
    "#                 funcEnum_2_scores_dict_fg = collect_scores_per_term_limit_2_inclusionTerms(protein_ans_fg, ENSP_2_tuple_funcEnum_score_dict, funcEnums_2_include_set, list_2_array=True)\n",
    "#                 funcEnum_2_scores_dict_bg = collect_scores_per_term_limit_2_inclusionTerms(protein_ans_bg, ENSP_2_tuple_funcEnum_score_dict, funcEnums_2_include_set, list_2_array=True)\n",
    "#                 print(\"running KolmogorovSmirnov_scipy\")\n",
    "#                 if debug:\n",
    "#                     fill_zeros = True\n",
    "#                     return foreground_n, background_n, funcEnum_2_scores_dict_fg, funcEnum_2_scores_dict_bg, p_values, cond_multitest, effectSizes, p_value_cutoff, funcEnum_count_foreground, funcEnum_count_background, over_under_int_arr, o_or_u_or_both_encoding, fill_zeros\n",
    "#                 KolmogorovSmirnov_scipy(foreground_n, background_n, funcEnum_2_scores_dict_fg, funcEnum_2_scores_dict_bg, p_values, cond_multitest, effectSizes, p_value_cutoff, funcEnum_count_foreground, funcEnum_count_background, over_under_int_arr, o_or_u_or_both_encoding, fill_zeros=True)\n",
    "\n",
    "    #### other methods e.g. abundance_correction, compare_samples are missing  #!!!\n",
    "    ### don't delete \"add_funcEnums_2_dict_CSC\", not using due to speed and too many proteins in list --> but use for characterize_foreground\n",
    "    # add_funcEnums_2_dict_CSC(protein_ans_fg, ENSP_2_functionEnumArray_dict, ENSP_2_rowIndex_dict, CSR_ENSPencoding_2_FuncEnum)\n",
    "\n",
    "    ### \"over/under\"\n",
    "    if o_or_u_or_both_encoding == 1: # overrepresented\n",
    "        over_under_arr_of_string[over_under_int_arr == 1] = \"o\"\n",
    "    elif o_or_u_or_both_encoding == 0: # both\n",
    "        over_under_arr_of_string[over_under_int_arr == 1] = \"o\"\n",
    "        over_under_arr_of_string[over_under_int_arr == 2] = \"u\"\n",
    "    elif o_or_u_or_both_encoding == 2: # underrepresented\n",
    "        over_under_arr_of_string[over_under_int_arr == 2] = \"u\"\n",
    "    else: # check already done above\n",
    "        return args_dict\n",
    "    ### multiple testing per entity type, save results preformed p_values_corrected\n",
    "    if args_dict[\"multiple_testing_per_etype\"]:\n",
    "        for etype_name, cond_etype in etype_cond_dict.items():\n",
    "            num_total_tests = etype_2_num_functions_dict[etype_name]\n",
    "            multiple_testing_per_entity_type(cond_etype, cond_multitest, p_values, p_values_corrected, indices_arr, num_total_tests)\n",
    "    else:\n",
    "        cond_all = np.ones(function_enumeration_len, dtype=bool)\n",
    "        num_total_tests = cond_all.shape[0]\n",
    "        multiple_testing_per_entity_type(cond_all, cond_multitest, p_values, p_values_corrected, indices_arr, num_total_tests)\n",
    "\n",
    "    ### Filter stuff\n",
    "#     if KS_etypes_FG_IDs:\n",
    "#         add_funcEnums_2_dict_CSC(protein_ans_fg, ENSP_2_functionEnumArray_dict, ENSP_2_rowIndex_dict, CSR_ENSPencoding_2_FuncEnum)\n",
    "    foreground_ids_arr_of_string, funcEnum_indices_for_IDs, cond_etypes_with_ontology_filtered, cond_etypes_rem_foreground_ids_filtered, cond_filter = filter_stuff(args_dict, protein_ans_fg, p_values_corrected, foreground_ids_arr_of_string, funcEnum_count_foreground, year_arr, p_values, indices_arr, ENSP_2_functionEnumArray_dict, cond_filter, etype_cond_dict, cond_PMIDs, cond_etypes_with_ontology, cond_etypes_rem_foreground_ids, over_under_int_arr)\n",
    "    if debug:\n",
    "        return foreground_ids_arr_of_string\n",
    "    if em in {\"compare_samples\"}:\n",
    "        background_ids_arr_of_string = map_funcEnum_2_ENSPs(protein_ans_bg, ENSP_2_functionEnumArray_dict, funcEnum_indices_for_IDs, background_ids_arr_of_string)\n",
    "\n",
    "    ### filter etypes with ontologies --> cond_terms_reduced_with_ontology\n",
    "    df_with_ontology = pd.DataFrame({\"term_enum\": indices_arr[cond_etypes_with_ontology_filtered].view(), \"foreground_ids\": foreground_ids_arr_of_string[cond_etypes_with_ontology_filtered].view(), \"hierarchical_level\": hierlevel_arr[cond_etypes_with_ontology_filtered].view(), \"p_value\": p_values[cond_etypes_with_ontology_filtered].view(), \"foreground_count\": funcEnum_count_foreground[cond_etypes_with_ontology_filtered].view(), \"etype\": entitytype_arr[cond_etypes_with_ontology_filtered].view()})\n",
    "    if args_dict[\"filter_parents\"]: # only for etypes with ontology, but since foreground IDs needed get them for all\n",
    "        filter_parents_if_same_foreground(blacklisted_terms_bool_arr_temp, cond_terms_reduced_with_ontology, lineage_dict_enum, df_with_ontology) # modifies cond_terms_reduced_with_ontology inplace\n",
    "    else: # since no filtering done use all etypes with ontology\n",
    "        cond_terms_reduced_with_ontology = cond_filter & cond_etypes_with_ontology\n",
    "    ### concatenate filtered results\n",
    "    cond_2_return = cond_PMIDs | cond_terms_reduced_with_ontology | cond_etypes_rem_foreground_ids_filtered\n",
    "\n",
    "    if simplified_output:\n",
    "        df_2_return = pd.DataFrame({\"term\": functionalterm_arr[cond_2_return].view(),\n",
    "                                \"hierarchical_level\": hierlevel_arr[cond_2_return].view(),\n",
    "                                \"p_value\": p_values[cond_2_return].view(),\n",
    "                                \"FDR\": p_values_corrected[cond_2_return].view(),\n",
    "                                \"category\": category_arr[cond_2_return].view(),\n",
    "                                \"etype\": entitytype_arr[cond_2_return].view(),\n",
    "                                \"description\": description_arr[cond_2_return].view(),\n",
    "                                \"year\": year_arr[cond_2_return].view(),\n",
    "                                \"FG_IDs\": foreground_ids_arr_of_string[cond_2_return].view(),\n",
    "                                \"FG_count\": funcEnum_count_foreground[cond_2_return].view(),\n",
    "                                \"BG_count\": funcEnum_count_background[cond_2_return].view()})\n",
    "        return df_2_return[['term', 'hierarchical_level', 'p_value', 'FDR', 'category', 'etype', 'description', 'FG_count', 'BG_count', 'FG_IDs', 'year']]\n",
    "\n",
    "    df_2_return = pd.DataFrame({\"term\": functionalterm_arr[cond_2_return].view(),\n",
    "                            \"hierarchical_level\": hierlevel_arr[cond_2_return].view(),\n",
    "                            \"p_value\": p_values[cond_2_return].view(),\n",
    "                            \"FDR\": p_values_corrected[cond_2_return].view(),\n",
    "                            \"category\": category_arr[cond_2_return].view(),\n",
    "                            \"etype\": entitytype_arr[cond_2_return].view(),\n",
    "                            \"description\": description_arr[cond_2_return].view(),\n",
    "                            \"year\": year_arr[cond_2_return].view(),\n",
    "#                             \"ratio_in_FG\": ratio_in_foreground[cond_2_return].view(),\n",
    "#                             \"ratio_in_BG\": ratio_in_background[cond_2_return].view(),\n",
    "                            \"FG_IDs\": foreground_ids_arr_of_string[cond_2_return].view(),\n",
    "                            \"FG_count\": funcEnum_count_foreground[cond_2_return].view(),\n",
    "                            \"BG_count\": funcEnum_count_background[cond_2_return].view(),\n",
    "                            \"effectSize\": effectSizes[cond_2_return].view(),\n",
    "                            \"over_under\": over_under_arr_of_string[cond_2_return].view(),\n",
    "                            \"funcEnum\": indices_arr[cond_2_return].view()})\n",
    "\n",
    "    if em in {\"compare_samples\"}: # , \"compare_groups\"\n",
    "        df_2_return[\"BG_IDs\"] = background_ids_arr_of_string[cond_2_return].view()\n",
    "    else:\n",
    "        cols_2_return_sort_order.remove(\"BG_IDs\")\n",
    "    df_2_return = s_value(df_2_return)\n",
    "    df_2_return[\"s_value_abs\"] = df_2_return[\"s_value\"].apply(lambda x: abs(x))\n",
    "    df_2_return = df_2_return.sort_values([\"etype\", \"s_value_abs\", \"hierarchical_level\", \"year\"], ascending=[False, False, False, False])\n",
    "    df_2_return[\"rank\"] = df_2_return.groupby(\"etype\")[\"s_value_abs\"].rank(ascending=False, method=\"first\").fillna(value=df_2_return.shape[0]).astype(int)\n",
    "    if debug:\n",
    "            return protein_ans_bg, ENSP_2_functionEnumArray_dict, funcEnum_indices_for_IDs, background_ids_arr_of_string, df_2_return\n",
    "    df_2_return = ui.translate_primary_back_to_secondary(df_2_return)\n",
    "    df_2_return[\"FG_n\"] = foreground_n\n",
    "    df_2_return[\"BG_n\"] = background_n\n",
    "#     if em == \"abundance_correction\":\n",
    "#         cond_KS_etypes_temp = df_2_return[\"etype\"].isin(variables.entity_types_with_scores)\n",
    "#         df_2_return.loc[cond_KS_etypes_temp, \"BG_n\"] = ui.background.shape[0]\n",
    "    # #!!! DEBUG uncomment for production #     df_2_return.loc[df_2_return[\"etype\"].isin([-20, -25, -26]), [\"ratio_in_FG\", \"ratio_in_BG\", \"FG_count\", \"BG_count\"]] = np.nan\n",
    "\n",
    "    ### calc ratio in foreground, count foreground / len(protein_ans)\n",
    "    df_2_return[\"ratio_in_FG\"] = df_2_return[\"FG_count\"] / df_2_return[\"FG_n\"] # ratio_in_foreground = funcEnum_count_foreground / foreground_n\n",
    "    df_2_return[\"ratio_in_BG\"] = df_2_return[\"BG_count\"] / df_2_return[\"BG_n\"] # ratio_in_background = funcEnum_count_background / background_n\n",
    "    try: \n",
    "        STRING_beta = args_dict[\"STRING_beta\"]\n",
    "    except KeyError:\n",
    "        STRING_beta = False\n",
    "    if STRING_beta:\n",
    "        df_2_return = df_2_return.rename(columns={\"BG_count\": 'background_count', \"FG_count\": 'foreground_count', \"FG_IDs\": 'foreground_ids'})\n",
    "        return df_2_return[variables.cols_sort_order_genome_STRING_beta + list(set(df_2_return.columns.tolist()) - set(variables.cols_sort_order_genome_STRING_beta))]\n",
    "    return df_2_return[cols_2_return_sort_order]\n",
    "\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "cdef set_fg_counts(unsigned int [::1] fg_scores_matrix_data, int [::1] fg_scores_matrix_indptr, unsigned int[::1] funcEnum_count_foreground, filter_foreground_count_one):\n",
    "    cdef:\n",
    "        unsigned int len_fg_scores_matrix_indptr\n",
    "        unsigned int funcEnum, num_fg_vals\n",
    "\n",
    "    len_fg_scores_matrix_indptr = fg_scores_matrix_indptr.shape[0]\n",
    "    for funcEnum in range(len_fg_scores_matrix_indptr - 1):\n",
    "        index_col_start_fg = fg_scores_matrix_indptr[funcEnum]\n",
    "        index_col_stop_fg = fg_scores_matrix_indptr[funcEnum + 1]\n",
    "        if index_col_start_fg == index_col_stop_fg:\n",
    "            continue # column is empty\n",
    "        elif filter_foreground_count_one and (index_col_stop_fg - index_col_start_fg) == 1:\n",
    "            continue\n",
    "        else:\n",
    "            fg_values = fg_scores_matrix_data[index_col_start_fg:index_col_stop_fg]\n",
    "        num_fg_vals = fg_values.shape[0]\n",
    "        funcEnum_count_foreground[funcEnum] = num_fg_vals\n",
    "\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "cdef int collect_scores_per_term_limit_2_inclusionTerms_arr_2(protein_AN_set, ENSP_2_tuple_funcEnum_score_dict, funcEnums_2_include_set, unsigned int[:, ::1] funcEnumContiguousIndex_2_Scores_arr, unsigned int[::1] funcEnum_2_funcEnumIndex_arr):\n",
    "    \"\"\"\n",
    "    # unsigned int[:, ::1] arr\n",
    "    for a given protein: a functional term should only have a single score (not multiple as previously)\n",
    "    ENSP_2_tuple_funcEnum_score_dict['3702.AT1G01010.1']\n",
    "    (array([ 211,  252,  253], dtype=uint32),\n",
    "     array([420000, 4166357, 4195121], dtype=uint32))\n",
    "    funcEnum_2_scores_array: 2D array of Zeros unless filled with Jensenlab-Score, \n",
    "        shape=(len_funcEnums_2_include_set, len_protein_AN_list)\n",
    "        row number indirectly codes for funcEnum, column codes for AN enumeration (which does not need to be preserved, since sorted afterwards)\n",
    "    some funcEnum rows will stay empty since entity_types_with_scores = {-20, -25, -26}  # GO-CC, BTO, DOID\n",
    "    are not contiguous numbers.\n",
    "    \"\"\"\n",
    "    cdef:\n",
    "        unsigned int index_protein\n",
    "        unsigned int index_funcEnum\n",
    "        unsigned int funcEnum_contiguous_index\n",
    "        unsigned int len_funcEnum_arr\n",
    "        unsigned int funcEnum\n",
    "        unsigned int score\n",
    "        const unsigned int[::1] funcEnum_arr\n",
    "        const unsigned int[::1] score_arr\n",
    "        unsigned int max_funcEnums_2_include_set = max(funcEnums_2_include_set)\n",
    "\n",
    "    for index_protein, protein_AN in enumerate(protein_AN_set): # row-index\n",
    "        try:\n",
    "            funcEnum_score = ENSP_2_tuple_funcEnum_score_dict[protein_AN]\n",
    "        except KeyError:\n",
    "            continue\n",
    "        funcEnum_arr = funcEnum_score[0]\n",
    "        score_arr = funcEnum_score[1]\n",
    "        len_funcEnum_arr = funcEnum_arr.shape[0]\n",
    "        for index_funcEnum in range(len_funcEnum_arr): # not col-index\n",
    "            funcEnum = funcEnum_arr[index_funcEnum]\n",
    "            if funcEnum <= max_funcEnums_2_include_set: # remove for speed-up, [filter later #!!! ToDo]\n",
    "                score = score_arr[index_funcEnum]\n",
    "                funcEnum_contiguous_index = funcEnum_2_funcEnumIndex_arr[funcEnum] # col-index, since enum\n",
    "                funcEnumContiguousIndex_2_Scores_arr[funcEnum_contiguous_index, index_protein] = score\n",
    "    return 0\n",
    "\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "cdef int create_funcEnum_count_background_v3(unsigned int[::1] funcEnum_count_background,\n",
    "                                         const unsigned int[::1] funcEnum_index_arr, # uint32\n",
    "                                         const unsigned int[::1] count_arr): # uint32\n",
    "    cdef:\n",
    "        int i, N = funcEnum_index_arr.shape[0]\n",
    "        unsigned int index_\n",
    "        unsigned short count\n",
    "\n",
    "    for i in range(N):\n",
    "        index_ = funcEnum_index_arr[i]\n",
    "        count = count_arr[i]\n",
    "        funcEnum_count_background[index_] = count\n",
    "    return 0\n",
    "\n",
    "def count_all_term_abundance_corrected(ui, ENSP_2_functionEnumArray_dict, funcEnum_count):\n",
    "    funcEnum_count_float = np.zeros(funcEnum_count.shape[0], dtype=np.dtype(\"float64\"))\n",
    "    for proteinGroup_list, correction_factor in ui.iter_bins():\n",
    "        for proteinGroup in proteinGroup_list:\n",
    "            try:\n",
    "                funcEnum_associations = ENSP_2_functionEnumArray_dict[proteinGroup]\n",
    "            except KeyError: # no functional annotation for proteins\n",
    "                continue\n",
    "            if proteinGroup in {'A0A2L0PMR4_VITS1','A0A2L0PNY0_VITS1', 'A0A2L0PNZ2_VITS1','A0A2L0PPD5_VITS1', 'Q8L311_VITS1'}:\n",
    "                print(proteinGroup, correction_factor, funcEnum_associations)\n",
    "            count_terms_cy_abundance_corrected(correction_factor, funcEnum_associations, funcEnum_count_float)\n",
    "    funcEnum_count = np.around(funcEnum_count_float).astype(dtype=np.dtype(\"uint32\"))\n",
    "    return funcEnum_count\n",
    "\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "cdef int count_terms_cy_abundance_corrected(double correction_factor,\n",
    "                                        unsigned int[::1] funcEnum_associations,\n",
    "                                        double[::1] funcEnum_count_float):\n",
    "    cdef int N, i, k\n",
    "    N = funcEnum_associations.shape[0]\n",
    "    for i in range(N):\n",
    "        k = funcEnum_associations[i]\n",
    "        funcEnum_count_float[k] += correction_factor\n",
    "    return 0\n",
    "\n",
    "def count_all_terms(ENSP_2_functionEnumArray_dict, protein_ans, funcEnum_count):\n",
    "    for ENSP in (ENSP for ENSP in protein_ans if ENSP in ENSP_2_functionEnumArray_dict):\n",
    "        funcEnumAssociations = ENSP_2_functionEnumArray_dict[ENSP]\n",
    "        count_terms_cy(funcEnumAssociations, funcEnum_count)\n",
    "\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "cdef int count_terms_cy(unsigned int[::1] funcEnum_associations,\n",
    "                    unsigned int[::1] funcEnum_count):\n",
    "    \"\"\"\n",
    "    without returning 'funcEnum_count' the function does inplace change of 'funcEnum_count'\n",
    "    :param funcEnum_associations: np.array (of variable length, with functional associations \n",
    "    as enumerations (instead of strings), \n",
    "    uint32, i.e. which functional associations are given for provided user input proteins)\n",
    "    :param funcEnum_count: np.array (shape of array from 0 to max enumeration of functional-terms, \n",
    "    uint32, each position codes for \n",
    "    a specific functional term, the value is a count for the given user input)\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    cdef int N, i, k\n",
    "    N = funcEnum_associations.shape[0]\n",
    "    for i in range(N):\n",
    "        k = funcEnum_associations[i]\n",
    "        funcEnum_count[k] += 1\n",
    "    return 0\n",
    "\n",
    "def collect_scores_per_term_characterize_foreground(protein_AN_list, ENSP_2_tuple_funcEnum_score_dict, funcEnums_2_include_set, score_cutoff=3):\n",
    "    funcEnum_2_scores_dict = defaultdict(lambda: [])\n",
    "    for protein_AN in protein_AN_list:\n",
    "        funcEnum_already_counted = set()\n",
    "        try:\n",
    "            funcEnum_score = ENSP_2_tuple_funcEnum_score_dict[protein_AN]\n",
    "        except KeyError:\n",
    "            continue\n",
    "        funcEnum_arr, score_arr = funcEnum_score\n",
    "        len_funcEnum_arr = len(funcEnum_arr)\n",
    "        for index_ in range(len_funcEnum_arr):\n",
    "            funcEnum = funcEnum_arr[index_]\n",
    "            if funcEnum in funcEnums_2_include_set:\n",
    "                score = score_arr[index_]\n",
    "                if score >= score_cutoff:\n",
    "                    if funcEnum not in funcEnum_already_counted:\n",
    "                        # in order to count a function only once per protein\n",
    "                        funcEnum_2_scores_dict[funcEnum].append(score)\n",
    "                        funcEnum_already_counted.update(set([funcEnum]))\n",
    "    return funcEnum_2_scores_dict\n",
    "\n",
    "def collect_scores_per_term(protein_AN_list, ENSP_2_tuple_funcEnum_score_dict, list_2_array=False):\n",
    "    \"\"\"\n",
    "    ENSP_2_tuple_funcEnum_score_dict['3702.AT1G01010.1']\n",
    "    (array([ 211,  252,  253], dtype=uint32),\n",
    "     array([4200000, 4166357, 4195121], dtype=uint32))\n",
    "    funcEnum_2_scores_dict: key: functionEnumeration, val: list of scores\n",
    "    \"\"\"\n",
    "    funcEnum_2_scores_dict = defaultdict(lambda: [])\n",
    "    for protein_AN in protein_AN_list:\n",
    "        try:\n",
    "            funcEnum_score = ENSP_2_tuple_funcEnum_score_dict[protein_AN]\n",
    "        except KeyError:\n",
    "            continue\n",
    "        funcEnum_arr, score_arr = funcEnum_score\n",
    "        len_funcEnum_arr = len(funcEnum_arr)\n",
    "        for index_ in range(len_funcEnum_arr):\n",
    "            score = score_arr[index_]\n",
    "            funcEnum_2_scores_dict[funcEnum_arr[index_]].append(score)\n",
    "    if list_2_array:\n",
    "        return {funcEnum: np.asarray(scores, dtype=np.dtype(variables.dtype_TM_score)) for funcEnum, scores in funcEnum_2_scores_dict.items()} # float64 --> uint32\n",
    "    # since concatenating np.arrays later on (for filling with zeros) produces 64 bit array anyway\n",
    "    else:\n",
    "        return funcEnum_2_scores_dict\n",
    "\n",
    "def collect_scores_per_term_limit_2_inclusionTerms(protein_AN_list, ENSP_2_tuple_funcEnum_score_dict, funcEnums_2_include_set, list_2_array=False):\n",
    "    \"\"\"\n",
    "    for a given protein: a functional term should only have a single score (not multiple as previously)\n",
    "    ENSP_2_tuple_funcEnum_score_dict['3702.AT1G01010.1']\n",
    "    (array([ 211,  252,  253], dtype=uint32),\n",
    "     array([420000, 4166357, 4195121], dtype=uint32))\n",
    "    funcEnum_2_scores_dict: key: functionEnumeration, val: list of Integer scores ( )\n",
    "    \"\"\"\n",
    "    len_protein_AN_list = len(protein_AN_list)\n",
    "    funcEnum_2_scores_dict = defaultdict(lambda: [0]*len_protein_AN_list)\n",
    "    for index_protein, protein_AN in enumerate(protein_AN_list):\n",
    "        try:\n",
    "            funcEnum_score = ENSP_2_tuple_funcEnum_score_dict[protein_AN]\n",
    "        except KeyError:\n",
    "            continue\n",
    "        funcEnum_arr, score_arr = funcEnum_score\n",
    "        len_funcEnum_arr = len(funcEnum_arr)\n",
    "        for index_ in range(len_funcEnum_arr):\n",
    "            funcEnum = funcEnum_arr[index_]\n",
    "            if funcEnum in funcEnums_2_include_set:\n",
    "                score = score_arr[index_]\n",
    "                funcEnum_2_scores_dict[funcEnum][index_protein] = score # funcEnum_2_scores_dict[funcEnum].append(score)\n",
    "    if list_2_array:\n",
    "        return {funcEnum: np.asarray(scores, dtype=np.dtype(variables.dtype_TM_score)) for funcEnum, scores in funcEnum_2_scores_dict.items()}\n",
    "    # since concatenating np.arrays later on (for filling with zeros) produces 64 bit array anyway\n",
    "    else:\n",
    "        return funcEnum_2_scores_dict\n",
    "\n",
    "def collect_scores_per_term_abundance_corrected(ui, ENSP_2_tuple_funcEnum_score_dict, funcEnums_2_include_set, list_2_array=False):\n",
    "    funcEnum_2_scores_dict = defaultdict(lambda: [])\n",
    "    for proteinGroup_list, correction_factor in ui.iter_bins():\n",
    "        for proteinGroup in proteinGroup_list:\n",
    "            try:\n",
    "                funcEnum_score = ENSP_2_tuple_funcEnum_score_dict[proteinGroup]\n",
    "            except KeyError:\n",
    "                continue\n",
    "            funcEnum_arr, score_arr = funcEnum_score\n",
    "            len_funcEnum_arr = len(funcEnum_arr)\n",
    "            for index_ in range(len_funcEnum_arr):\n",
    "                funcEnum = funcEnum_arr[index_]\n",
    "                if funcEnum in funcEnums_2_include_set:\n",
    "                    score = score_arr[index_]\n",
    "                    funcEnum_2_scores_dict[funcEnum].append(score*correction_factor)\n",
    "    if list_2_array:\n",
    "        return {funcEnum: np.asarray(scores, dtype=np.dtype(variables.dtype_TM_score)) for funcEnum, scores in funcEnum_2_scores_dict.items()}\n",
    "        # since concatenating np.arrays later on (for filling with zeros) produces 64 bit array anyway\n",
    "    else:\n",
    "        return funcEnum_2_scores_dict\n",
    "\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "cdef int calc_pvalues_orig(unsigned int[::1] funcEnum_count_foreground,\n",
    "                  unsigned int[::1] funcEnum_count_background,\n",
    "                  unsigned int foreground_n,\n",
    "                  unsigned int background_n,\n",
    "                  double[::1] p_values,\n",
    "                  cond_multitest,\n",
    "                  double[::1] effectSizes,\n",
    "                  unsigned int[::1] over_under_int_arr,\n",
    "                  unsigned int o_or_u_or_both_encoding):\n",
    "    cdef:\n",
    "        int index_, foreground_count, background_count, a, b, c, d\n",
    "        int len_functions = funcEnum_count_foreground.shape[0]\n",
    "        dict fisher_dict = {}\n",
    "        double p_val_uncorrected\n",
    "        double odds_ratio\n",
    "\n",
    "    for index_ in range(len_functions):\n",
    "        foreground_count = funcEnum_count_foreground[index_]\n",
    "        if foreground_count == 0: # continue and leave p-value set to 1, no multiple testing\n",
    "            continue\n",
    "        if foreground_count == 1: # leave p-value set to 1, BUT DO multiple testing\n",
    "            cond_multitest[index_] = True\n",
    "            over_under_int_arr[index_] = 3 # meaningless encoding in order not to filter out things later if p_value_cutoff == 1\n",
    "        else: # calculate p-value and do multiple testing\n",
    "            cond_multitest[index_] = True\n",
    "            background_count = funcEnum_count_background[index_]\n",
    "            a = foreground_count # number of proteins associated with given GO-term\n",
    "            b = foreground_n - foreground_count # number of proteins not associated with GO-term\n",
    "            c = background_count\n",
    "            d = background_n - background_count\n",
    "            p_val_uncorrected = fisher_dict.get((a, b, c, d), -1)\n",
    "            if p_val_uncorrected == -1:\n",
    "                if o_or_u_or_both_encoding == 1: # overrepresented\n",
    "                    p_val_uncorrected = pvalue(a, b, c, d).right_tail\n",
    "                    over_under_int_arr[index_] = 1\n",
    "                elif o_or_u_or_both_encoding == 0: # both\n",
    "                    p_val_uncorrected = pvalue(a, b, c, d).two_tail\n",
    "                    try:\n",
    "                        is_greater = (a / (a + b)) > (c / (c + d))\n",
    "                        if is_greater:\n",
    "                            is_greater = 1\n",
    "                        else:\n",
    "                            is_greater = 2\n",
    "                    except ZeroDivisionError:\n",
    "                        is_greater = 0 # np.nan\n",
    "                    over_under_int_arr[index_] = is_greater\n",
    "                elif o_or_u_or_both_encoding == 2: # underrepresented\n",
    "                    p_val_uncorrected = pvalue(a, b, c, d).left_tail\n",
    "                    over_under_int_arr[index_] = 2\n",
    "                else:\n",
    "                    p_val_uncorrected = 1\n",
    "                    over_under_int_arr[index_] = 3\n",
    "                fisher_dict[(a, b, c, d)] = p_val_uncorrected\n",
    "            else: # write over_under but don't calc pvalue\n",
    "                if o_or_u_or_both_encoding == 1: # overrepresented\n",
    "                    over_under_int_arr[index_] = 1\n",
    "                elif o_or_u_or_both_encoding == 0: # both\n",
    "                    try:\n",
    "                        is_greater = (a / (a + b)) > (c / (c + d))\n",
    "                    except ZeroDivisionError:\n",
    "                        is_greater = np.nan\n",
    "                    over_under_int_arr[index_] = is_greater\n",
    "                elif o_or_u_or_both_encoding == 2: # underrepresented\n",
    "                    over_under_int_arr[index_] = 2\n",
    "                else:\n",
    "                    over_under_int_arr[index_] = 3 # which caser is this supposed to be?\n",
    "            p_values[index_] = p_val_uncorrected\n",
    "            try:\n",
    "                # https://stats.stackexchange.com/questions/22508/effect-size-for-fishers-exact-test\n",
    "                # odds_ratio = (a * d) / (b * c) # true odds ratio\n",
    "                # odds_ratio = (d / (c + d)) - (a / (a + b)) # difference in proportions\n",
    "                odds_ratio = (a / (a + b)) - (c / (c + d)) # difference in proportions DBL\n",
    "                # odds_ratio = (a / (a + b)) / (c / (c + d)) # from old agotool, ratio of percent in fg to percent in bg\n",
    "            except ZeroDivisionError:\n",
    "                odds_ratio = np.nan\n",
    "            effectSizes[index_] = odds_ratio\n",
    "    return 0\n",
    "\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "cdef calc_pvalues(unsigned int[::1] funcEnum_count_foreground,\n",
    "                  unsigned int[::1] funcEnum_count_background,\n",
    "                  unsigned int foreground_n,\n",
    "                  unsigned int background_n,\n",
    "                  double[::1] p_values,\n",
    "                  cond_multitest,\n",
    "                  double[::1] effectSizes,\n",
    "                  unsigned int[::1] over_under_int_arr,\n",
    "                  unsigned int o_or_u_or_both_encoding):\n",
    "    cdef:\n",
    "        int index_, foreground_count, background_count, a, b, c, d\n",
    "        int len_functions = funcEnum_count_foreground.shape[0]\n",
    "        dict fisher_dict = {}\n",
    "        double p_val_uncorrected\n",
    "        double odds_ratio\n",
    "\n",
    "    for index_ in range(len_functions):\n",
    "        foreground_count = funcEnum_count_foreground[index_]\n",
    "        if foreground_count > 0:\n",
    "            cond_multitest[index_] = True\n",
    "            over_under_int_arr[index_] = 3 # meaningless encoding in order not to filter out things later if p_value_cutoff == 1\n",
    "            if foreground_count == 1: # leave p-value set to 1, BUT DO multiple testing\n",
    "                continue\n",
    "            background_count = funcEnum_count_background[index_]\n",
    "            a = foreground_count # number of proteins associated with given GO-term\n",
    "            b = foreground_n - foreground_count # number of proteins not associated with GO-term\n",
    "            c = background_count\n",
    "            d = background_n - background_count\n",
    "            p_val_uncorrected = fisher_dict.get((a, b, c, d), -1)\n",
    "            if p_val_uncorrected == -1:\n",
    "                if o_or_u_or_both_encoding == 1: # overrepresented\n",
    "                    p_val_uncorrected = pvalue(a, b, c, d).right_tail\n",
    "                    over_under_int_arr[index_] = 1\n",
    "                elif o_or_u_or_both_encoding == 0: # both\n",
    "                    p_val_uncorrected = pvalue(a, b, c, d).two_tail\n",
    "                    try:\n",
    "                        is_greater = (a / (a + b)) > (c / (c + d))\n",
    "                        if is_greater:\n",
    "                            is_greater = 1\n",
    "                        else:\n",
    "                            is_greater = 2\n",
    "                    except ZeroDivisionError:\n",
    "                        is_greater = 0 # np.nan\n",
    "                    over_under_int_arr[index_] = is_greater\n",
    "                elif o_or_u_or_both_encoding == 2: # underrepresented\n",
    "                    p_val_uncorrected = pvalue(a, b, c, d).left_tail\n",
    "                    over_under_int_arr[index_] = 2\n",
    "                else:\n",
    "                    p_val_uncorrected = 1\n",
    "                    over_under_int_arr[index_] = 3\n",
    "                fisher_dict[(a, b, c, d)] = p_val_uncorrected\n",
    "            else: # write over_under but don't calc pvalue\n",
    "                if o_or_u_or_both_encoding == 1: # overrepresented\n",
    "                    over_under_int_arr[index_] = 1\n",
    "                elif o_or_u_or_both_encoding == 0: # both\n",
    "                    try:\n",
    "                        is_greater = (a / (a + b)) > (c / (c + d))\n",
    "                    except ZeroDivisionError:\n",
    "                        is_greater = np.nan\n",
    "                    over_under_int_arr[index_] = is_greater\n",
    "                elif o_or_u_or_both_encoding == 2: # underrepresented\n",
    "                    over_under_int_arr[index_] = 2\n",
    "                else:\n",
    "                    over_under_int_arr[index_] = 3 # which caser is this supposed to be?\n",
    "            p_values[index_] = p_val_uncorrected\n",
    "            try:\n",
    "                # https://stats.stackexchange.com/questions/22508/effect-size-for-fishers-exact-test\n",
    "                # odds_ratio = (a * d) / (b * c) # true odds ratio\n",
    "                # odds_ratio = (d / (c + d)) - (a / (a + b)) # difference in proportions\n",
    "                odds_ratio = (a / (a + b)) - (c / (c + d)) # difference in proportions DBL\n",
    "                # odds_ratio = (a / (a + b)) / (c / (c + d)) # from old agotool, ratio of percent in fg to percent in bg\n",
    "            except ZeroDivisionError:\n",
    "                odds_ratio = np.nan\n",
    "            effectSizes[index_] = odds_ratio\n",
    "    return 0\n",
    "\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "cpdef int calc_pvalues_compare_groups(unsigned int[::1] funcEnum_count_foreground,\n",
    "                  unsigned int[::1] funcEnum_count_background,\n",
    "                  unsigned int[::1] funcEnum_count_foreground_redundant,\n",
    "                  unsigned int[::1] funcEnum_count_background_redundant,\n",
    "                  unsigned int foreground_replicates,\n",
    "                  unsigned int background_replicates,\n",
    "                  double[::1] p_values,\n",
    "                  cond_multitest,\n",
    "                  double[::1] effectSizes,\n",
    "                  unsigned int[::1] over_under_int_arr,\n",
    "                  unsigned int o_or_u_or_both_encoding):\n",
    "    cdef:\n",
    "        int index_, foreground_count, background_count, a, b, c, d, foreground_n, background_n\n",
    "        int len_functions = funcEnum_count_foreground_redundant.shape[0]\n",
    "        dict fisher_dict = {}\n",
    "        double p_val_uncorrected\n",
    "        double odds_ratio\n",
    "\n",
    "    for index_ in range(len_functions):\n",
    "        foreground_count = funcEnum_count_foreground_redundant[index_]\n",
    "        if foreground_count == 0:\n",
    "            # continue and leave p-value set to 1, no multiple testing\n",
    "            continue\n",
    "        elif foreground_count == 1:\n",
    "            # leave p-value set to 1, BUT DO multiple testing\n",
    "            cond_multitest[index_] = True\n",
    "            over_under_int_arr[index_] = 3 # meaningless encoding in order not to filter out things later if p_value_cutoff == 1\n",
    "        else:\n",
    "            # calculate p-value and do multiple testing\n",
    "            background_count = funcEnum_count_background_redundant[index_]\n",
    "            cond_multitest[index_] = True\n",
    "            a = foreground_count # number of proteins associated with given GO-term\n",
    "            foreground_n = funcEnum_count_foreground[index_] * foreground_replicates\n",
    "            b = foreground_n - foreground_count # number of proteins not associated with GO-term\n",
    "            background_n = funcEnum_count_background[index_] * background_replicates\n",
    "            c = background_count\n",
    "            if background_count == 0:\n",
    "                cond_multitest[index_] = True\n",
    "                over_under_int_arr[index_] = 3\n",
    "                continue\n",
    "            d = background_n - background_count\n",
    "            p_val_uncorrected = fisher_dict.get((a, b, c, d), -1)\n",
    "            if p_val_uncorrected == -1:\n",
    "                if o_or_u_or_both_encoding == 1: # overrepresented\n",
    "                    p_val_uncorrected = pvalue(a, b, c, d).right_tail\n",
    "                    over_under_int_arr[index_] = 1\n",
    "                elif o_or_u_or_both_encoding == 0: # both\n",
    "                    p_val_uncorrected = pvalue(a, b, c, d).two_tail\n",
    "                    try:\n",
    "                        is_greater = (a / (a + b)) > (c / (c + d))\n",
    "                        if is_greater:\n",
    "                            is_greater = 1\n",
    "                        else:\n",
    "                            is_greater = 2\n",
    "                    except ZeroDivisionError:\n",
    "                        is_greater = 0 # np.nan\n",
    "                    over_under_int_arr[index_] = is_greater\n",
    "                elif o_or_u_or_both_encoding == 2: # underrepresented\n",
    "                    p_val_uncorrected = pvalue(a, b, c, d).left_tail\n",
    "                    over_under_int_arr[index_] = 2\n",
    "                else:\n",
    "                    p_val_uncorrected = 1\n",
    "                    over_under_int_arr[index_] = 3\n",
    "                fisher_dict[(a, b, c, d)] = p_val_uncorrected\n",
    "            else: # write over_under but don't calc pvalue\n",
    "                if o_or_u_or_both_encoding == 1: # overrepresented\n",
    "                    over_under_int_arr[index_] = 1\n",
    "                elif o_or_u_or_both_encoding == 0: # both\n",
    "                    try:\n",
    "                        is_greater = (a / (a + b)) > (c / (c + d))\n",
    "                    except ZeroDivisionError:\n",
    "                        is_greater = np.nan\n",
    "                    over_under_int_arr[index_] = is_greater\n",
    "                elif o_or_u_or_both_encoding == 2: # underrepresented\n",
    "                    over_under_int_arr[index_] = 2\n",
    "                else:\n",
    "                    over_under_int_arr[index_] = 3 # which case is this supposed to be?\n",
    "            p_values[index_] = p_val_uncorrected\n",
    "            try:\n",
    "                odds_ratio = (a / (a + b)) - (c / (c + d)) # difference in proportions DBL\n",
    "            except ZeroDivisionError:\n",
    "                odds_ratio = np.nan\n",
    "            effectSizes[index_] = odds_ratio\n",
    "    return 0\n",
    "\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "@cdivision(True)\n",
    "cdef BenjaminiHochberg_cy(double[::1] p_values,\n",
    "                         unsigned int num_total_tests,\n",
    "                         double[::1] p_values_corrected,\n",
    "                         unsigned int[::1] indices_2_BH):\n",
    "    \"\"\"\n",
    "    #!!! cpdef instead of cdef for scores debugging/profiling\n",
    "    ein index array mit absoluten positionen, pvals absolut und pvalscorr absolut\n",
    "    p_values_2_BH, p_values_2_BH.shape[0], p_values_corrected_2_BH, indices_of_p_values_2_BH)\n",
    "    :param p_values: unsorted array of float\n",
    "    :param num_total_tests: Integer (number of all possible tests within etype/category, regardless of input)\n",
    "    :param p_values_corrected: array of float (1.0 by default), shape is full function_enumeration_len NOT p_values    \n",
    "    :param indices_2_BH: indices of superset, shape of array reduced to p_values_2_BH\n",
    "    iterate over p_values in p_values_2_BH_sort_order\n",
    "    set p_value_corrected at positions from indices_2_BH[p_values_2_BH_sort_order]\n",
    "    \"\"\"\n",
    "    cdef:\n",
    "        double prev_bh_value = 0.0\n",
    "        double p_value, bh_value\n",
    "        unsigned int index_2_BH, i\n",
    "        unsigned int enum_counter = 1\n",
    "        unsigned int N = indices_2_BH.shape[0]\n",
    "\n",
    "    for i in range(N):\n",
    "        index_2_BH = indices_2_BH[i]\n",
    "        p_value = p_values[index_2_BH]\n",
    "        bh_value = p_value * num_total_tests / enum_counter\n",
    "        # Sometimes this correction can give values greater than 1,\n",
    "        # so we set those values at 1\n",
    "        bh_value = min(bh_value, 1)\n",
    "        # To preserve monotonicity in the values, we take the\n",
    "        # maximum of the previous value or this one, so that we\n",
    "        # don't yield a value less than the previous.\n",
    "        bh_value = max(bh_value, prev_bh_value)\n",
    "        prev_bh_value = bh_value\n",
    "        p_values_corrected[index_2_BH] = bh_value\n",
    "        enum_counter += 1\n",
    "\n",
    "def map_funcEnum_2_ENSPs(protein_ans_list, ENSP_2_functionEnumArray_dict, funcEnum_indices, foreground_ids_arr_of_string):\n",
    "    \"\"\"\n",
    "    previously named get_foreground_IDs_arr now map_funcEnum_2_ENSPs\n",
    "    for given protein_ans produce concatenate strings of ENSP associations\n",
    "    :param protein_ans_list: List of String (or array), user provided ENSPs\n",
    "    :param ENSP_2_functionEnumArray_dict: key: String, val: array of uint32, all ENSP to function enum associations\n",
    "    :param funcEnum_indices: array of uint32, relevant func enums after filtering\n",
    "    :param foreground_ids_arr_of_string: list of empty string, len of function_enumeration_len, list instead of array since len of longest string unknown and would take lots of memory\n",
    "    :return: List of String of len function_enumeration_len with comma sep ENSPs at index positions coding for func enum\n",
    "    \"\"\"\n",
    "    funcEnum_2_ENSPs_dict = {index_: [] for index_ in funcEnum_indices}\n",
    "    for ENSP in protein_ans_list:\n",
    "        try:\n",
    "            functionEnumArray = ENSP_2_functionEnumArray_dict[ENSP]\n",
    "        except KeyError: # happens since some ENSPs are without functional associations (or if single association in genome it is filtered out)\n",
    "            continue\n",
    "        for funcEnum in functionEnumArray:\n",
    "            if funcEnum in funcEnum_2_ENSPs_dict:\n",
    "                funcEnum_2_ENSPs_dict[funcEnum].append(ENSP)\n",
    "\n",
    "    for funcEnum, ENSPs in funcEnum_2_ENSPs_dict.items():\n",
    "        foreground_ids_arr_of_string[funcEnum] = \";\".join(sorted(set(ENSPs))) # needs to be sorted otherwise grouping incorrect later on\n",
    "    return foreground_ids_arr_of_string\n",
    "\n",
    "def get_preloaded_objects_for_single_analysis(blacklisted_terms_bool_arr, function_enumeration_len=6834675):\n",
    "    \"\"\"\n",
    "    funcEnum_count_foreground, funcEnum_count_background, p_values, p_values_corrected, cond_multitest, blacklisted_terms_bool_arr_temp, cond_terms_reduced_with_ontology, foreground_ids_arr_of_string, cond_filter, cond_PMIDs\n",
    "    \"\"\"\n",
    "    funcEnum_count_foreground = np.zeros(shape=function_enumeration_len, dtype=np.dtype(\"uint32\"))\n",
    "    foreground_ids_arr_of_string = np.empty(shape=(function_enumeration_len,), dtype=object)\n",
    "    blacklisted_terms_bool_arr_temp = blacklisted_terms_bool_arr.copy()\n",
    "    # was uint32, but uint16 is sufficient for STRING v11, not using it for the foreground due to potential redundancy\n",
    "    # or for \"compare_samples\" for the same reason --> keep the same\n",
    "    funcEnum_count_background = np.zeros(shape=function_enumeration_len, dtype=np.dtype(\"uint32\"))\n",
    "    p_values = np.ones(shape=function_enumeration_len, dtype=np.dtype(\"float64\"))\n",
    "    p_values_corrected = np.ones(shape=function_enumeration_len, dtype=np.dtype(\"float64\"))\n",
    "    cond_multitest = np.zeros(function_enumeration_len, dtype=bool)\n",
    "    cond_filter = np.ones(function_enumeration_len, dtype=bool)\n",
    "    cond_PMIDs = np.zeros(function_enumeration_len, dtype=bool)\n",
    "    cond_terms_reduced_with_ontology = np.zeros(function_enumeration_len, dtype=bool)\n",
    "    background_ids_arr_of_string = np.empty(shape=(function_enumeration_len,), dtype=object)\n",
    "    effectSizes = np.empty(function_enumeration_len, dtype=np.dtype(\"float64\"))\n",
    "    effectSizes.fill(np.nan)\n",
    "    over_under_int_arr = np.zeros(function_enumeration_len, dtype=np.dtype(\"uint32\")) # encoding of 1: \"overrepresented\", 2: \"underrepresented\", 0: \"NaN\"\n",
    "    over_under_arr_of_string = np.empty(function_enumeration_len, np.dtype(\"U1\"))\n",
    "    return foreground_ids_arr_of_string, background_ids_arr_of_string, funcEnum_count_foreground, funcEnum_count_background, p_values, p_values_corrected, cond_multitest, blacklisted_terms_bool_arr_temp, cond_terms_reduced_with_ontology, cond_filter, cond_PMIDs, effectSizes, over_under_int_arr, over_under_arr_of_string\n",
    "\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "cdef filter_parents_if_same_foreground(uint8[::1] blacklisted_terms_bool_arr_temp,\n",
    "                                       cond_terms_reduced_with_ontology,\n",
    "                                       dict lineage_dict_enum,\n",
    "                                       df):\n",
    "    \"\"\"    \n",
    "    potential speed up using C++ types for sets, BUT data is copied so profile \n",
    "\n",
    "    # distutils: language = c++    \n",
    "    from libcpp.vector cimport vector\n",
    "    from libcpp.set cimport set \n",
    "    \"\"\"\n",
    "    cdef:\n",
    "        unsigned int term_enum, lineage_term\n",
    "        # unsigned int lineage\n",
    "\n",
    "    for group_terms in df.sort_values([\"foreground_ids\", \"p_value\", \"hierarchical_level\"], ascending=[True, True, False]).groupby(\"foreground_ids\", sort=False).apply(lambda group: group[\"term_enum\"].values):\n",
    "        group_terms_set = set(group_terms)\n",
    "        for term_enum in group_terms:\n",
    "            if blacklisted_terms_bool_arr_temp[term_enum] == 0: # False\n",
    "                cond_terms_reduced_with_ontology[term_enum] = True\n",
    "                try:\n",
    "                    lineage = lineage_dict_enum[term_enum] & group_terms_set # bitwise intersection\n",
    "                except KeyError: # not in hierarchy (even though it should be, but some Reactome terms are inconsistent)\n",
    "                    blacklisted_terms_bool_arr_temp[term_enum] = 1 # True\n",
    "                    continue\n",
    "                for lineage_term in lineage:\n",
    "                    blacklisted_terms_bool_arr_temp[lineage_term] = 1 # True\n",
    "\n",
    "def multiple_testing_per_entity_type(cond_etype, cond_multitest, p_values, p_values_corrected, indices_arr, num_total_tests):\n",
    "    # select indices for given entity type and if multiple testing needs to be applied\n",
    "    cond = cond_etype & cond_multitest\n",
    "    # select p_values for BenjaminiHochberg\n",
    "    p_values_2_BH = p_values[cond]\n",
    "    # previously: num_total_tests = p_values_2_BH.shape[0]\n",
    "    # select indices for BH\n",
    "    indices_2_BH = indices_arr[cond]\n",
    "    # sort p_values and remember indices sort order\n",
    "    p_values_2_BH_sort_order = np.argsort(p_values_2_BH) # index positions of a reduced set\n",
    "    indices_2_BH_of_superset = indices_2_BH[p_values_2_BH_sort_order]\n",
    "    BenjaminiHochberg_cy(p_values, num_total_tests, p_values_corrected, indices_2_BH_of_superset)\n",
    "\n",
    "def s_value(df, p_value_cutoff=0.05, KS_stat_cutoff=0.1, diff_proportions_cutoff=0.1):\n",
    "    \"\"\"\n",
    "    calculate 's-value' type statistic in order to rank based on a combination of p-value and effect size\n",
    "    for etypes -20, -25, and -26 (GOCC, BTO, and DOID) --> Common Language Effect Size\n",
    "    for other etypes difference in ratios\n",
    "    justification for cles_cutoff --> Kerby (https://doi.org/10.2466%2F11.IT.3.1) if the null is true the CLES is 50%\n",
    "    justification for diff_proportions_cutoff --> unsure how to justify from lit. need be smaller than cles_cutoff\n",
    "    --> changed from cles to KS_stat\n",
    "    \"\"\"\n",
    "    min_pval = df[\"p_value\"][df[\"p_value\"] > 0].min()\n",
    "    df[\"p_value_minlog\"] = df[\"p_value\"].apply(log_take_min_if_zero, args=(min_pval, ))\n",
    "    df[\"s_value\"] = 0.0\n",
    "    cond_scores = df[\"etype\"].isin([-20, -25, -26])\n",
    "    p_value_cutoff = -1 * math.log10(p_value_cutoff) # test for values smaller than 0\n",
    "    df[\"s_value\"] = df[\"p_value_minlog\"] * df[\"effectSize\"]\n",
    "    df = df.drop(columns=[\"p_value_minlog\"])\n",
    "    return df\n",
    "\n",
    "def log_take_min_if_zero(val, min_pval):\n",
    "    try:\n",
    "        return -1*math.log10(val)\n",
    "    except:\n",
    "        return -1*math.log10(min_pval)\n",
    "\n",
    "def limit_to_entity_types(limit_2_entity_type, function_enumeration_len, etype_cond_dict, funcEnum_count_foreground):\n",
    "    if limit_2_entity_type is not None:\n",
    "        cond_limit_2_entity_type = np.zeros(function_enumeration_len, dtype=bool)\n",
    "        for cond_name in [\"cond_\" + etype[1:] for etype in limit_2_entity_type.split(\";\")]:\n",
    "            try:\n",
    "                cond_limit_2_entity_type |= etype_cond_dict[cond_name] # add other etypes\n",
    "            except KeyError: # user provided etype can be mistyped of non-existent\n",
    "                pass\n",
    "        # set funcEnumAssociations to zero where cond_limit_2_entity_type is False\n",
    "        funcEnum_count_foreground[~cond_limit_2_entity_type] = 0\n",
    "        return cond_limit_2_entity_type # return bool arr of locations that should NOT be tested\n",
    "    else:\n",
    "        return np.ones(function_enumeration_len, dtype=bool)\n",
    "\n",
    "def limit_to_go_subset(etype_cond_dict, go_slim_subset, goslimtype_2_cond_dict, funcEnum_count_foreground):\n",
    "    if go_slim_subset is None:\n",
    "        return funcEnum_count_foreground\n",
    "    cond_GO_etypes = etype_cond_dict[\"cond_21\"] | etype_cond_dict[\"cond_22\"] | etype_cond_dict[\"cond_23\"]\n",
    "    cond = cond_GO_etypes != goslimtype_2_cond_dict[go_slim_subset] # select all GO terms that are not slim\n",
    "    # set these to count 0\n",
    "    funcEnum_count_foreground[cond] = 0\n",
    "    return funcEnum_count_foreground\n",
    "\n",
    "def add_funcEnums_2_dict(protein_ans_fg, ENSP_2_functionEnumArray_dict, ENSP_2_tuple_funcEnum_score_dict):\n",
    "    ### add Protein 2 functionEnum info for JensenLabScore data to get foregroundIDs in DF\n",
    "    for protein in protein_ans_fg:\n",
    "        try: # sort is probably not necessary # potential speedup removing the sorting\n",
    "            ENSP_2_functionEnumArray_dict[protein] = np.sort(np.concatenate((ENSP_2_tuple_funcEnum_score_dict[protein][0], ENSP_2_functionEnumArray_dict[protein])))\n",
    "        except KeyError:\n",
    "            pass # print(\"protein {} not in ENSP_2_tuple_funcEnum_score_dict\".format(protein)) # --> simply not annotated with anything from textmining\n",
    "\n",
    "def add_funcEnums_2_dict_CSC(protein_AN_set, ENSP_2_functionEnumArray_dict, ENSP_2_rowIndex_dict, CSR_ENSPencoding_2_FuncEnum):\n",
    "    \"\"\"\n",
    "    rowIndex = ENSP_2_rowIndex_dict[\"128UP_DROME\"]\n",
    "    CSR_ENSPencoding_2_FuncEnum[rowIndex].indices # --> FunEnums_array == ENSP_2_tuple_funcEnum_score_dict[\"128UP_DROME\"][0]\n",
    "    CSR_ENSPencoding_2_FuncEnum[rowIndex].data # --> Scores_array == ENSP_2_tuple_funcEnum_score_dict[ensp][1]\n",
    "    \"\"\"\n",
    "    for protein in protein_AN_set:\n",
    "        try:\n",
    "            rowIndex = ENSP_2_rowIndex_dict[protein]\n",
    "        except KeyError:\n",
    "            continue\n",
    "        funcEnum_array = CSR_ENSPencoding_2_FuncEnum[rowIndex].indices\n",
    "        ENSP_2_functionEnumArray_dict[protein] = np.sort(np.concatenate((funcEnum_array, ENSP_2_functionEnumArray_dict[protein])))\n",
    "\n",
    "def replace_secondary_and_primary_IDs(ans_string, secondary_2_primary_dict, invert_dict=False):\n",
    "    if invert_dict:\n",
    "        dict_2_use = {v: k for k, v in secondary_2_primary_dict.items()}\n",
    "    else:\n",
    "        dict_2_use = secondary_2_primary_dict\n",
    "    ids_2_return = []\n",
    "    for id_ in ans_string.split(\";\"): # if proteinGroup\n",
    "        if id_ in dict_2_use:\n",
    "            ids_2_return.append(dict_2_use[id_])\n",
    "        else:\n",
    "            ids_2_return.append(id_)\n",
    "    return \";\".join(ids_2_return)\n",
    "\n",
    "def add_protein_groups_to_ENSP_2_functionEnumArray_dict(ENSP_2_functionEnumArray_dict, all_unique_proteinGroups):\n",
    "    \"\"\"\n",
    "    for all protein groups\n",
    "    \"\"\"\n",
    "    for proteinGroup in all_unique_proteinGroups:\n",
    "        if proteinGroup not in ENSP_2_functionEnumArray_dict:\n",
    "            functionEnumArray_list = []\n",
    "            for protein in proteinGroup.split(\";\"):\n",
    "                try:\n",
    "                    functionEnumArray_list.append(ENSP_2_functionEnumArray_dict[protein])\n",
    "                except KeyError: # no functional annotation for given protein\n",
    "                    pass\n",
    "            try:\n",
    "                ENSP_2_functionEnumArray_dict[proteinGroup] = reduce(np.union1d, functionEnumArray_list)\n",
    "            except TypeError: # empty list\n",
    "                #ENSP_2_functionEnumArray_dict[proteinGroup] = False #np.array(dtype=np.dtype(\"uint32\"))\n",
    "                pass\n",
    "    return ENSP_2_functionEnumArray_dict\n",
    "\n",
    "def slice_ScoresMatrix_for_given_ENSP(protein_AN_set, ENSP_2_rowIndex_dict, matrix):\n",
    "    \"\"\"\n",
    "    produces 2D array\n",
    "    number of rows corresponds to number of proteins if in ENSP_2_Score_dict\n",
    "    number of columns corresponds to number of funcEnum of KS_etype; encoded as funcEnumIndex range(0, max(cond_KS_etypes)+1)\n",
    "    \"\"\"\n",
    "    list_of_rowIndices = []\n",
    "    for ENSP in protein_AN_set:\n",
    "        try:\n",
    "            rowIndex = ENSP_2_rowIndex_dict[ENSP]\n",
    "        except KeyError:\n",
    "            continue\n",
    "        list_of_rowIndices.append(rowIndex)\n",
    "    return matrix[list_of_rowIndices], list_of_rowIndices\n",
    "\n",
    "def KolmogorovSmirnov_old_v2(foreground_n, background_n, funcEnum_2_scores_dict_fg, funcEnum_2_scores_dict_bg, p_values, cond_multitest, effectSizes, p_value_cutoff, funcEnum_count_foreground, funcEnum_count_background, over_under_int_arr, o_or_u_or_both_encoding, enrichment_method=\"genome\"):\n",
    "    for funcEnum, scores_fg in funcEnum_2_scores_dict_fg.items():\n",
    "        scores_bg = funcEnum_2_scores_dict_bg[funcEnum]\n",
    "        if o_or_u_or_both_encoding == 0:\n",
    "            alternative = \"two-sided\"\n",
    "        elif o_or_u_or_both_encoding == 1:\n",
    "            alternative = \"greater\"\n",
    "        elif o_or_u_or_both_encoding == 2:\n",
    "            alternative = \"less\"\n",
    "        statistic, pvalue, is_greater = KS_DBL(scores_fg, scores_bg, alternative=alternative) # statistic, pvalue = stats.ks_2samp(scores_fg, scores_bg)\n",
    "        if pvalue <= p_value_cutoff:\n",
    "            if o_or_u_or_both_encoding == 1 and is_greater: # overrepresented\n",
    "                p_values[funcEnum] = pvalue\n",
    "                effectSizes[funcEnum] = statistic\n",
    "                over_under_int_arr[funcEnum] = 1\n",
    "            elif o_or_u_or_both_encoding == 0: # both\n",
    "                p_values[funcEnum] = pvalue\n",
    "                effectSizes[funcEnum] = statistic\n",
    "                if is_greater:\n",
    "                    over_under_int_arr[funcEnum] = 1 # over\n",
    "                else:\n",
    "                    over_under_int_arr[funcEnum] = 2 # under\n",
    "            elif o_or_u_or_both_encoding == 2 and not is_greater: # underrepresented\n",
    "                p_values[funcEnum] = pvalue\n",
    "                effectSizes[funcEnum] = statistic\n",
    "                over_under_int_arr[funcEnum] = 2 # under\n",
    "            else:\n",
    "                pass\n",
    "        cond_multitest[funcEnum] = True\n",
    "        funcEnum_count_foreground[funcEnum] = len(scores_fg) # number of scores, important for BH (that this does not equal 0 or nan)\n",
    "        funcEnum_count_background[funcEnum] = len(scores_bg)\n",
    "\n",
    "def KS_DBL(data1, data2, alternative=\"two-sided\", data2_sorted=False):\n",
    "    data1 = np.sort(data1)\n",
    "    if not data2_sorted: # genome comes presorted\n",
    "        data2 = np.sort(data2)\n",
    "    n1 = data1.shape[0]\n",
    "    n2 = data2.shape[0]\n",
    "    data_all = np.concatenate([data1, data2])\n",
    "    # using searchsorted solves equal data problem\n",
    "    cdf1 = np.searchsorted(data1, data_all, side='right') / n1\n",
    "    cdf2 = np.searchsorted(data2, data_all, side='right') / n2\n",
    "    cdf_diff = cdf1 - cdf2\n",
    "    minS = -np.min(cdf_diff)\n",
    "    maxS = np.max(cdf_diff)\n",
    "    if alternative == \"two-sided\":\n",
    "        D = max(minS, maxS)\n",
    "    elif alternative == \"greater\":\n",
    "        D = maxS\n",
    "    elif alternative == \"less\":\n",
    "        D = minS\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    p_value = math.exp(-2.0 * n1 * n2 * D * D / ( n1 + n2))\n",
    "    if alternative != \"two-sided\":\n",
    "        p_value /= 2\n",
    "    if p_value > 1:\n",
    "        p_value = 1\n",
    "    if p_value < 0:\n",
    "        p_value = 0\n",
    "    if maxS > minS:\n",
    "        is_greater = True\n",
    "    else:\n",
    "        is_greater = False\n",
    "    return D, p_value, is_greater\n",
    "\n",
    "def KS_DBL_adapted_from_Christian(fg_values, bg_values):\n",
    "    fg_values = sorted(fg_values)\n",
    "    bg_values = sorted(bg_values)\n",
    "    fg_size = len(fg_values)\n",
    "    bg_size = len(bg_values)\n",
    "    n1 = fg_size\n",
    "    n2 = bg_size\n",
    "    n1_plus_n2 = n1 + n2\n",
    "    n1_times_n2_times_mintwo = -2.0 * n1 * n2\n",
    "    D_max = 0.0\n",
    "    fg_rank, bg_rank = 0, 0\n",
    "    while fg_rank < fg_size:\n",
    "        fg_cumulative = fg_rank / fg_size\n",
    "        fg_val = fg_values[fg_rank]\n",
    "        for bg_rank_temp, bg_val in enumerate(bg_values[bg_rank:], 0):\n",
    "            if fg_val <= bg_val:\n",
    "                bg_rank = bg_rank_temp + bg_rank\n",
    "                break\n",
    "        bg_cumulative = (bg_rank + 1) / bg_size\n",
    "        D_current = abs(fg_cumulative - bg_cumulative)\n",
    "        if D_current > D_max:\n",
    "            D_max = D_current\n",
    "        fg_rank += 1\n",
    "        fg_cumulative = fg_rank / fg_size\n",
    "        D_current = abs(fg_cumulative - bg_cumulative)\n",
    "        if D_current > D_max:\n",
    "            D_max = D_current\n",
    "    pvalue = math.exp(n1_times_n2_times_mintwo * D_max * D_max / n1_plus_n2)\n",
    "    return D_max, pvalue\n",
    "\n",
    "def filter_stuff(args_dict, protein_ans_fg, p_values_corrected, foreground_ids_arr_of_string, funcEnum_count_foreground, year_arr, p_values, indices_arr, ENSP_2_functionEnumArray_dict, cond_filter, etype_cond_dict, cond_PMIDs, cond_etypes_with_ontology, cond_etypes_rem_foreground_ids, over_under_int_arr):\n",
    "    FDR_cutoff, p_value_cutoff = args_dict[\"FDR_cutoff\"], args_dict[\"p_value_cutoff\"]\n",
    "    cond_filter = (p_values_corrected <= FDR_cutoff) & (p_values <= p_value_cutoff)\n",
    "    ### remove terms with only a single annotation\n",
    "    if args_dict[\"filter_foreground_count_one\"] is True:\n",
    "        cond_filter &= funcEnum_count_foreground > 1\n",
    "    else:  # remove terms without any annotation\n",
    "        cond_filter &= funcEnum_count_foreground > 0\n",
    "\n",
    "    ### overrepresented/underrepresented/both\n",
    "    o_or_u_or_both_encoding = args_dict[\"o_or_u_or_both_encoding\"]\n",
    "    if o_or_u_or_both_encoding == 1: # overrepresented\n",
    "        cond_o_or_u_or_both = over_under_int_arr == 1\n",
    "    elif o_or_u_or_both_encoding == 2: # underrepresented\n",
    "        cond_o_or_u_or_both = over_under_int_arr == 2\n",
    "    elif o_or_u_or_both_encoding == 0: # both\n",
    "        cond_o_or_u_or_both = over_under_int_arr > 0\n",
    "    else:\n",
    "        pass # should not happen\n",
    "    cond_filter &= cond_o_or_u_or_both\n",
    "    filter_PMID_top_n = args_dict[\"filter_PMID_top_n\"]\n",
    "    if filter_PMID_top_n is not None:\n",
    "        cond_PMID_2_filter = cond_filter & etype_cond_dict[\"cond_56\"]  # -56\n",
    "        df_PMID = pd.DataFrame({\"foreground_count\": funcEnum_count_foreground[cond_PMID_2_filter].view(), \"year\": year_arr[cond_PMID_2_filter].view(), \"p_value\": p_values[cond_PMID_2_filter].view(), \"FDR\": p_values_corrected[cond_PMID_2_filter].view(), \"indices_arr\": indices_arr[cond_PMID_2_filter].view()})\n",
    "        indices_PMID = df_PMID.sort_values([\"FDR\", \"p_value\", \"year\", \"foreground_count\"], ascending=[True, True, False, False])[\"indices_arr\"].values[:filter_PMID_top_n]\n",
    "        for index_ in indices_PMID:\n",
    "            cond_PMIDs[index_] = True\n",
    "    else:  # since no filtering use all PMIDs\n",
    "        cond_PMIDs = cond_filter & etype_cond_dict[\"cond_56\"]\n",
    "    cond_etypes_with_ontology_filtered = cond_etypes_with_ontology & cond_filter  # {-21, -22, -23, -51, -57}\n",
    "    # entity_types_with_ontology = {-20, -21, -22, -23, -25, -26, -51, -57} # Interpro has ontology, but omitted here to turn off filter_parents functionality\n",
    "    cond_etypes_rem_foreground_ids_filtered = cond_etypes_rem_foreground_ids & cond_filter  # remaining etypes -52, -53, -54, -55\n",
    "    cond_IDs_2_query = (cond_PMIDs | cond_etypes_with_ontology_filtered | cond_etypes_rem_foreground_ids_filtered)\n",
    "    ### get foreground IDs of relevant subset --> array for entire data set\n",
    "    ## exclude TextMining KS functionEnumerations since these are probably not very informative and we need performance --> don't exclude\n",
    "#     if not KS_etypes_FG_IDs:\n",
    "#         cond_IDs_2_query = cond_IDs_2_query & ~cond_KS_etypes # commented on purpose since STRING needs these\n",
    "    funcEnum_indices_for_IDs = indices_arr[cond_IDs_2_query]\n",
    "    foreground_ids_arr_of_string = map_funcEnum_2_ENSPs(protein_ans_fg, ENSP_2_functionEnumArray_dict, funcEnum_indices_for_IDs, foreground_ids_arr_of_string)\n",
    "#     if not KS_etypes_FG_IDs:\n",
    "#         foreground_ids_arr_of_string[cond_KS_etypes] = \"\" # commented out for STRING\n",
    "    return foreground_ids_arr_of_string, funcEnum_indices_for_IDs, cond_etypes_with_ontology_filtered, cond_etypes_rem_foreground_ids_filtered, cond_filter\n",
    "\n",
    "\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "cdef int KolmogorovSmirnov_sparse_cy(FunctionEnum_2_Scores_dict, unsigned int foreground_n, unsigned int background_n, unsigned int [::1] fg_scores_matrix_data, int [::1] fg_scores_matrix_indptr, unsigned int [::1] bg_scores_matrix_data, int [::1] bg_scores_matrix_indptr, double[::1] p_values, cond_multitest, double[::1] effectSizes, double p_value_cutoff, unsigned int[::1] funcEnum_count_foreground, unsigned int[::1] funcEnum_count_background, unsigned int[::1] over_under_int_arr, unsigned int o_or_u_or_both_encoding, enrichment_method, filter_foreground_count_one, debug=False):\n",
    "    cdef:\n",
    "        int bg_rank_temp\n",
    "        unsigned int median_index, num_half_bg, num_half_fg, num_zeros_2_fill_bg, num_zeros_2_fill_fg, fg_size_plus_bg_size, funcEnum, bg_index, len_fg_scores_matrix_indptr, index_col_start_fg, index_col_stop_fg, index_col_start_bg, index_col_stop_bg, num_fg_vals, num_bg_vals, fg_val, bg_val, fg_rank, bg_rank\n",
    "        double fg_size_times_bg_size_times_mintwo, pvalue, D_max_abs, D_current_abs, D_current_absfg_cumulative, bg_cumulative, median_fg, median_bg\n",
    "        unsigned int[::1] fg_values, bg_values\n",
    "    fg_size_plus_bg_size = foreground_n + background_n\n",
    "    fg_size_times_bg_size_times_mintwo = -2.0 * foreground_n * background_n\n",
    "    len_fg_scores_matrix_indptr = fg_scores_matrix_indptr.shape[0]\n",
    "    for funcEnum in range(len_fg_scores_matrix_indptr - 1):\n",
    "        index_col_start_fg = fg_scores_matrix_indptr[funcEnum]\n",
    "        index_col_stop_fg = fg_scores_matrix_indptr[funcEnum + 1]\n",
    "        if index_col_start_fg == index_col_stop_fg:\n",
    "            continue # column is empty\n",
    "        elif filter_foreground_count_one and (index_col_stop_fg - index_col_start_fg) == 1:\n",
    "            continue\n",
    "        else:\n",
    "            fg_values = fg_scores_matrix_data[index_col_start_fg:index_col_stop_fg]\n",
    "\n",
    "        if enrichment_method == \"genome\": # is pre-sorted\n",
    "            try:\n",
    "                bg_values = FunctionEnum_2_Scores_dict[funcEnum]\n",
    "            except KeyError:\n",
    "                continue\n",
    "            num_bg_vals = bg_values.shape[0]\n",
    "            if num_bg_vals == 0:\n",
    "                continue\n",
    "        else:\n",
    "            index_col_start_bg = bg_scores_matrix_indptr[funcEnum]\n",
    "            index_col_stop_bg = bg_scores_matrix_indptr[funcEnum + 1]\n",
    "            if index_col_start_bg == index_col_stop_bg:\n",
    "                continue # column is empty\n",
    "            else:\n",
    "                bg_values = bg_scores_matrix_data[index_col_start_bg:index_col_stop_bg]\n",
    "            bg_values = np.sort(bg_values)\n",
    "            num_bg_vals = bg_values.shape[0]\n",
    "        fg_values = np.sort(fg_values)\n",
    "        num_fg_vals = fg_values.shape[0]\n",
    "        num_zeros_2_fill_fg = foreground_n - num_fg_vals\n",
    "        num_zeros_2_fill_bg = background_n - num_bg_vals\n",
    "        fg_rank, bg_rank, D_max_abs = 0, 0, 0\n",
    "        while fg_rank < num_fg_vals:\n",
    "            fg_val = fg_values[fg_rank]\n",
    "            fg_cumulative = (fg_rank + num_zeros_2_fill_fg) / foreground_n\n",
    "            bg_rank_temp = 0\n",
    "            for bg_index in range(bg_rank, num_bg_vals):\n",
    "                bg_val = bg_values[bg_index]\n",
    "                if fg_val <= bg_val:\n",
    "                    bg_rank = bg_rank_temp + bg_rank\n",
    "                    break\n",
    "                bg_rank_temp += 1\n",
    "\n",
    "            bg_cumulative = (bg_rank + num_zeros_2_fill_bg + 1) / background_n\n",
    "            D_current_abs = abs(fg_cumulative - bg_cumulative)\n",
    "            if D_current_abs > D_max_abs:\n",
    "                D_max_abs = D_current_abs\n",
    "\n",
    "            fg_rank += 1\n",
    "            fg_cumulative = (fg_rank + num_zeros_2_fill_fg) / foreground_n\n",
    "            D_current_abs = abs(fg_cumulative - bg_cumulative)\n",
    "            if D_current_abs > D_max_abs:\n",
    "                D_max_abs = D_current_abs\n",
    "        pvalue = math.exp(fg_size_times_bg_size_times_mintwo * D_max_abs * D_max_abs / fg_size_plus_bg_size)\n",
    "        if o_or_u_or_both_encoding != 0:\n",
    "            pvalue /= 2\n",
    "        num_half_fg = int(round((num_fg_vals + num_zeros_2_fill_fg)/2)) # index at half of fg\n",
    "        if num_half_fg > num_zeros_2_fill_fg:\n",
    "            median_index = int(num_half_fg - num_zeros_2_fill_fg)\n",
    "            median_fg = fg_values[median_index]\n",
    "        else:\n",
    "            median_fg = 0\n",
    "        num_half_bg = int(round((num_bg_vals + num_zeros_2_fill_bg)/2))\n",
    "        if num_half_bg > num_zeros_2_fill_bg:\n",
    "            median_index = int(num_half_bg - num_zeros_2_fill_bg)\n",
    "            median_bg = bg_values[median_index]\n",
    "        else:\n",
    "            median_bg = 0\n",
    "        is_greater = median_fg > median_bg # since rank based this is inverted\n",
    "\n",
    "        if pvalue <= p_value_cutoff:\n",
    "            p_values[funcEnum] = pvalue\n",
    "            effectSizes[funcEnum] = D_max_abs\n",
    "            if is_greater: # overrepresented\n",
    "                over_under_int_arr[funcEnum] = 1\n",
    "            else: # underrepresented\n",
    "                over_under_int_arr[funcEnum] = 2\n",
    "        cond_multitest[funcEnum] = True\n",
    "        funcEnum_count_foreground[funcEnum] = num_fg_vals\n",
    "        funcEnum_count_background[funcEnum] = num_bg_vals\n",
    "    return 0\n",
    "\n",
    "def KolmogorovSmirnov_scipy(foreground_n, background_n, funcEnum_2_scores_dict_fg, funcEnum_2_scores_dict_bg, p_values, cond_multitest, effectSizes, p_value_cutoff, funcEnum_count_foreground, funcEnum_count_background, over_under_int_arr, o_or_u_or_both_encoding, fill_zeros=True):\n",
    "    for funcEnum, scores_fg in funcEnum_2_scores_dict_fg.items():\n",
    "        funcEnum_count_foreground[funcEnum] = sum(scores_fg > 0) # len(scores_fg) # don't count Zeros\n",
    "        # number of scores, important for BH (that this does not equal 0 or nan)\n",
    "        scores_fg = list(scores_fg) # already filled with 0\n",
    "        try:\n",
    "            scores_bg = funcEnum_2_scores_dict_bg[funcEnum]\n",
    "            funcEnum_count_background[funcEnum] = sum(scores_bg > 0)\n",
    "            scores_bg = list(scores_bg)\n",
    "        except KeyError: # funcEnum not in background\n",
    "            continue\n",
    "        len_scores_fg = len(scores_fg)\n",
    "        if fill_zeros:\n",
    "            number_of_zeros_2_fill = foreground_n - len_scores_fg\n",
    "            if number_of_zeros_2_fill > 0:\n",
    "                scores_fg = [0]*number_of_zeros_2_fill + scores_fg\n",
    "        len_scores_bg = len(scores_bg)\n",
    "        if fill_zeros:\n",
    "            number_of_zeros_2_fill = background_n - len_scores_bg\n",
    "            if number_of_zeros_2_fill > 0:\n",
    "                scores_bg = [0]*number_of_zeros_2_fill + scores_bg\n",
    "        statistic, pvalue = stats.ks_2samp(scores_fg, scores_bg, alternative=\"two-sided\", mode=\"asymp\")\n",
    "        if pvalue <= p_value_cutoff:\n",
    "            p_values[funcEnum] = pvalue\n",
    "            effectSizes[funcEnum] = statistic\n",
    "            is_greater = np.median(scores_fg) > np.median(scores_bg)\n",
    "            ### use all values since test is two-tailed (and multiple testing had to be done)\n",
    "            # filter for overrepresented/underrepresented terms\n",
    "            if is_greater: # overrepresented\n",
    "                over_under_int_arr[funcEnum] = 1\n",
    "            else:\n",
    "                over_under_int_arr[funcEnum] = 2 # under\n",
    "        cond_multitest[funcEnum] = True\n",
    "\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "cdef int KolmogorovSmirnov_sparse_scipy(FunctionEnum_2_Scores_dict, unsigned int foreground_n, unsigned int background_n, unsigned int [::1] fg_scores_matrix_data, int [::1] fg_scores_matrix_indptr, unsigned int [::1] bg_scores_matrix_data, int [::1] bg_scores_matrix_indptr, double[::1] p_values, cond_multitest, double[::1] effectSizes, double p_value_cutoff, unsigned int[::1] funcEnum_count_foreground, unsigned int[::1] funcEnum_count_background, unsigned int[::1] over_under_int_arr, unsigned int o_or_u_or_both_encoding, enrichment_method, filter_foreground_count_one, debug=False):\n",
    "    cdef:\n",
    "        int bg_rank_temp, n1, n2\n",
    "        unsigned int median_index, num_half_bg, num_half_fg, num_zeros_2_fill_bg, num_zeros_2_fill_fg, fg_size_plus_bg_size, funcEnum, bg_index, len_fg_scores_matrix_indptr, index_col_start_fg, index_col_stop_fg, index_col_start_bg, index_col_stop_bg, num_fg_vals, num_bg_vals, fg_val, bg_val, fg_rank, bg_rank\n",
    "        double fg_size_times_bg_size_times_mintwo, p_value, D, bg_cumulative, median_fg, median_bg\n",
    "        unsigned int[::1] fg_values, bg_values\n",
    "    fg_size_plus_bg_size = foreground_n + background_n\n",
    "    fg_size_times_bg_size_times_mintwo = -2.0 * foreground_n * background_n\n",
    "    len_fg_scores_matrix_indptr = fg_scores_matrix_indptr.shape[0]\n",
    "    for funcEnum in range(len_fg_scores_matrix_indptr - 1):\n",
    "        index_col_start_fg = fg_scores_matrix_indptr[funcEnum]\n",
    "        index_col_stop_fg = fg_scores_matrix_indptr[funcEnum + 1]\n",
    "        if index_col_start_fg == index_col_stop_fg:\n",
    "            continue # column is empty\n",
    "        elif filter_foreground_count_one and (index_col_stop_fg - index_col_start_fg) == 1:\n",
    "            continue\n",
    "        else:\n",
    "            fg_values = fg_scores_matrix_data[index_col_start_fg:index_col_stop_fg]\n",
    "\n",
    "        if enrichment_method == \"genome\": # is pre-sorted\n",
    "            try:\n",
    "                bg_values = FunctionEnum_2_Scores_dict[funcEnum]\n",
    "            except KeyError:\n",
    "                continue\n",
    "            num_bg_vals = bg_values.shape[0]\n",
    "            if num_bg_vals == 0:\n",
    "                continue\n",
    "        else:\n",
    "            index_col_start_bg = bg_scores_matrix_indptr[funcEnum]\n",
    "            index_col_stop_bg = bg_scores_matrix_indptr[funcEnum + 1]\n",
    "            if index_col_start_bg == index_col_stop_bg:\n",
    "                continue # column is empty\n",
    "            else:\n",
    "                bg_values = bg_scores_matrix_data[index_col_start_bg:index_col_stop_bg]\n",
    "            bg_values = np.sort(bg_values)\n",
    "            num_bg_vals = bg_values.shape[0]\n",
    "        fg_values = np.sort(fg_values)\n",
    "        num_fg_vals = fg_values.shape[0]\n",
    "        num_zeros_2_fill_fg = foreground_n - num_fg_vals\n",
    "        num_zeros_2_fill_bg = background_n - num_bg_vals\n",
    "        fg_values_with_zeros = np.concatenate((np.zeros((num_zeros_2_fill_fg,), dtype=variables.dtype_TM_score), fg_values))\n",
    "        bg_values_with_zeros = np.concatenate((np.zeros((num_zeros_2_fill_bg,), dtype=variables.dtype_TM_score), bg_values))\n",
    "        n1 = fg_values_with_zeros.shape[0]\n",
    "        n2 = bg_values_with_zeros.shape[0]\n",
    "        data_all = np.concatenate([fg_values_with_zeros, bg_values_with_zeros])\n",
    "        # using searchsorted solves equal data problem\n",
    "        cdf1 = np.searchsorted(fg_values_with_zeros, data_all, side='right') / n1\n",
    "        cdf2 = np.searchsorted(bg_values_with_zeros, data_all, side='right') / n2\n",
    "        cdf_diff = cdf1 - cdf2\n",
    "        minS = -np.min(cdf_diff)\n",
    "        maxS = np.max(cdf_diff)\n",
    "        D = max(minS, maxS)\n",
    "        p_value = math.exp(-2.0 * n1 * n2 * D * D / ( n1 + n2)) * 2\n",
    "        if p_value > 1:\n",
    "            p_value = 1\n",
    "        if p_value < 0:\n",
    "            p_value = 0\n",
    "        if maxS < minS: # inverted since scores not ranks\n",
    "            is_greater = True\n",
    "        else:\n",
    "            is_greater = False\n",
    "        if p_value <= p_value_cutoff:\n",
    "            p_values[funcEnum] = p_value\n",
    "            effectSizes[funcEnum] = D\n",
    "            if is_greater: # overrepresented\n",
    "                over_under_int_arr[funcEnum] = 1\n",
    "            else: # underrepresented\n",
    "                over_under_int_arr[funcEnum] = 2\n",
    "        cond_multitest[funcEnum] = True\n",
    "        funcEnum_count_foreground[funcEnum] = num_fg_vals\n",
    "        funcEnum_count_background[funcEnum] = num_bg_vals\n",
    "    return 0\n",
    "\n",
    "def run_characterize_foreground_cy(ui, preloaded_objects_per_analysis, static_preloaded_objects, low_memory=False):\n",
    "    if not low_memory:\n",
    "        # ENSP_2_functionEnumArray_dict, year_arr, hierlevel_arr, entitytype_arr, functionalterm_arr, indices_arr, description_arr, category_arr, etype_2_minmax_funcEnum, function_enumeration_len, etype_cond_dict, etype_2_num_functions_dict, taxid_2_proteome_count, taxid_2_tuple_funcEnum_index_2_associations_counts, lineage_dict_enum, blacklisted_terms_bool_arr, cond_etypes_with_ontology, cond_etypes_rem_foreground_ids, kegg_taxid_2_acronym_dict, goslimtype_2_cond_dict, ENSP_2_rowIndex_dict, rowIndex_2_ENSP_dict, CSC_ENSPencoding_2_FuncEnum, CSR_ENSPencoding_2_FuncEnum, Taxid_2_FunctionEnum_2_Scores_dict = static_preloaded_objects\n",
    "        ENSP_2_functionEnumArray_dict, year_arr, hierlevel_arr, entitytype_arr, functionalterm_arr, indices_arr, description_arr, category_arr, etype_2_minmax_funcEnum, function_enumeration_len, etype_cond_dict, etype_2_num_functions_dict, taxid_2_proteome_count, taxid_2_tuple_funcEnum_index_2_associations_counts, lineage_dict_enum, blacklisted_terms_bool_arr, cond_etypes_with_ontology, cond_etypes_rem_foreground_ids, kegg_taxid_2_acronym_dict, goslimtype_2_cond_dict = static_preloaded_objects\n",
    "    else:  # missing: ENSP_2_functionEnumArray_dict\n",
    "        # year_arr, hierlevel_arr, entitytype_arr, functionalterm_arr, indices_arr, description_arr, category_arr, etype_2_minmax_funcEnum, function_enumeration_len, etype_cond_dict, etype_2_num_functions_dict, taxid_2_proteome_count, taxid_2_tuple_funcEnum_index_2_associations_counts, lineage_dict_enum, blacklisted_terms_bool_arr, cond_etypes_with_ontology, cond_etypes_rem_foreground_ids, kegg_taxid_2_acronym_dict, goslimtype_2_cond_dict, ENSP_2_rowIndex_dict, rowIndex_2_ENSP_dict, CSC_ENSPencoding_2_FuncEnum, CSR_ENSPencoding_2_FuncEnum, Taxid_2_FunctionEnum_2_Scores_dict = static_preloaded_objects\n",
    "        year_arr, hierlevel_arr, entitytype_arr, functionalterm_arr, indices_arr, description_arr, category_arr, etype_2_minmax_funcEnum, function_enumeration_len, etype_cond_dict, etype_2_num_functions_dict, taxid_2_proteome_count, taxid_2_tuple_funcEnum_index_2_associations_counts, lineage_dict_enum, blacklisted_terms_bool_arr, cond_etypes_with_ontology, cond_etypes_rem_foreground_ids, kegg_taxid_2_acronym_dict, goslimtype_2_cond_dict = static_preloaded_objects\n",
    "    foreground_ids_arr_of_string, background_ids_arr_of_string, funcEnum_count_foreground, funcEnum_count_background, p_values, p_values_corrected, cond_multitest, blacklisted_terms_bool_arr_temp, cond_terms_reduced_with_ontology, cond_filter, cond_PMIDs, effectSizes, over_under_int_arr, over_under_arr_of_string = preloaded_objects_per_analysis\n",
    "    em = ui.enrichment_method\n",
    "    foreground_n = ui.get_foreground_n()\n",
    "    args_dict = ui.args_dict\n",
    "    filter_foreground_count_one = args_dict[\"filter_foreground_count_one\"]\n",
    "    cols_2_return_sort_order = variables.cols_sort_order_characterize_foreground[:]\n",
    "\n",
    "    protein_ans_fg = ui.get_foreground_an_set()\n",
    "    if low_memory:\n",
    "        ENSP_2_functionEnumArray_dict = query.get_functionEnumArray_from_proteins(ui.get_all_individual_AN(), dict_2_array=True)\n",
    "    ### add protein groups to ENSP_2_functionEnumArray_dict\n",
    "    ENSP_2_functionEnumArray_dict = add_protein_groups_to_ENSP_2_functionEnumArray_dict(ENSP_2_functionEnumArray_dict, ui.get_all_unique_proteinGroups())\n",
    "\n",
    "    ## count foreground\n",
    "    count_all_terms(ENSP_2_functionEnumArray_dict, protein_ans_fg, funcEnum_count_foreground)\n",
    "\n",
    "    ## limit to given entity types\n",
    "    cond_limit_2_entity_type = limit_to_entity_types(args_dict[\"limit_2_entity_type\"], function_enumeration_len, etype_cond_dict, funcEnum_count_foreground)\n",
    "    limit_to_go_subset(etype_cond_dict, args_dict[\"go_slim_subset\"], goslimtype_2_cond_dict, funcEnum_count_foreground)\n",
    "\n",
    "#     ### Jensenlab Scores KS test\n",
    "#     cond_KS_etypes = etype_cond_dict[\"cond_25\"] | etype_cond_dict[\"cond_26\"] | etype_cond_dict[\"cond_20\"]\n",
    "#     funcEnums_2_include_set = set(indices_arr[cond_KS_etypes & cond_limit_2_entity_type])\n",
    "\n",
    "    # orig\n",
    "#     if orig:\n",
    "#         funcEnum_2_scores_dict_fg = collect_scores_per_term_characterize_foreground(protein_ans_fg, ENSP_2_tuple_funcEnum_score_dict, funcEnums_2_include_set, score_cutoff=args_dict[\"score_cutoff\"])\n",
    "#         for funcEnum, scores_fg in funcEnum_2_scores_dict_fg.items():\n",
    "#             funcEnum_count_foreground[funcEnum] = len(scores_fg)\n",
    "    # new CSC version\n",
    "#     else:\n",
    "\n",
    "#     fg_scores_matrix, list_of_rowIndices_fg = slice_ScoresMatrix_for_given_ENSP(protein_ans_fg, ENSP_2_rowIndex_dict, CSC_ENSPencoding_2_FuncEnum)\n",
    "#     fg_scores_matrix_data = fg_scores_matrix.data\n",
    "#     fg_scores_matrix_indptr = fg_scores_matrix.indptr\n",
    "#     if fg_scores_matrix_data.size > 0:\n",
    "#         set_fg_counts(fg_scores_matrix_data, fg_scores_matrix_indptr, funcEnum_count_foreground, filter_foreground_count_one)\n",
    "#         # add_funcEnums_2_dict(protein_ans_fg, ENSP_2_functionEnumArray_dict, ENSP_2_tuple_funcEnum_score_dict)\n",
    "#         add_funcEnums_2_dict_CSC(protein_ans_fg, ENSP_2_functionEnumArray_dict, ENSP_2_rowIndex_dict, CSR_ENSPencoding_2_FuncEnum)\n",
    "\n",
    "    ### calc ratio in foreground, count foreground / len(protein_ans)\n",
    "    ratio_in_foreground = funcEnum_count_foreground / foreground_n\n",
    "\n",
    "    ### concatenate filtered results\n",
    "    if filter_foreground_count_one:\n",
    "        cond_2_return = funcEnum_count_foreground > 1\n",
    "    else:\n",
    "        cond_2_return = funcEnum_count_foreground >= 1\n",
    "\n",
    "    ### limit PMID results\n",
    "    filter_PMID_top_n = args_dict[\"filter_PMID_top_n\"]\n",
    "    if filter_PMID_top_n is not None:\n",
    "        cond_PMID_2_filter = cond_2_return & etype_cond_dict[\"cond_56\"]\n",
    "        df_PMID = pd.DataFrame({\"foreground_count\": funcEnum_count_foreground[cond_PMID_2_filter].view(), \"year\": year_arr[cond_PMID_2_filter].view(), \"indices_arr\": indices_arr[cond_PMID_2_filter].view()})\n",
    "        indices_PMID = df_PMID.sort_values([\"foreground_count\", \"year\"], ascending=[False, False])[\"indices_arr\"].values[:filter_PMID_top_n]\n",
    "        # set all PMIDs to False and then include only those that were selected\n",
    "        cond_2_return[etype_cond_dict[\"cond_56\"]] = False\n",
    "        for index_ in indices_PMID:\n",
    "            cond_2_return[index_] = True\n",
    "    ### exclude blacklisted terms\n",
    "#     print(len(cond_2_return), sum(cond_2_return))    \n",
    "    cond_2_return[blacklisted_terms_bool_arr > 0] = False\n",
    "#     print(blacklisted_terms_bool_arr)\n",
    "#     print(len(cond_2_return), sum(cond_2_return))\n",
    "\n",
    "    try:\n",
    "        privileged = args_dict[\"privileged\"]\n",
    "    except KeyError:\n",
    "        privileged = False\n",
    "    if not privileged:\n",
    "        # remove KEGG unless privileged\n",
    "        cond_kegg = etype_cond_dict[\"cond_52\"]\n",
    "        cond_2_return = cond_2_return & ~cond_kegg\n",
    "\n",
    "    funcEnum_indices_for_IDs = indices_arr[cond_2_return]\n",
    "    foreground_ids_arr_of_string = map_funcEnum_2_ENSPs(protein_ans_fg, ENSP_2_functionEnumArray_dict, funcEnum_indices_for_IDs, foreground_ids_arr_of_string)\n",
    "    if not low_memory:\n",
    "        df_2_return = pd.DataFrame({\"term\": functionalterm_arr[cond_2_return].view(),\n",
    "                                    \"hierarchical_level\": hierlevel_arr[cond_2_return].view(),\n",
    "                                    \"category\": category_arr[cond_2_return].view(),\n",
    "                                    \"etype\": entitytype_arr[cond_2_return].view(),\n",
    "                                    \"description\": description_arr[cond_2_return].view(),\n",
    "                                    \"year\": year_arr[cond_2_return].view(),\n",
    "                                    \"ratio_in_FG\": ratio_in_foreground[cond_2_return].view(),\n",
    "                                    \"FG_ids\": foreground_ids_arr_of_string[cond_2_return].view(),\n",
    "                                    \"FG_count\": funcEnum_count_foreground[cond_2_return].view()})\n",
    "    else:\n",
    "        df_2_return = pd.DataFrame({\"term\": functionalterm_arr[cond_2_return].view(),\n",
    "                                    \"hierarchical_level\": hierlevel_arr[cond_2_return].view(),\n",
    "                                    \"etype\": entitytype_arr[cond_2_return].view(),\n",
    "                                    \"year\": year_arr[cond_2_return].view(),\n",
    "                                    \"ratio_in_FG\": ratio_in_foreground[cond_2_return].view(),\n",
    "                                    \"FG_IDs\": foreground_ids_arr_of_string[cond_2_return].view(),\n",
    "                                    \"FG_count\": funcEnum_count_foreground[cond_2_return].view(),\n",
    "                                    \"funcEnum\": indices_arr[cond_2_return].view()})\n",
    "        df_2_return[\"category\"] = df_2_return[\"etype\"].apply(lambda etype: variables.entityType_2_functionType_dict[etype])\n",
    "        funcEnum_2_description_dict = query.get_function_description_from_funcEnum(indices_arr[cond_2_return].tolist())\n",
    "        df_2_return[\"description\"] = df_2_return[\"funcEnum\"].apply(lambda funcEnum: funcEnum_2_description_dict[funcEnum])\n",
    "    #cols_2_return_sort_order = ['etype', 'term', 'hierarchical_level', 'description', 'year','ratio_in_FG', 'FG_count', 'FG_n', 'FG_IDs', 'funcEnum', 'category']\n",
    "    df_2_return = ui.translate_primary_back_to_secondary(df_2_return)\n",
    "    df_2_return[\"FG_n\"] = foreground_n\n",
    "    # rank everything correctly except PMIDs, \"year\"-column will only affect PMIDs\n",
    "    df_2_return = df_2_return.sort_values([\"etype\", \"year\", \"FG_count\"], ascending=[True, False, False]).reset_index(drop=True)\n",
    "    cond_PMIDs = df_2_return[\"etype\"] == -56\n",
    "    df_2_return.loc[~cond_PMIDs, \"rank\"] = df_2_return[~cond_PMIDs].groupby(\"etype\")[\"FG_count\"].rank(ascending=False, method=\"first\").fillna(value=df_2_return.shape[0])\n",
    "    df_2_return.loc[cond_PMIDs, \"rank\"] = df_2_return[cond_PMIDs].groupby(\"etype\")[\"year\"].rank(ascending=False, method=\"first\").fillna(value=df_2_return.shape[0])\n",
    "    df_2_return[\"rank\"] = df_2_return[\"rank\"].astype(int)\n",
    "    return df_2_return[cols_2_return_sort_order]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run ze function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fn_userinput = r\"/Users/dblyon/modules/cpr/agotool/data/exampledata/Example_Yeast_acetylation_abundance_correction.txt\"\n",
    "# os.path.basename(fn_userinput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "userinput 107 something wrong\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Userinput' object has no attribute 'foreground'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-beef05d7001f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_enrichment_cy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mncbi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mui\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreloaded_objects_per_analysis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatic_preloaded_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlow_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m             \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_enrichment_cy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mncbi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mui\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreloaded_objects_per_analysis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatic_preloaded_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlow_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m             \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"etype\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rank\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m_cython_magic_4bb8b936563368d3792e311942b2eb13.pyx\u001b[0m in \u001b[0;36m_cython_magic_4bb8b936563368d3792e311942b2eb13.run_enrichment_cy\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/modules/cpr/agotool/app/python/userinput.py\u001b[0m in \u001b[0;36mget_background_n\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    408\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ERROR taxid\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"taxid:\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"taxid\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menrichment_method\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"abundance_correction\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# same as foreground\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforeground\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    411\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menrichment_method\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"compare_samples\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# simply background to compare to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackground\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Userinput' object has no attribute 'foreground'"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(userinput)\n",
    "ENSP_2_tuple_funcEnum_score_dict = None\n",
    "#######################\n",
    "### examples\n",
    "# foreground_input = [\"HBA_HUMAN\", \"HBB_HUMAN\", \"HBD_HUMAN\", \"HBE_HUMAN\"] # example 1: Human hemoglobin, genome\n",
    "# example 2: Yeast acetylation, abundance_correction. Example_1_Yeast_acetylation_abundance_correction.txt\n",
    "# example 3: compare_samples\n",
    "# human plasma liver cirrhosis Lili Niu\n",
    "# foreground_input = ['P05062;A0A024R145;A8K430;A0A087WXX2;Q8NHT3', 'Q08380;B4DVE1;A0A0S2Z3Y1;B3KP88;B4DDG4;B4DWA8;B4DI70', 'P04004;D9ZGG2;B7Z553', 'O95445', 'P01833', 'P43652', 'Q5SRP5']\n",
    "# mouse Insulin (STRING network )\n",
    "# foreground_input = ['10090.ENSMUSP00000005671', '10090.ENSMUSP00000020846', '10090.ENSMUSP00000022921', '10090.ENSMUSP00000028252', '10090.ENSMUSP00000056668', '10090.ENSMUSP00000061877', '10090.ENSMUSP00000084464', '10090.ENSMUSP00000088837', '10090.ENSMUSP00000099787', '10090.ENSMUSP00000099862', '10090.ENSMUSP00000104298']\n",
    "# mouse interferon (STRING network)\n",
    "# foreground_input = ['10090.ENSMUSP00000001036', '10090.ENSMUSP00000023689', '10090.ENSMUSP00000023693', '10090.ENSMUSP00000038121', '10090.ENSMUSP00000056720', '10090.ENSMUSP00000066743', '10090.ENSMUSP00000092581', '10090.ENSMUSP00000099842', '10090.ENSMUSP00000100872', '10090.ENSMUSP00000120525', '10090.ENSMUSP00000127921']\n",
    "#Q9R117\\nP33896\\nO35664\\nO35716\\nP01575\\nP42225\\nP07351\\nP52332\\nQ9WVL2\\nQ61179\\nQ61716\n",
    "# foreground_input = [\"ADH1_YEAST\", \"PDC1_YEAST\", \"PFKA1_YEAST\"]\n",
    "# foreground_input = [\"PGM1_YEAST\", \"G6PI_YEAST\", \"PMG2_YEAST\", \"CISY2_YEAST\"]\n",
    "############\n",
    "contiguous = True\n",
    "foreground_n = 300\n",
    "# foreground_input = sorted(get_random_human_ENSP(foreground_n, joined_for_web=False, contiguous=contiguous, UniProt_ID=True))\n",
    "# foreground_input = ['MEF2A_HUMAN', 'MEF2B_HUMAN', 'MEF2C_HUMAN', 'MEF2D_HUMAN', 'MEFV_HUMAN', 'MEG10_HUMAN', 'MEG11_HUMAN', 'MEGF6_HUMAN', 'MEGF8_HUMAN', 'MEGF9_HUMAN', 'MEI1_HUMAN', 'MEI4_HUMAN', 'MEIG1_HUMAN', 'MEIKN_HUMAN', 'MEIOB_HUMAN', 'MEIOC_HUMAN', 'MEIS1_HUMAN', 'MEIS2_HUMAN', 'MEIS3_HUMAN', 'MELK_HUMAN']\n",
    "from_file = True # read user input from file\n",
    "fn_userinput = r\"/Users/dblyon/modules/cpr/agotool/data/exampledata/Example_Yeast_acetylation_abundance_correction.txt\"\n",
    "fn_userinput = r\"/Users/dblyon/Downloads/agotoolquestions/ClpP2up_KEimputed_aGOtool.txt\"\n",
    "# fn_userinput = r\"/Users/dblyon/modules/cpr/agotool/data/exampledata/Example_1_Yeast_acetylation_foreground_only.txt\"\n",
    "# fn_userinput = r\"/Users/dblyon/modules/cpr/agotool/data/exampledata/Example_1.1_Yeast_acetylation_without_abundance.txt\"\n",
    "# foreground_input = [\"P69905\"]\n",
    "# foreground_input = corona\n",
    "\n",
    "enrichment_method = \"abundance_correction\" # \"\" \"abundance_correction\" \"compare_samples\" \"genome\" \"compare_groups\"\n",
    "args_dict = {}\n",
    "args_dict[\"enrichment_method\"] = enrichment_method\n",
    "args_dict[\"taxid\"] = 9606 # 9606 # 559292 Yeast\n",
    "args_dict[\"FDR_cutoff\"] = 0.05\n",
    "args_dict[\"p_value_cutoff\"] = 0.01\n",
    "args_dict[\"limit_2_entity_type\"] = None # \"-20;-25;-26\" #\"-21;-22;-23;-51;-52;-53;-54;-55;-56-57;-58\"\n",
    "args_dict[\"filter_PMID_top_n\"] = 100\n",
    "args_dict[\"filter_foreground_count_one\"] = True\n",
    "args_dict[\"filter_parents\"] = True\n",
    "args_dict[\"go_slim_subset\"] = None # \"generic\"\n",
    "args_dict[\"o_or_u_or_both\"] = \"both\" # \"both\" \"underrepresented\" \"overrepresented\"\n",
    "args_dict[\"multiple_testing_per_etype\"] = True\n",
    "args_dict[\"privileged\"] = True\n",
    "args_dict[\"score_cutoff\"] = 0\n",
    "# args_dict[\"foreground_replicates\"] = 10\n",
    "# args_dict[\"background_replicates\"] = 10\n",
    "taxid = args_dict[\"taxid\"]\n",
    "debug = False\n",
    "profile = False\n",
    "simplified_output = False\n",
    "args_dict[\"simplified_output\"] = simplified_output\n",
    "args_dict[\"STRING_beta\"] = False\n",
    "# KS_method = \"sparse_scipy\" # {\"scipy\", \"cy\", \"sparse_scipy\"}\n",
    "background_n = 300\n",
    "contiguous = True\n",
    "# background_input = sorted(get_random_human_ENSP(background_n, joined_for_web=False, contiguous=contiguous)) # background_input = ENSPs_homo\n",
    "# background_input = query.get_proteins_of_taxid(taxid, read_from_flat_files=True)\n",
    "# background_input = None\n",
    "if from_file:\n",
    "    ui = userinput.Userinput(pqo, fn_userinput, args_dict=args_dict)\n",
    "else:\n",
    "    ui = userinput.Userinput(pqo, fn=None, foreground_string=userinput.stringify_for_Userinput(foreground_input), background_string=userinput.stringify_for_Userinput(background_input), args_dict=args_dict)\n",
    "ncbi = pqo.ncbi\n",
    "preloaded_objects_per_analysis = pqo.get_preloaded_objects_per_analysis()\n",
    "\n",
    "if profile:\n",
    "    profile = line_profiler.LineProfiler(calc_pvalues_v2) # run_enrichment_cy, KolmogorovSmirnov_sparse_cy, KolmogorovSmirnov_sparse_cy_genome\n",
    "    profile.runcall(run_enrichment_cy, ENSP_2_tuple_funcEnum_score_dict, ncbi, ui, preloaded_objects_per_analysis, static_preloaded_objects, low_memory=True, debug=debug, KS_method=KS_method)\n",
    "    profile.print_stats()\n",
    "else:\n",
    "    if enrichment_method == \"characterize_foreground\":\n",
    "        df = run_characterize_foreground_cy(ui, preloaded_objects_per_analysis, static_preloaded_objects, low_memory=True)\n",
    "        df = df.sort_values([\"etype\", \"FG_count\"], ascending=[False, False])\n",
    "    else:\n",
    "        if debug:\n",
    "            df = run_enrichment_cy(ncbi, ui, preloaded_objects_per_analysis, static_preloaded_objects, low_memory=True, debug=debug)\n",
    "        else:\n",
    "            df = run_enrichment_cy(ncbi, ui, preloaded_objects_per_analysis, static_preloaded_objects, low_memory=True, debug=debug)\n",
    "            df = df.sort_values([\"etype\", \"rank\"], ascending=[False, True])\n",
    "            print(df.shape)\n",
    "            print(df.groupby(\"category\")[\"term\"].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'userinput' from '/Users/dblyon/modules/cpr/agotool/app/python/userinput.py'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(userinput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "taxid = random.choice(query.get_taxids())\n",
    "background = query.get_proteins_of_taxid(taxid)\n",
    "foreground = random.sample(background, 200)\n",
    "intensity = [str(ele) for ele in np.random.normal(size=len(background))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A0A2L0PPD5_VITS1 0.15 [ 5378  5401  5880  5881  6497  6498  7135  8224  8348  9324  9325 12485\n",
      " 13034 13347 13709 15735 24006 24207 24453 24454 24740 25932 26329 26846\n",
      " 26891 26992 26993 27986 29177 29236 29239 31993 32095 47048 47093 47345\n",
      " 47346 47363 47403 47531 47652 47697 47783 47788 47789 47790 47791 47792\n",
      " 47796 47797 49164 81983 85932]\n",
      "A0A2L0PNZ2_VITS1 0.09722222222222222 [ 5284  5303  5312  5370  5371  5378  5381  5383  6497  6498  6608  7135\n",
      "  8224  8713  8927 10382 12784 13034 13035 13046 13058 13347 13972 15735\n",
      " 17770 24006 24033 24096 26329 26846 26891 27495 27528 28387 29126 29298\n",
      " 29323 29324 29336 29337 29339 30955 33721 46918 46964 46997 47341 47349\n",
      " 47432 47491 47697 47788 47790 47796 47797 57230 91262]\n",
      "A0A2L0PMR4_VITS1 0.06896551724137931 [ 5284  5370  5371  5378  5381  5383  6497  6498  6608  7135  8224  8927\n",
      " 10382 12784 13034 13035 13046 13058 13347 13972 15735 17770 24006 24033\n",
      " 24096 26329 26846 26891 27331 27986 29298 29303 31032 31034 31412 31420\n",
      " 46784 46918 47036 47055 47125 47341 47349 47491 47697 47788 47789 47790\n",
      " 47791 47792 47796 47797 49447 53540 57752 67905 86722]\n",
      "Q8L311_VITS1 0.10714285714285714 [ 5378  6497  6498  6608  7135  8224 13034 13347 15735 24006 24453 24454\n",
      " 24740 25798 26329 26846 26891 27136 27867 27986 28153 28612 28732 28757\n",
      " 28758 28759 28913 29177 29253 29254 29256 29258 29836 29857 29867 31417\n",
      " 33253 33790 46848 46938 46987 47048 47055 47231 47345 47346 47652 47697\n",
      " 47788 47791 47792 47796 47797 48957 60338 68161 68162 79671 85642]\n",
      "A0A2L0PNY0_VITS1 0.10714285714285714 [ 5378  5383  6497  6498  6608  7135  8224 13034 13035 13347 15735 24006\n",
      " 24453 24454 24740 26329 26600 26846 26891 27986 29177 29217 29836 31032\n",
      " 31034 31412 31417 33253 33790 46938 46987 47048 47055 47345 47346 47652\n",
      " 47697 47788 47791 47792 47796 47797 48798 60442 77687 86592]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-522f2a683ff6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"FG_count\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"FG_n\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"BG_count\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"BG_n\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"FG_count\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"BG_count\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "enrichment_method = \"abundance_correction\"\n",
    "args_dict = {}\n",
    "args_dict[\"enrichment_method\"] = enrichment_method\n",
    "args_dict[\"taxid\"] = taxid\n",
    "args_dict[\"FDR_cutoff\"] = 1\n",
    "args_dict[\"p_value_cutoff\"] = 1\n",
    "args_dict[\"limit_2_entity_type\"] = None \n",
    "args_dict[\"filter_PMID_top_n\"] = 100\n",
    "args_dict[\"filter_foreground_count_one\"] = True\n",
    "args_dict[\"filter_parents\"] = True\n",
    "args_dict[\"go_slim_subset\"] = None\n",
    "args_dict[\"o_or_u_or_both_encoding\"] = 0\n",
    "args_dict[\"multiple_testing_per_etype\"] = True\n",
    "args_dict[\"privileged\"] = True\n",
    "args_dict[\"score_cutoff\"] = 0\n",
    "args_dict[\"num_bins\"] = 100\n",
    "args_dict[\"foreground_n\"] = None\n",
    "args_dict[\"background_n\"] = None\n",
    "args_dict[\"simplified_output\"] = False\n",
    "args_dict[\"foreground\"] = \"%0d\".join(foreground)\n",
    "args_dict[\"background\"] = \"%0d\".join(background)\n",
    "args_dict[\"background_intensity\"] = \"%0d\".join(intensity)\n",
    "preloaded_objects_per_analysis = pqo.get_preloaded_objects_per_analysis()\n",
    "ui = userinput.REST_API_input(pqo, args_dict=args_dict)\n",
    "df = run_enrichment_cy(ncbi, ui, preloaded_objects_per_analysis, static_preloaded_objects, low_memory=True, debug=debug)\n",
    "assert (df[\"FG_n\"] == df[\"BG_n\"]).all()\n",
    "assert (df[\"FG_count\"] <= df[\"FG_n\"]).all()\n",
    "assert (df[\"BG_count\"] <= df[\"BG_n\"]).all()\n",
    "assert (df[\"FG_count\"] <= df[\"BG_count\"]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.53012"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.15 + 0.09722 + 0.0689 + 0.107 + 0.107"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>hierarchical_level</th>\n",
       "      <th>description</th>\n",
       "      <th>year</th>\n",
       "      <th>over_under</th>\n",
       "      <th>p_value</th>\n",
       "      <th>FDR</th>\n",
       "      <th>effectSize</th>\n",
       "      <th>ratio_in_FG</th>\n",
       "      <th>ratio_in_BG</th>\n",
       "      <th>FG_count</th>\n",
       "      <th>FG_n</th>\n",
       "      <th>BG_count</th>\n",
       "      <th>BG_n</th>\n",
       "      <th>FG_IDs</th>\n",
       "      <th>s_value</th>\n",
       "      <th>rank</th>\n",
       "      <th>funcEnum</th>\n",
       "      <th>category</th>\n",
       "      <th>etype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>GO:0019538</td>\n",
       "      <td>5</td>\n",
       "      <td>protein metabolic process</td>\n",
       "      <td>-1</td>\n",
       "      <td>u</td>\n",
       "      <td>0.220052</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.025</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.040</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>8</td>\n",
       "      <td>200</td>\n",
       "      <td>A0A2L0PJZ5_VITS1;A0A2L0PQL5_VITS1;A0A2L0PQM0_V...</td>\n",
       "      <td>-0.016437</td>\n",
       "      <td>1</td>\n",
       "      <td>8828</td>\n",
       "      <td>Gene Ontology biological process</td>\n",
       "      <td>-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>GO:0045333</td>\n",
       "      <td>6</td>\n",
       "      <td>cellular respiration</td>\n",
       "      <td>-1</td>\n",
       "      <td>o</td>\n",
       "      <td>0.215217</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.005</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>A0A2L0PMR4_VITS1;A0A2L0PNY0_VITS1;A0A2L0PNZ2_V...</td>\n",
       "      <td>0.013342</td>\n",
       "      <td>2</td>\n",
       "      <td>13347</td>\n",
       "      <td>Gene Ontology biological process</td>\n",
       "      <td>-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GO:0006139</td>\n",
       "      <td>5</td>\n",
       "      <td>nucleobase-containing compound metabolic process</td>\n",
       "      <td>-1</td>\n",
       "      <td>o</td>\n",
       "      <td>0.382609</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.075</td>\n",
       "      <td>21</td>\n",
       "      <td>200</td>\n",
       "      <td>15</td>\n",
       "      <td>200</td>\n",
       "      <td>A0A2L0PID3_VITS1;A0A2L0PID8_VITS1;A0A2L0PIJ7_V...</td>\n",
       "      <td>0.012517</td>\n",
       "      <td>3</td>\n",
       "      <td>5407</td>\n",
       "      <td>Gene Ontology biological process</td>\n",
       "      <td>-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GO:0006091</td>\n",
       "      <td>4</td>\n",
       "      <td>generation of precursor metabolites and energy</td>\n",
       "      <td>-1</td>\n",
       "      <td>o</td>\n",
       "      <td>0.284097</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.010</td>\n",
       "      <td>6</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>A0A2L0PMR4_VITS1;A0A2L0PNY0_VITS1;A0A2L0PNZ2_V...</td>\n",
       "      <td>0.010931</td>\n",
       "      <td>4</td>\n",
       "      <td>5378</td>\n",
       "      <td>Gene Ontology biological process</td>\n",
       "      <td>-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>GO:0055114</td>\n",
       "      <td>3</td>\n",
       "      <td>oxidation-reduction process</td>\n",
       "      <td>-1</td>\n",
       "      <td>o</td>\n",
       "      <td>0.284097</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.010</td>\n",
       "      <td>6</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>A0A2L0PMR4_VITS1;A0A2L0PNH0_VITS1;A0A2L0PNY0_V...</td>\n",
       "      <td>0.010931</td>\n",
       "      <td>5</td>\n",
       "      <td>15735</td>\n",
       "      <td>Gene Ontology biological process</td>\n",
       "      <td>-21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          term  hierarchical_level  \\\n",
       "47  GO:0019538                   5   \n",
       "67  GO:0045333                   6   \n",
       "9   GO:0006139                   5   \n",
       "6   GO:0006091                   4   \n",
       "74  GO:0055114                   3   \n",
       "\n",
       "                                         description  year over_under  \\\n",
       "47                         protein metabolic process    -1          u   \n",
       "67                              cellular respiration    -1          o   \n",
       "9   nucleobase-containing compound metabolic process    -1          o   \n",
       "6     generation of precursor metabolites and energy    -1          o   \n",
       "74                       oxidation-reduction process    -1          o   \n",
       "\n",
       "     p_value  FDR  effectSize  ratio_in_FG  ratio_in_BG  FG_count  FG_n  \\\n",
       "47  0.220052  1.0      -0.025        0.015        0.040         3   200   \n",
       "67  0.215217  1.0       0.020        0.025        0.005         5   200   \n",
       "9   0.382609  1.0       0.030        0.105        0.075        21   200   \n",
       "6   0.284097  1.0       0.020        0.030        0.010         6   200   \n",
       "74  0.284097  1.0       0.020        0.030        0.010         6   200   \n",
       "\n",
       "    BG_count  BG_n                                             FG_IDs  \\\n",
       "47         8   200  A0A2L0PJZ5_VITS1;A0A2L0PQL5_VITS1;A0A2L0PQM0_V...   \n",
       "67         1   200  A0A2L0PMR4_VITS1;A0A2L0PNY0_VITS1;A0A2L0PNZ2_V...   \n",
       "9         15   200  A0A2L0PID3_VITS1;A0A2L0PID8_VITS1;A0A2L0PIJ7_V...   \n",
       "6          2   200  A0A2L0PMR4_VITS1;A0A2L0PNY0_VITS1;A0A2L0PNZ2_V...   \n",
       "74         2   200  A0A2L0PMR4_VITS1;A0A2L0PNH0_VITS1;A0A2L0PNY0_V...   \n",
       "\n",
       "     s_value  rank  funcEnum                          category  etype  \n",
       "47 -0.016437     1      8828  Gene Ontology biological process    -21  \n",
       "67  0.013342     2     13347  Gene Ontology biological process    -21  \n",
       "9   0.012517     3      5407  Gene Ontology biological process    -21  \n",
       "6   0.010931     4      5378  Gene Ontology biological process    -21  \n",
       "74  0.010931     5     15735  Gene Ontology biological process    -21  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A0A2L0PMR4_VITS1;A0A2L0PNY0_VITS1;A0A2L0PNZ2_VITS1;A0A2L0PPD5_VITS1;Q8L311_VITS1'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[67, \"FG_IDs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Please check the foreground you've provided. It seems we can't find anything to parse.\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ui.args_dict['ERROR foreground empty']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ui.check_parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>background</th>\n",
       "      <th>intensity</th>\n",
       "      <th>foreground</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [background, intensity, foreground]\n",
       "Index: []"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ui.df_orig.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>hierarchical_level</th>\n",
       "      <th>description</th>\n",
       "      <th>year</th>\n",
       "      <th>over_under</th>\n",
       "      <th>p_value</th>\n",
       "      <th>FDR</th>\n",
       "      <th>effectSize</th>\n",
       "      <th>ratio_in_FG</th>\n",
       "      <th>ratio_in_BG</th>\n",
       "      <th>FG_count</th>\n",
       "      <th>FG_n</th>\n",
       "      <th>BG_count</th>\n",
       "      <th>BG_n</th>\n",
       "      <th>FG_IDs</th>\n",
       "      <th>s_value</th>\n",
       "      <th>rank</th>\n",
       "      <th>funcEnum</th>\n",
       "      <th>category</th>\n",
       "      <th>etype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GO:0016020</td>\n",
       "      <td>2</td>\n",
       "      <td>membrane</td>\n",
       "      <td>-1</td>\n",
       "      <td>u</td>\n",
       "      <td>9.992662e-07</td>\n",
       "      <td>0.002762</td>\n",
       "      <td>-0.122667</td>\n",
       "      <td>0.048000</td>\n",
       "      <td>0.170667</td>\n",
       "      <td>18</td>\n",
       "      <td>375</td>\n",
       "      <td>64</td>\n",
       "      <td>375</td>\n",
       "      <td>Q7AP69;Q8Y3N6;Q8Y3U8;Q8Y4C8;Q8Y527;Q8Y7P9;Q8Y8...</td>\n",
       "      <td>-0.736039</td>\n",
       "      <td>1</td>\n",
       "      <td>24453</td>\n",
       "      <td>Gene Ontology cellular component</td>\n",
       "      <td>-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GO:0016021</td>\n",
       "      <td>5</td>\n",
       "      <td>integral component of membrane</td>\n",
       "      <td>-1</td>\n",
       "      <td>u</td>\n",
       "      <td>1.728198e-06</td>\n",
       "      <td>0.002762</td>\n",
       "      <td>-0.114667</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.154667</td>\n",
       "      <td>15</td>\n",
       "      <td>375</td>\n",
       "      <td>58</td>\n",
       "      <td>375</td>\n",
       "      <td>Q8Y3N6;Q8Y3U8;Q8Y527;Q8Y7P9;Q8Y868;Q8Y8H7;Q8Y8...</td>\n",
       "      <td>-0.660756</td>\n",
       "      <td>2</td>\n",
       "      <td>24454</td>\n",
       "      <td>Gene Ontology cellular component</td>\n",
       "      <td>-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GO:0071944</td>\n",
       "      <td>3</td>\n",
       "      <td>cell periphery</td>\n",
       "      <td>-1</td>\n",
       "      <td>u</td>\n",
       "      <td>1.476595e-05</td>\n",
       "      <td>0.010203</td>\n",
       "      <td>-0.074667</td>\n",
       "      <td>0.021333</td>\n",
       "      <td>0.096000</td>\n",
       "      <td>8</td>\n",
       "      <td>375</td>\n",
       "      <td>36</td>\n",
       "      <td>375</td>\n",
       "      <td>Q8Y3N6;Q8Y3U8;Q8Y527;Q8Y7P9;Q8Y833;Q8YAV5;P0DJ...</td>\n",
       "      <td>-0.360695</td>\n",
       "      <td>3</td>\n",
       "      <td>25932</td>\n",
       "      <td>Gene Ontology cellular component</td>\n",
       "      <td>-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GO:0005886</td>\n",
       "      <td>4</td>\n",
       "      <td>plasma membrane</td>\n",
       "      <td>-1</td>\n",
       "      <td>u</td>\n",
       "      <td>1.531462e-05</td>\n",
       "      <td>0.010203</td>\n",
       "      <td>-0.072000</td>\n",
       "      <td>0.018667</td>\n",
       "      <td>0.090667</td>\n",
       "      <td>7</td>\n",
       "      <td>375</td>\n",
       "      <td>34</td>\n",
       "      <td>375</td>\n",
       "      <td>Q8Y3N6;Q8Y3U8;Q8Y527;Q8Y7P9;Q8Y833;Q8YAV5;P0DJP3</td>\n",
       "      <td>-0.346672</td>\n",
       "      <td>4</td>\n",
       "      <td>24207</td>\n",
       "      <td>Gene Ontology cellular component</td>\n",
       "      <td>-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KW-0812</td>\n",
       "      <td>3</td>\n",
       "      <td>Transmembrane</td>\n",
       "      <td>-1</td>\n",
       "      <td>u</td>\n",
       "      <td>1.442517e-06</td>\n",
       "      <td>0.001694</td>\n",
       "      <td>-0.112000</td>\n",
       "      <td>0.034667</td>\n",
       "      <td>0.146667</td>\n",
       "      <td>13</td>\n",
       "      <td>375</td>\n",
       "      <td>55</td>\n",
       "      <td>375</td>\n",
       "      <td>Q8Y3N6;Q8Y3U8;Q8Y527;Q8Y7P9;Q8Y868;Q8Y8H7;Q8Y8...</td>\n",
       "      <td>-0.654178</td>\n",
       "      <td>1</td>\n",
       "      <td>47345</td>\n",
       "      <td>UniProt keywords</td>\n",
       "      <td>-51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         term  hierarchical_level                     description  year  \\\n",
       "1  GO:0016020                   2                        membrane    -1   \n",
       "2  GO:0016021                   5  integral component of membrane    -1   \n",
       "3  GO:0071944                   3                  cell periphery    -1   \n",
       "0  GO:0005886                   4                 plasma membrane    -1   \n",
       "4     KW-0812                   3                   Transmembrane    -1   \n",
       "\n",
       "  over_under       p_value       FDR  effectSize  ratio_in_FG  ratio_in_BG  \\\n",
       "1          u  9.992662e-07  0.002762   -0.122667     0.048000     0.170667   \n",
       "2          u  1.728198e-06  0.002762   -0.114667     0.040000     0.154667   \n",
       "3          u  1.476595e-05  0.010203   -0.074667     0.021333     0.096000   \n",
       "0          u  1.531462e-05  0.010203   -0.072000     0.018667     0.090667   \n",
       "4          u  1.442517e-06  0.001694   -0.112000     0.034667     0.146667   \n",
       "\n",
       "   FG_count  FG_n  BG_count  BG_n  \\\n",
       "1        18   375        64   375   \n",
       "2        15   375        58   375   \n",
       "3         8   375        36   375   \n",
       "0         7   375        34   375   \n",
       "4        13   375        55   375   \n",
       "\n",
       "                                              FG_IDs   s_value  rank  \\\n",
       "1  Q7AP69;Q8Y3N6;Q8Y3U8;Q8Y4C8;Q8Y527;Q8Y7P9;Q8Y8... -0.736039     1   \n",
       "2  Q8Y3N6;Q8Y3U8;Q8Y527;Q8Y7P9;Q8Y868;Q8Y8H7;Q8Y8... -0.660756     2   \n",
       "3  Q8Y3N6;Q8Y3U8;Q8Y527;Q8Y7P9;Q8Y833;Q8YAV5;P0DJ... -0.360695     3   \n",
       "0   Q8Y3N6;Q8Y3U8;Q8Y527;Q8Y7P9;Q8Y833;Q8YAV5;P0DJP3 -0.346672     4   \n",
       "4  Q8Y3N6;Q8Y3U8;Q8Y527;Q8Y7P9;Q8Y868;Q8Y8H7;Q8Y8... -0.654178     1   \n",
       "\n",
       "   funcEnum                          category  etype  \n",
       "1     24453  Gene Ontology cellular component    -22  \n",
       "2     24454  Gene Ontology cellular component    -22  \n",
       "3     25932  Gene Ontology cellular component    -22  \n",
       "0     24207  Gene Ontology cellular component    -22  \n",
       "4     47345                  UniProt keywords    -51  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7766643.143999999\n",
      "7766643.143999999\n"
     ]
    }
   ],
   "source": [
    "print(ui.background[\"intensity\"].min())\n",
    "print(ui.foreground[\"intensity\"].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# foreground_ids_arr_of_string, background_ids_arr_of_string, funcEnum_count_foreground, funcEnum_count_background, p_values, p_values_corrected, cond_multitest, blacklisted_terms_bool_arr_temp, cond_terms_reduced_with_ontology, cond_filter, cond_PMIDs, effectSizes, over_under_int_arr, over_under_arr_of_string = preloaded_objects_per_analysis\n",
    "len(\"\"\"foreground_ids_arr_of_string, background_ids_arr_of_string, funcEnum_count_foreground, funcEnum_count_background, p_values, p_values_corrected, cond_multitest, blacklisted_terms_bool_arr_temp, cond_terms_reduced_with_ontology, cond_filter, cond_PMIDs, effectSizes, over_under_int_arr, over_under_arr_of_string\"\"\".split(\", \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preloaded_objects_per_analysis = pqo.get_preloaded_objects_per_analysis()\n",
    "len(preloaded_objects_per_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'userinput' from '/Users/dblyon/modules/cpr/agotool/app/python/userinput.py'>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(userinput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7766642.143999999"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ui.default_missing_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7766643.143999999, 7766643.143999999)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ui.background[\"intensity\"].min(), ui.foreground[\"intensity\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_intensity = \"intensity\"\n",
    "DEFAULT_MISSING_BIN = -1\n",
    "NUM_BINS = 100\n",
    "# take subset of foreground with proper abundance values and create bins\n",
    "cond = ui.foreground[col_intensity] > ui.default_missing_bin\n",
    "bins = pd.cut(ui.foreground.loc[cond, col_intensity], bins=NUM_BINS, retbins=True)[1]\n",
    "# add missing bin for the remainder of proteins\n",
    "bins = np.insert(bins, 0, ui.default_missing_bin - 1)  # bins = [DEFAULT_MISSING_BIN - 1] + list(bins)\n",
    "# cut foreground and background into bins\n",
    "# groups_fg = ui.foreground.groupby(pd.cut(ui.foreground[col_intensity], bins=bins))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = ui.foreground[\"intensity\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1 == sorted(l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bins = pd.cut(ui.foreground.loc[cond, col_intensity], bins=NUM_BINS, retbins=True)[1]\n",
    "# bins = np.insert(bins, 0, ui.default_missing_bin - 1)  # bins = [DEFAULT_MISSING_BIN - 1] + list(bins)\n",
    "l1 = list(bins)\n",
    "l1 == sorted(l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-43722050.6"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-4.37220506e+07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.37220506e+07,  5.22653581e+08,  1.03754052e+09,  1.55242746e+09,\n",
       "        2.06731439e+09,  2.58220133e+09,  3.09708827e+09,  3.61197521e+09,\n",
       "        4.12686214e+09,  4.64174908e+09,  5.15663602e+09,  5.67152296e+09,\n",
       "        6.18640990e+09,  6.70129683e+09,  7.21618377e+09,  7.73107071e+09,\n",
       "        8.24595765e+09,  8.76084458e+09,  9.27573152e+09,  9.79061846e+09,\n",
       "        1.03055054e+10,  1.08203923e+10,  1.13352793e+10,  1.18501662e+10,\n",
       "        1.23650531e+10,  1.28799401e+10,  1.33948270e+10,  1.39097140e+10,\n",
       "        1.44246009e+10,  1.49394878e+10,  1.54543748e+10,  1.59692617e+10,\n",
       "        1.64841487e+10,  1.69990356e+10,  1.75139225e+10,  1.80288095e+10,\n",
       "        1.85436964e+10,  1.90585833e+10,  1.95734703e+10,  2.00883572e+10,\n",
       "        2.06032442e+10,  2.11181311e+10,  2.16330180e+10,  2.21479050e+10,\n",
       "        2.26627919e+10,  2.31776788e+10,  2.36925658e+10,  2.42074527e+10,\n",
       "        2.47223397e+10,  2.52372266e+10,  2.57521135e+10,  2.62670005e+10,\n",
       "        2.67818874e+10,  2.72967743e+10,  2.78116613e+10,  2.83265482e+10,\n",
       "        2.88414352e+10,  2.93563221e+10,  2.98712090e+10,  3.03860960e+10,\n",
       "        3.09009829e+10,  3.14158698e+10,  3.19307568e+10,  3.24456437e+10,\n",
       "        3.29605307e+10,  3.34754176e+10,  3.39903045e+10,  3.45051915e+10,\n",
       "        3.50200784e+10,  3.55349653e+10,  3.60498523e+10,  3.65647392e+10,\n",
       "        3.70796262e+10,  3.75945131e+10,  3.81094000e+10,  3.86242870e+10,\n",
       "        3.91391739e+10,  3.96540608e+10,  4.01689478e+10,  4.06838347e+10,\n",
       "        4.11987217e+10,  4.17136086e+10,  4.22284955e+10,  4.27433825e+10,\n",
       "        4.32582694e+10,  4.37731563e+10,  4.42880433e+10,  4.48029302e+10,\n",
       "        4.53178172e+10,  4.58327041e+10,  4.63475910e+10,  4.68624780e+10,\n",
       "        4.73773649e+10,  4.78922519e+10,  4.84071388e+10,  4.89220257e+10,\n",
       "        4.94369127e+10,  4.99517996e+10,  5.04666865e+10,  5.09815735e+10,\n",
       "        5.14964604e+10])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7.76664114e+06, -4.37220506e+07,  5.22653581e+08,  1.03754052e+09,\n",
       "        1.55242746e+09,  2.06731439e+09,  2.58220133e+09,  3.09708827e+09,\n",
       "        3.61197521e+09,  4.12686214e+09,  4.64174908e+09,  5.15663602e+09,\n",
       "        5.67152296e+09,  6.18640990e+09,  6.70129683e+09,  7.21618377e+09,\n",
       "        7.73107071e+09,  8.24595765e+09,  8.76084458e+09,  9.27573152e+09,\n",
       "        9.79061846e+09,  1.03055054e+10,  1.08203923e+10,  1.13352793e+10,\n",
       "        1.18501662e+10,  1.23650531e+10,  1.28799401e+10,  1.33948270e+10,\n",
       "        1.39097140e+10,  1.44246009e+10,  1.49394878e+10,  1.54543748e+10,\n",
       "        1.59692617e+10,  1.64841487e+10,  1.69990356e+10,  1.75139225e+10,\n",
       "        1.80288095e+10,  1.85436964e+10,  1.90585833e+10,  1.95734703e+10,\n",
       "        2.00883572e+10,  2.06032442e+10,  2.11181311e+10,  2.16330180e+10,\n",
       "        2.21479050e+10,  2.26627919e+10,  2.31776788e+10,  2.36925658e+10,\n",
       "        2.42074527e+10,  2.47223397e+10,  2.52372266e+10,  2.57521135e+10,\n",
       "        2.62670005e+10,  2.67818874e+10,  2.72967743e+10,  2.78116613e+10,\n",
       "        2.83265482e+10,  2.88414352e+10,  2.93563221e+10,  2.98712090e+10,\n",
       "        3.03860960e+10,  3.09009829e+10,  3.14158698e+10,  3.19307568e+10,\n",
       "        3.24456437e+10,  3.29605307e+10,  3.34754176e+10,  3.39903045e+10,\n",
       "        3.45051915e+10,  3.50200784e+10,  3.55349653e+10,  3.60498523e+10,\n",
       "        3.65647392e+10,  3.70796262e+10,  3.75945131e+10,  3.81094000e+10,\n",
       "        3.86242870e+10,  3.91391739e+10,  3.96540608e+10,  4.01689478e+10,\n",
       "        4.06838347e+10,  4.11987217e+10,  4.17136086e+10,  4.22284955e+10,\n",
       "        4.27433825e+10,  4.32582694e+10,  4.37731563e+10,  4.42880433e+10,\n",
       "        4.48029302e+10,  4.53178172e+10,  4.58327041e+10,  4.63475910e+10,\n",
       "        4.68624780e+10,  4.73773649e+10,  4.78922519e+10,  4.84071388e+10,\n",
       "        4.89220257e+10,  4.94369127e+10,  4.99517996e+10,  5.04666865e+10,\n",
       "        5.09815735e+10,  5.14964604e+10])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bins = pd.cut(ui.foreground.loc[cond, col_intensity], bins=NUM_BINS, retbins=True)[1]\n",
    "bins = np.insert(bins, 0, ui.default_missing_bin - 1)  # bins = [DEFAULT_MISSING_BIN - 1] + list(bins)\n",
    "bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ui.foreground.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ui.df_orig.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(static_preloaded_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "Brenda Tissue Ontology                            3004\n",
       "Disease Ontology                                  4609\n",
       "Gene Ontology biological process                  2307\n",
       "Gene Ontology cellular component                  2221\n",
       "Gene Ontology molecular function                   329\n",
       "INTERPRO                                           198\n",
       "KEGG (Kyoto Encyclopedia of Genes and Genomes)      61\n",
       "PFAM (Protein FAMilies)                             77\n",
       "PMID (PubMed IDentifier)                           100\n",
       "Reactome                                           229\n",
       "UniProt keywords                                   159\n",
       "WikiPathways                                        97\n",
       "Name: term, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"category\")[\"term\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "etype\n",
       "-58      97\n",
       "-57     229\n",
       "-56     100\n",
       "-55      77\n",
       "-54     198\n",
       "-52      61\n",
       "-51     159\n",
       "-26    4609\n",
       "-25    3004\n",
       "-23     329\n",
       "-22    2221\n",
       "-21    2307\n",
       "Name: term, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"etype\")[\"term\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>hierarchical_level</th>\n",
       "      <th>description</th>\n",
       "      <th>year</th>\n",
       "      <th>over_under</th>\n",
       "      <th>p_value</th>\n",
       "      <th>FDR</th>\n",
       "      <th>effectSize</th>\n",
       "      <th>ratio_in_FG</th>\n",
       "      <th>ratio_in_BG</th>\n",
       "      <th>FG_count</th>\n",
       "      <th>FG_n</th>\n",
       "      <th>BG_count</th>\n",
       "      <th>BG_n</th>\n",
       "      <th>FG_IDs</th>\n",
       "      <th>s_value</th>\n",
       "      <th>rank</th>\n",
       "      <th>funcEnum</th>\n",
       "      <th>category</th>\n",
       "      <th>etype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>GO:0007264</td>\n",
       "      <td>7</td>\n",
       "      <td>small GTPase mediated signal transduction</td>\n",
       "      <td>-1</td>\n",
       "      <td>o</td>\n",
       "      <td>5.740206e-07</td>\n",
       "      <td>0.001620</td>\n",
       "      <td>0.284433</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.015567</td>\n",
       "      <td>90</td>\n",
       "      <td>300</td>\n",
       "      <td>321</td>\n",
       "      <td>20621</td>\n",
       "      <td>RAB10_HUMAN;RAB12_HUMAN;RAB13_HUMAN;RAB14_HUMA...</td>\n",
       "      <td>1.775169</td>\n",
       "      <td>1</td>\n",
       "      <td>6181</td>\n",
       "      <td>Gene Ontology biological process</td>\n",
       "      <td>-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>GO:0007265</td>\n",
       "      <td>8</td>\n",
       "      <td>Ras protein signal transduction</td>\n",
       "      <td>-1</td>\n",
       "      <td>o</td>\n",
       "      <td>3.664623e-07</td>\n",
       "      <td>0.001620</td>\n",
       "      <td>0.274737</td>\n",
       "      <td>0.286667</td>\n",
       "      <td>0.011930</td>\n",
       "      <td>86</td>\n",
       "      <td>300</td>\n",
       "      <td>246</td>\n",
       "      <td>20621</td>\n",
       "      <td>RAB10_HUMAN;RAB12_HUMAN;RAB13_HUMAN;RAB14_HUMA...</td>\n",
       "      <td>1.768200</td>\n",
       "      <td>2</td>\n",
       "      <td>6182</td>\n",
       "      <td>Gene Ontology biological process</td>\n",
       "      <td>-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>GO:0035556</td>\n",
       "      <td>6</td>\n",
       "      <td>intracellular signal transduction</td>\n",
       "      <td>-1</td>\n",
       "      <td>o</td>\n",
       "      <td>1.913462e-06</td>\n",
       "      <td>0.001620</td>\n",
       "      <td>0.292154</td>\n",
       "      <td>0.373333</td>\n",
       "      <td>0.081179</td>\n",
       "      <td>112</td>\n",
       "      <td>300</td>\n",
       "      <td>1674</td>\n",
       "      <td>20621</td>\n",
       "      <td>RAB10_HUMAN;RAB12_HUMAN;RAB13_HUMAN;RAB14_HUMA...</td>\n",
       "      <td>1.670589</td>\n",
       "      <td>3</td>\n",
       "      <td>11464</td>\n",
       "      <td>Gene Ontology biological process</td>\n",
       "      <td>-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>GO:0005968</td>\n",
       "      <td>5</td>\n",
       "      <td>Rab-protein geranylgeranyltransferase complex</td>\n",
       "      <td>-1</td>\n",
       "      <td>o</td>\n",
       "      <td>7.765349e-07</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>0.216251</td>\n",
       "      <td>0.236667</td>\n",
       "      <td>0.020416</td>\n",
       "      <td>71</td>\n",
       "      <td>300</td>\n",
       "      <td>421</td>\n",
       "      <td>20621</td>\n",
       "      <td>R7BP_HUMAN;RAB10_HUMAN;RAB13_HUMAN;RAB14_HUMAN...</td>\n",
       "      <td>1.321256</td>\n",
       "      <td>1</td>\n",
       "      <td>24383</td>\n",
       "      <td>Gene Ontology cellular component</td>\n",
       "      <td>-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>GO:0036284</td>\n",
       "      <td>3</td>\n",
       "      <td>tubulobulbar complex</td>\n",
       "      <td>-1</td>\n",
       "      <td>o</td>\n",
       "      <td>8.282181e-07</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>0.205082</td>\n",
       "      <td>0.253333</td>\n",
       "      <td>0.048252</td>\n",
       "      <td>76</td>\n",
       "      <td>300</td>\n",
       "      <td>995</td>\n",
       "      <td>20621</td>\n",
       "      <td>R3GEF_HUMAN;RAB10_HUMAN;RAB12_HUMAN;RAB13_HUMA...</td>\n",
       "      <td>1.247276</td>\n",
       "      <td>2</td>\n",
       "      <td>25542</td>\n",
       "      <td>Gene Ontology cellular component</td>\n",
       "      <td>-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>GO:0055037</td>\n",
       "      <td>10</td>\n",
       "      <td>recycling endosome</td>\n",
       "      <td>-1</td>\n",
       "      <td>o</td>\n",
       "      <td>2.801950e-06</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>0.214992</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.135008</td>\n",
       "      <td>105</td>\n",
       "      <td>300</td>\n",
       "      <td>2784</td>\n",
       "      <td>20621</td>\n",
       "      <td>R3GEF_HUMAN;RAB10_HUMAN;RAB12_HUMAN;RAB13_HUMA...</td>\n",
       "      <td>1.193752</td>\n",
       "      <td>3</td>\n",
       "      <td>26100</td>\n",
       "      <td>Gene Ontology cellular component</td>\n",
       "      <td>-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845</th>\n",
       "      <td>GO:0097159</td>\n",
       "      <td>3</td>\n",
       "      <td>organic cyclic compound binding</td>\n",
       "      <td>-1</td>\n",
       "      <td>o</td>\n",
       "      <td>3.038793e-06</td>\n",
       "      <td>0.001956</td>\n",
       "      <td>0.380380</td>\n",
       "      <td>0.673333</td>\n",
       "      <td>0.292954</td>\n",
       "      <td>202</td>\n",
       "      <td>300</td>\n",
       "      <td>6041</td>\n",
       "      <td>20621</td>\n",
       "      <td>QSOX1_HUMAN;R3HC1_HUMAN;R3HD1_HUMAN;R3HD2_HUMA...</td>\n",
       "      <td>2.098668</td>\n",
       "      <td>1</td>\n",
       "      <td>34160</td>\n",
       "      <td>Gene Ontology molecular function</td>\n",
       "      <td>-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>848</th>\n",
       "      <td>GO:1901363</td>\n",
       "      <td>3</td>\n",
       "      <td>heterocyclic compound binding</td>\n",
       "      <td>-1</td>\n",
       "      <td>o</td>\n",
       "      <td>3.737711e-06</td>\n",
       "      <td>0.001956</td>\n",
       "      <td>0.384744</td>\n",
       "      <td>0.673333</td>\n",
       "      <td>0.288589</td>\n",
       "      <td>202</td>\n",
       "      <td>300</td>\n",
       "      <td>5951</td>\n",
       "      <td>20621</td>\n",
       "      <td>QSOX1_HUMAN;R3HC1_HUMAN;R3HD1_HUMAN;R3HD2_HUMA...</td>\n",
       "      <td>2.088158</td>\n",
       "      <td>2</td>\n",
       "      <td>34673</td>\n",
       "      <td>Gene Ontology molecular function</td>\n",
       "      <td>-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>GO:0032550</td>\n",
       "      <td>6</td>\n",
       "      <td>purine ribonucleoside binding</td>\n",
       "      <td>-1</td>\n",
       "      <td>o</td>\n",
       "      <td>3.924690e-07</td>\n",
       "      <td>0.001956</td>\n",
       "      <td>0.284809</td>\n",
       "      <td>0.303333</td>\n",
       "      <td>0.018525</td>\n",
       "      <td>91</td>\n",
       "      <td>300</td>\n",
       "      <td>382</td>\n",
       "      <td>20621</td>\n",
       "      <td>RAB10_HUMAN;RAB12_HUMAN;RAB13_HUMAN;RAB14_HUMA...</td>\n",
       "      <td>1.824539</td>\n",
       "      <td>3</td>\n",
       "      <td>31219</td>\n",
       "      <td>Gene Ontology molecular function</td>\n",
       "      <td>-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1230</th>\n",
       "      <td>BTO:0005590</td>\n",
       "      <td>4</td>\n",
       "      <td>Cervical adenocarcinoma cell line</td>\n",
       "      <td>-1</td>\n",
       "      <td>o</td>\n",
       "      <td>3.265207e-06</td>\n",
       "      <td>0.000672</td>\n",
       "      <td>0.215443</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.434557</td>\n",
       "      <td>195</td>\n",
       "      <td>300</td>\n",
       "      <td>8961</td>\n",
       "      <td>20621</td>\n",
       "      <td>R113A_HUMAN;R144B_HUMAN;R3GEF_HUMAN;R3HCL_HUMA...</td>\n",
       "      <td>1.181940</td>\n",
       "      <td>1</td>\n",
       "      <td>38946</td>\n",
       "      <td>Brenda Tissue Ontology</td>\n",
       "      <td>-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912</th>\n",
       "      <td>BTO:0000567</td>\n",
       "      <td>5</td>\n",
       "      <td>HeLa cell</td>\n",
       "      <td>-1</td>\n",
       "      <td>o</td>\n",
       "      <td>4.275868e-06</td>\n",
       "      <td>0.000672</td>\n",
       "      <td>0.215782</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.434218</td>\n",
       "      <td>195</td>\n",
       "      <td>300</td>\n",
       "      <td>8954</td>\n",
       "      <td>20621</td>\n",
       "      <td>R113A_HUMAN;R144B_HUMAN;R3GEF_HUMAN;R3HCL_HUMA...</td>\n",
       "      <td>1.158531</td>\n",
       "      <td>2</td>\n",
       "      <td>35211</td>\n",
       "      <td>Brenda Tissue Ontology</td>\n",
       "      <td>-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1077</th>\n",
       "      <td>BTO:0001967</td>\n",
       "      <td>2</td>\n",
       "      <td>Cervical cancer cell line</td>\n",
       "      <td>-1</td>\n",
       "      <td>o</td>\n",
       "      <td>3.567432e-06</td>\n",
       "      <td>0.000672</td>\n",
       "      <td>0.207681</td>\n",
       "      <td>0.663333</td>\n",
       "      <td>0.455652</td>\n",
       "      <td>199</td>\n",
       "      <td>300</td>\n",
       "      <td>9396</td>\n",
       "      <td>20621</td>\n",
       "      <td>R113A_HUMAN;R144B_HUMAN;R3GEF_HUMAN;R3HCL_HUMA...</td>\n",
       "      <td>1.131374</td>\n",
       "      <td>3</td>\n",
       "      <td>36214</td>\n",
       "      <td>Brenda Tissue Ontology</td>\n",
       "      <td>-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1302</th>\n",
       "      <td>DOID:0060234</td>\n",
       "      <td>10</td>\n",
       "      <td>Carpenter syndrome</td>\n",
       "      <td>-1</td>\n",
       "      <td>o</td>\n",
       "      <td>4.713886e-07</td>\n",
       "      <td>0.001210</td>\n",
       "      <td>0.200020</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>0.019980</td>\n",
       "      <td>66</td>\n",
       "      <td>300</td>\n",
       "      <td>412</td>\n",
       "      <td>20621</td>\n",
       "      <td>RAB10_HUMAN;RAB12_HUMAN;RAB13_HUMAN;RAB14_HUMA...</td>\n",
       "      <td>1.265453</td>\n",
       "      <td>1</td>\n",
       "      <td>40326</td>\n",
       "      <td>Disease Ontology</td>\n",
       "      <td>-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1303</th>\n",
       "      <td>DOID:0060237</td>\n",
       "      <td>6</td>\n",
       "      <td>Warburg micro syndrome</td>\n",
       "      <td>-1</td>\n",
       "      <td>o</td>\n",
       "      <td>6.391243e-07</td>\n",
       "      <td>0.001210</td>\n",
       "      <td>0.180880</td>\n",
       "      <td>0.203333</td>\n",
       "      <td>0.022453</td>\n",
       "      <td>61</td>\n",
       "      <td>300</td>\n",
       "      <td>463</td>\n",
       "      <td>20621</td>\n",
       "      <td>R3GEF_HUMAN;RAB10_HUMAN;RAB12_HUMAN;RAB13_HUMA...</td>\n",
       "      <td>1.120449</td>\n",
       "      <td>2</td>\n",
       "      <td>40329</td>\n",
       "      <td>Disease Ontology</td>\n",
       "      <td>-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1444</th>\n",
       "      <td>DOID:12960</td>\n",
       "      <td>9</td>\n",
       "      <td>Acrocephalosyndactylia</td>\n",
       "      <td>-1</td>\n",
       "      <td>o</td>\n",
       "      <td>1.625312e-06</td>\n",
       "      <td>0.001210</td>\n",
       "      <td>0.183126</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.066874</td>\n",
       "      <td>75</td>\n",
       "      <td>300</td>\n",
       "      <td>1379</td>\n",
       "      <td>20621</td>\n",
       "      <td>QSOX2_HUMAN;RAB10_HUMAN;RAB12_HUMAN;RAB13_HUMA...</td>\n",
       "      <td>1.060130</td>\n",
       "      <td>3</td>\n",
       "      <td>44049</td>\n",
       "      <td>Disease Ontology</td>\n",
       "      <td>-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1625</th>\n",
       "      <td>KW-0343</td>\n",
       "      <td>2</td>\n",
       "      <td>GTPase activation</td>\n",
       "      <td>-1</td>\n",
       "      <td>o</td>\n",
       "      <td>3.946567e-07</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>0.283172</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.016828</td>\n",
       "      <td>90</td>\n",
       "      <td>300</td>\n",
       "      <td>347</td>\n",
       "      <td>20621</td>\n",
       "      <td>RAB10_HUMAN;RAB12_HUMAN;RAB13_HUMAN;RAB14_HUMA...</td>\n",
       "      <td>1.813375</td>\n",
       "      <td>1</td>\n",
       "      <td>48078</td>\n",
       "      <td>UniProt keywords</td>\n",
       "      <td>-51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1637</th>\n",
       "      <td>KW-0637</td>\n",
       "      <td>3</td>\n",
       "      <td>Prenyltransferase</td>\n",
       "      <td>-1</td>\n",
       "      <td>o</td>\n",
       "      <td>7.192969e-07</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>0.255041</td>\n",
       "      <td>0.263333</td>\n",
       "      <td>0.008293</td>\n",
       "      <td>79</td>\n",
       "      <td>300</td>\n",
       "      <td>171</td>\n",
       "      <td>20621</td>\n",
       "      <td>RAB10_HUMAN;RAB12_HUMAN;RAB13_HUMAN;RAB14_HUMA...</td>\n",
       "      <td>1.566739</td>\n",
       "      <td>2</td>\n",
       "      <td>48335</td>\n",
       "      <td>UniProt keywords</td>\n",
       "      <td>-51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1628</th>\n",
       "      <td>KW-0450</td>\n",
       "      <td>2</td>\n",
       "      <td>Lipoyl</td>\n",
       "      <td>-1</td>\n",
       "      <td>o</td>\n",
       "      <td>6.261517e-07</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>0.238828</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.041172</td>\n",
       "      <td>84</td>\n",
       "      <td>300</td>\n",
       "      <td>849</td>\n",
       "      <td>20621</td>\n",
       "      <td>R4RL1_HUMAN;R4RL2_HUMAN;R7BP_HUMAN;RAB10_HUMAN...</td>\n",
       "      <td>1.481529</td>\n",
       "      <td>3</td>\n",
       "      <td>48173</td>\n",
       "      <td>UniProt keywords</td>\n",
       "      <td>-51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1658</th>\n",
       "      <td>map04015</td>\n",
       "      <td>-1</td>\n",
       "      <td>Rap1 signaling pathway</td>\n",
       "      <td>-1</td>\n",
       "      <td>o</td>\n",
       "      <td>7.995546e-07</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.068943</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.011057</td>\n",
       "      <td>24</td>\n",
       "      <td>300</td>\n",
       "      <td>228</td>\n",
       "      <td>20621</td>\n",
       "      <td>RAB5A_HUMAN;RAB5B_HUMAN;RAB5C_HUMAN;RAC1_HUMAN...</td>\n",
       "      <td>0.420358</td>\n",
       "      <td>1</td>\n",
       "      <td>49148</td>\n",
       "      <td>KEGG (Kyoto Encyclopedia of Genes and Genomes)</td>\n",
       "      <td>-52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1655</th>\n",
       "      <td>map01110</td>\n",
       "      <td>-1</td>\n",
       "      <td>Biosynthesis of secondary metabolites</td>\n",
       "      <td>-1</td>\n",
       "      <td>u</td>\n",
       "      <td>3.384016e-06</td>\n",
       "      <td>0.000296</td>\n",
       "      <td>-0.054048</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.060715</td>\n",
       "      <td>2</td>\n",
       "      <td>300</td>\n",
       "      <td>1252</td>\n",
       "      <td>20621</td>\n",
       "      <td>RDH10_HUMAN;RDH11_HUMAN</td>\n",
       "      <td>-0.295674</td>\n",
       "      <td>2</td>\n",
       "      <td>49101</td>\n",
       "      <td>KEGG (Kyoto Encyclopedia of Genes and Genomes)</td>\n",
       "      <td>-52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1664</th>\n",
       "      <td>map04260</td>\n",
       "      <td>-1</td>\n",
       "      <td>Cardiac muscle contraction</td>\n",
       "      <td>-1</td>\n",
       "      <td>o</td>\n",
       "      <td>2.302045e-07</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.038908</td>\n",
       "      <td>0.046667</td>\n",
       "      <td>0.007759</td>\n",
       "      <td>14</td>\n",
       "      <td>300</td>\n",
       "      <td>160</td>\n",
       "      <td>20621</td>\n",
       "      <td>RAD1_HUMAN;RAD50_HUMAN;RAD9A_HUMAN;RAD9B_HUMAN...</td>\n",
       "      <td>0.258264</td>\n",
       "      <td>3</td>\n",
       "      <td>49194</td>\n",
       "      <td>KEGG (Kyoto Encyclopedia of Genes and Genomes)</td>\n",
       "      <td>-52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1688</th>\n",
       "      <td>IPR005226</td>\n",
       "      <td>1</td>\n",
       "      <td>UPF0014 family</td>\n",
       "      <td>-1</td>\n",
       "      <td>o</td>\n",
       "      <td>7.192969e-07</td>\n",
       "      <td>0.002416</td>\n",
       "      <td>0.282095</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>0.007905</td>\n",
       "      <td>87</td>\n",
       "      <td>300</td>\n",
       "      <td>163</td>\n",
       "      <td>20621</td>\n",
       "      <td>RAB10_HUMAN;RAB12_HUMAN;RAB13_HUMAN;RAB14_HUMA...</td>\n",
       "      <td>1.732938</td>\n",
       "      <td>1</td>\n",
       "      <td>53757</td>\n",
       "      <td>INTERPRO</td>\n",
       "      <td>-54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1686</th>\n",
       "      <td>IPR001807</td>\n",
       "      <td>1</td>\n",
       "      <td>Chloride channel, voltage gated</td>\n",
       "      <td>-1</td>\n",
       "      <td>o</td>\n",
       "      <td>9.094123e-07</td>\n",
       "      <td>0.002422</td>\n",
       "      <td>0.283356</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>0.006644</td>\n",
       "      <td>87</td>\n",
       "      <td>300</td>\n",
       "      <td>137</td>\n",
       "      <td>20621</td>\n",
       "      <td>RAB10_HUMAN;RAB12_HUMAN;RAB13_HUMAN;RAB14_HUMA...</td>\n",
       "      <td>1.711823</td>\n",
       "      <td>2</td>\n",
       "      <td>50868</td>\n",
       "      <td>INTERPRO</td>\n",
       "      <td>-54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1698</th>\n",
       "      <td>IPR027419</td>\n",
       "      <td>1</td>\n",
       "      <td>CRISPR-associated protein Csx1, C-terminal</td>\n",
       "      <td>-1</td>\n",
       "      <td>o</td>\n",
       "      <td>1.824103e-06</td>\n",
       "      <td>0.004001</td>\n",
       "      <td>0.281628</td>\n",
       "      <td>0.323333</td>\n",
       "      <td>0.041705</td>\n",
       "      <td>97</td>\n",
       "      <td>300</td>\n",
       "      <td>860</td>\n",
       "      <td>20621</td>\n",
       "      <td>RA51B_HUMAN;RA51C_HUMAN;RA51D_HUMAN;RA54B_HUMA...</td>\n",
       "      <td>1.616251</td>\n",
       "      <td>3</td>\n",
       "      <td>72546</td>\n",
       "      <td>INTERPRO</td>\n",
       "      <td>-54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1705</th>\n",
       "      <td>PF00072</td>\n",
       "      <td>-1</td>\n",
       "      <td>Response regulator receiver domain</td>\n",
       "      <td>-1</td>\n",
       "      <td>o</td>\n",
       "      <td>9.094123e-07</td>\n",
       "      <td>0.002947</td>\n",
       "      <td>0.283356</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>0.006644</td>\n",
       "      <td>87</td>\n",
       "      <td>300</td>\n",
       "      <td>137</td>\n",
       "      <td>20621</td>\n",
       "      <td>RAB10_HUMAN;RAB12_HUMAN;RAB13_HUMAN;RAB14_HUMA...</td>\n",
       "      <td>1.711823</td>\n",
       "      <td>1</td>\n",
       "      <td>86737</td>\n",
       "      <td>PFAM (Protein FAMilies)</td>\n",
       "      <td>-55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1706</th>\n",
       "      <td>PF00077</td>\n",
       "      <td>-1</td>\n",
       "      <td>Retroviral aspartyl protease</td>\n",
       "      <td>-1</td>\n",
       "      <td>o</td>\n",
       "      <td>9.351653e-07</td>\n",
       "      <td>0.002947</td>\n",
       "      <td>0.149962</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.010038</td>\n",
       "      <td>48</td>\n",
       "      <td>300</td>\n",
       "      <td>207</td>\n",
       "      <td>20621</td>\n",
       "      <td>RA1L2_HUMAN;RALYL_HUMAN;RALY_HUMAN;RAVR1_HUMAN...</td>\n",
       "      <td>0.904136</td>\n",
       "      <td>2</td>\n",
       "      <td>86742</td>\n",
       "      <td>PFAM (Protein FAMilies)</td>\n",
       "      <td>-55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1710</th>\n",
       "      <td>PF00789</td>\n",
       "      <td>-1</td>\n",
       "      <td>UBX domain</td>\n",
       "      <td>-1</td>\n",
       "      <td>o</td>\n",
       "      <td>2.647844e-07</td>\n",
       "      <td>0.002145</td>\n",
       "      <td>0.034969</td>\n",
       "      <td>0.036667</td>\n",
       "      <td>0.001697</td>\n",
       "      <td>11</td>\n",
       "      <td>300</td>\n",
       "      <td>35</td>\n",
       "      <td>20621</td>\n",
       "      <td>RADIL_HUMAN;RAIN_HUMAN;RAPH1_HUMAN;RASF1_HUMAN...</td>\n",
       "      <td>0.229997</td>\n",
       "      <td>3</td>\n",
       "      <td>87413</td>\n",
       "      <td>PFAM (Protein FAMilies)</td>\n",
       "      <td>-55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1750</th>\n",
       "      <td>HSA-8874081</td>\n",
       "      <td>5</td>\n",
       "      <td>MET activates PTK2 signaling</td>\n",
       "      <td>-1</td>\n",
       "      <td>o</td>\n",
       "      <td>3.004857e-07</td>\n",
       "      <td>0.002526</td>\n",
       "      <td>0.203515</td>\n",
       "      <td>0.206667</td>\n",
       "      <td>0.003152</td>\n",
       "      <td>62</td>\n",
       "      <td>300</td>\n",
       "      <td>65</td>\n",
       "      <td>20621</td>\n",
       "      <td>RAB10_HUMAN;RAB12_HUMAN;RAB13_HUMAN;RAB14_HUMA...</td>\n",
       "      <td>1.327358</td>\n",
       "      <td>1</td>\n",
       "      <td>3506275</td>\n",
       "      <td>Reactome</td>\n",
       "      <td>-57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1739</th>\n",
       "      <td>HSA-606279</td>\n",
       "      <td>4</td>\n",
       "      <td>Deposition of new CENPA-containing nucleosomes...</td>\n",
       "      <td>-1</td>\n",
       "      <td>o</td>\n",
       "      <td>1.990689e-06</td>\n",
       "      <td>0.002631</td>\n",
       "      <td>0.198581</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.068086</td>\n",
       "      <td>80</td>\n",
       "      <td>300</td>\n",
       "      <td>1404</td>\n",
       "      <td>20621</td>\n",
       "      <td>QSOX1_HUMAN;R144A_HUMAN;R4RL1_HUMAN;R4RL2_HUMA...</td>\n",
       "      <td>1.132108</td>\n",
       "      <td>2</td>\n",
       "      <td>3505944</td>\n",
       "      <td>Reactome</td>\n",
       "      <td>-57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1722</th>\n",
       "      <td>HSA-392517</td>\n",
       "      <td>3</td>\n",
       "      <td>Rap1 signalling</td>\n",
       "      <td>-1</td>\n",
       "      <td>o</td>\n",
       "      <td>2.079463e-06</td>\n",
       "      <td>0.002631</td>\n",
       "      <td>0.169872</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.096795</td>\n",
       "      <td>80</td>\n",
       "      <td>300</td>\n",
       "      <td>1996</td>\n",
       "      <td>20621</td>\n",
       "      <td>QSOX1_HUMAN;R144A_HUMAN;R4RL1_HUMAN;R4RL2_HUMA...</td>\n",
       "      <td>0.965222</td>\n",
       "      <td>3</td>\n",
       "      <td>3505460</td>\n",
       "      <td>Reactome</td>\n",
       "      <td>-57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1769</th>\n",
       "      <td>WP4224</td>\n",
       "      <td>-1</td>\n",
       "      <td>Purine metabolism</td>\n",
       "      <td>-1</td>\n",
       "      <td>o</td>\n",
       "      <td>2.754122e-07</td>\n",
       "      <td>0.000232</td>\n",
       "      <td>0.071271</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.008729</td>\n",
       "      <td>24</td>\n",
       "      <td>300</td>\n",
       "      <td>180</td>\n",
       "      <td>20621</td>\n",
       "      <td>RAB5A_HUMAN;RAB5B_HUMAN;RAB5C_HUMAN;RAC1_HUMAN...</td>\n",
       "      <td>0.467539</td>\n",
       "      <td>1</td>\n",
       "      <td>3515661</td>\n",
       "      <td>WikiPathways</td>\n",
       "      <td>-58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1772</th>\n",
       "      <td>WP4304</td>\n",
       "      <td>-1</td>\n",
       "      <td>Oligodendrocyte Specification and differentiat...</td>\n",
       "      <td>-1</td>\n",
       "      <td>o</td>\n",
       "      <td>8.073087e-08</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.029127</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.000873</td>\n",
       "      <td>9</td>\n",
       "      <td>300</td>\n",
       "      <td>18</td>\n",
       "      <td>20621</td>\n",
       "      <td>RAB5A_HUMAN;RAB5B_HUMAN;RAB5C_HUMAN;RAF1_HUMAN...</td>\n",
       "      <td>0.206597</td>\n",
       "      <td>2</td>\n",
       "      <td>3515699</td>\n",
       "      <td>WikiPathways</td>\n",
       "      <td>-58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1770</th>\n",
       "      <td>WP4258</td>\n",
       "      <td>-1</td>\n",
       "      <td>LncRNA involvement in canonical Wnt signaling ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>o</td>\n",
       "      <td>2.722533e-07</td>\n",
       "      <td>0.000232</td>\n",
       "      <td>0.029842</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.003492</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "      <td>72</td>\n",
       "      <td>20621</td>\n",
       "      <td>RABP1_HUMAN;RABP2_HUMAN;RAF1_HUMAN;RARB_HUMAN;...</td>\n",
       "      <td>0.195912</td>\n",
       "      <td>3</td>\n",
       "      <td>3515676</td>\n",
       "      <td>WikiPathways</td>\n",
       "      <td>-58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              term  hierarchical_level  \\\n",
       "35      GO:0007264                   7   \n",
       "36      GO:0007265                   8   \n",
       "69      GO:0035556                   6   \n",
       "266     GO:0005968                   5   \n",
       "502     GO:0036284                   3   \n",
       "605     GO:0055037                  10   \n",
       "845     GO:0097159                   3   \n",
       "848     GO:1901363                   3   \n",
       "835     GO:0032550                   6   \n",
       "1230   BTO:0005590                   4   \n",
       "912    BTO:0000567                   5   \n",
       "1077   BTO:0001967                   2   \n",
       "1302  DOID:0060234                  10   \n",
       "1303  DOID:0060237                   6   \n",
       "1444    DOID:12960                   9   \n",
       "1625       KW-0343                   2   \n",
       "1637       KW-0637                   3   \n",
       "1628       KW-0450                   2   \n",
       "1658      map04015                  -1   \n",
       "1655      map01110                  -1   \n",
       "1664      map04260                  -1   \n",
       "1688     IPR005226                   1   \n",
       "1686     IPR001807                   1   \n",
       "1698     IPR027419                   1   \n",
       "1705       PF00072                  -1   \n",
       "1706       PF00077                  -1   \n",
       "1710       PF00789                  -1   \n",
       "1750   HSA-8874081                   5   \n",
       "1739    HSA-606279                   4   \n",
       "1722    HSA-392517                   3   \n",
       "1769        WP4224                  -1   \n",
       "1772        WP4304                  -1   \n",
       "1770        WP4258                  -1   \n",
       "\n",
       "                                            description  year over_under  \\\n",
       "35            small GTPase mediated signal transduction    -1          o   \n",
       "36                      Ras protein signal transduction    -1          o   \n",
       "69                    intracellular signal transduction    -1          o   \n",
       "266       Rab-protein geranylgeranyltransferase complex    -1          o   \n",
       "502                                tubulobulbar complex    -1          o   \n",
       "605                                  recycling endosome    -1          o   \n",
       "845                     organic cyclic compound binding    -1          o   \n",
       "848                       heterocyclic compound binding    -1          o   \n",
       "835                       purine ribonucleoside binding    -1          o   \n",
       "1230                  Cervical adenocarcinoma cell line    -1          o   \n",
       "912                                           HeLa cell    -1          o   \n",
       "1077                          Cervical cancer cell line    -1          o   \n",
       "1302                                 Carpenter syndrome    -1          o   \n",
       "1303                             Warburg micro syndrome    -1          o   \n",
       "1444                             Acrocephalosyndactylia    -1          o   \n",
       "1625                                  GTPase activation    -1          o   \n",
       "1637                                  Prenyltransferase    -1          o   \n",
       "1628                                             Lipoyl    -1          o   \n",
       "1658                             Rap1 signaling pathway    -1          o   \n",
       "1655              Biosynthesis of secondary metabolites    -1          u   \n",
       "1664                         Cardiac muscle contraction    -1          o   \n",
       "1688                                     UPF0014 family    -1          o   \n",
       "1686                    Chloride channel, voltage gated    -1          o   \n",
       "1698         CRISPR-associated protein Csx1, C-terminal    -1          o   \n",
       "1705                 Response regulator receiver domain    -1          o   \n",
       "1706                       Retroviral aspartyl protease    -1          o   \n",
       "1710                                         UBX domain    -1          o   \n",
       "1750                       MET activates PTK2 signaling    -1          o   \n",
       "1739  Deposition of new CENPA-containing nucleosomes...    -1          o   \n",
       "1722                                    Rap1 signalling    -1          o   \n",
       "1769                                  Purine metabolism    -1          o   \n",
       "1772  Oligodendrocyte Specification and differentiat...    -1          o   \n",
       "1770  LncRNA involvement in canonical Wnt signaling ...    -1          o   \n",
       "\n",
       "           p_value       FDR  effectSize  ratio_in_FG  ratio_in_BG  FG_count  \\\n",
       "35    5.740206e-07  0.001620    0.284433     0.300000     0.015567        90   \n",
       "36    3.664623e-07  0.001620    0.274737     0.286667     0.011930        86   \n",
       "69    1.913462e-06  0.001620    0.292154     0.373333     0.081179       112   \n",
       "266   7.765349e-07  0.000452    0.216251     0.236667     0.020416        71   \n",
       "502   8.282181e-07  0.000452    0.205082     0.253333     0.048252        76   \n",
       "605   2.801950e-06  0.000452    0.214992     0.350000     0.135008       105   \n",
       "845   3.038793e-06  0.001956    0.380380     0.673333     0.292954       202   \n",
       "848   3.737711e-06  0.001956    0.384744     0.673333     0.288589       202   \n",
       "835   3.924690e-07  0.001956    0.284809     0.303333     0.018525        91   \n",
       "1230  3.265207e-06  0.000672    0.215443     0.650000     0.434557       195   \n",
       "912   4.275868e-06  0.000672    0.215782     0.650000     0.434218       195   \n",
       "1077  3.567432e-06  0.000672    0.207681     0.663333     0.455652       199   \n",
       "1302  4.713886e-07  0.001210    0.200020     0.220000     0.019980        66   \n",
       "1303  6.391243e-07  0.001210    0.180880     0.203333     0.022453        61   \n",
       "1444  1.625312e-06  0.001210    0.183126     0.250000     0.066874        75   \n",
       "1625  3.946567e-07  0.000461    0.283172     0.300000     0.016828        90   \n",
       "1637  7.192969e-07  0.000461    0.255041     0.263333     0.008293        79   \n",
       "1628  6.261517e-07  0.000461    0.238828     0.280000     0.041172        84   \n",
       "1658  7.995546e-07  0.000101    0.068943     0.080000     0.011057        24   \n",
       "1655  3.384016e-06  0.000296   -0.054048     0.006667     0.060715         2   \n",
       "1664  2.302045e-07  0.000101    0.038908     0.046667     0.007759        14   \n",
       "1688  7.192969e-07  0.002416    0.282095     0.290000     0.007905        87   \n",
       "1686  9.094123e-07  0.002422    0.283356     0.290000     0.006644        87   \n",
       "1698  1.824103e-06  0.004001    0.281628     0.323333     0.041705        97   \n",
       "1705  9.094123e-07  0.002947    0.283356     0.290000     0.006644        87   \n",
       "1706  9.351653e-07  0.002947    0.149962     0.160000     0.010038        48   \n",
       "1710  2.647844e-07  0.002145    0.034969     0.036667     0.001697        11   \n",
       "1750  3.004857e-07  0.002526    0.203515     0.206667     0.003152        62   \n",
       "1739  1.990689e-06  0.002631    0.198581     0.266667     0.068086        80   \n",
       "1722  2.079463e-06  0.002631    0.169872     0.266667     0.096795        80   \n",
       "1769  2.754122e-07  0.000232    0.071271     0.080000     0.008729        24   \n",
       "1772  8.073087e-08  0.000138    0.029127     0.030000     0.000873         9   \n",
       "1770  2.722533e-07  0.000232    0.029842     0.033333     0.003492        10   \n",
       "\n",
       "      FG_n  BG_count   BG_n  \\\n",
       "35     300       321  20621   \n",
       "36     300       246  20621   \n",
       "69     300      1674  20621   \n",
       "266    300       421  20621   \n",
       "502    300       995  20621   \n",
       "605    300      2784  20621   \n",
       "845    300      6041  20621   \n",
       "848    300      5951  20621   \n",
       "835    300       382  20621   \n",
       "1230   300      8961  20621   \n",
       "912    300      8954  20621   \n",
       "1077   300      9396  20621   \n",
       "1302   300       412  20621   \n",
       "1303   300       463  20621   \n",
       "1444   300      1379  20621   \n",
       "1625   300       347  20621   \n",
       "1637   300       171  20621   \n",
       "1628   300       849  20621   \n",
       "1658   300       228  20621   \n",
       "1655   300      1252  20621   \n",
       "1664   300       160  20621   \n",
       "1688   300       163  20621   \n",
       "1686   300       137  20621   \n",
       "1698   300       860  20621   \n",
       "1705   300       137  20621   \n",
       "1706   300       207  20621   \n",
       "1710   300        35  20621   \n",
       "1750   300        65  20621   \n",
       "1739   300      1404  20621   \n",
       "1722   300      1996  20621   \n",
       "1769   300       180  20621   \n",
       "1772   300        18  20621   \n",
       "1770   300        72  20621   \n",
       "\n",
       "                                                 FG_IDs   s_value  rank  \\\n",
       "35    RAB10_HUMAN;RAB12_HUMAN;RAB13_HUMAN;RAB14_HUMA...  1.775169     1   \n",
       "36    RAB10_HUMAN;RAB12_HUMAN;RAB13_HUMAN;RAB14_HUMA...  1.768200     2   \n",
       "69    RAB10_HUMAN;RAB12_HUMAN;RAB13_HUMAN;RAB14_HUMA...  1.670589     3   \n",
       "266   R7BP_HUMAN;RAB10_HUMAN;RAB13_HUMAN;RAB14_HUMAN...  1.321256     1   \n",
       "502   R3GEF_HUMAN;RAB10_HUMAN;RAB12_HUMAN;RAB13_HUMA...  1.247276     2   \n",
       "605   R3GEF_HUMAN;RAB10_HUMAN;RAB12_HUMAN;RAB13_HUMA...  1.193752     3   \n",
       "845   QSOX1_HUMAN;R3HC1_HUMAN;R3HD1_HUMAN;R3HD2_HUMA...  2.098668     1   \n",
       "848   QSOX1_HUMAN;R3HC1_HUMAN;R3HD1_HUMAN;R3HD2_HUMA...  2.088158     2   \n",
       "835   RAB10_HUMAN;RAB12_HUMAN;RAB13_HUMAN;RAB14_HUMA...  1.824539     3   \n",
       "1230  R113A_HUMAN;R144B_HUMAN;R3GEF_HUMAN;R3HCL_HUMA...  1.181940     1   \n",
       "912   R113A_HUMAN;R144B_HUMAN;R3GEF_HUMAN;R3HCL_HUMA...  1.158531     2   \n",
       "1077  R113A_HUMAN;R144B_HUMAN;R3GEF_HUMAN;R3HCL_HUMA...  1.131374     3   \n",
       "1302  RAB10_HUMAN;RAB12_HUMAN;RAB13_HUMAN;RAB14_HUMA...  1.265453     1   \n",
       "1303  R3GEF_HUMAN;RAB10_HUMAN;RAB12_HUMAN;RAB13_HUMA...  1.120449     2   \n",
       "1444  QSOX2_HUMAN;RAB10_HUMAN;RAB12_HUMAN;RAB13_HUMA...  1.060130     3   \n",
       "1625  RAB10_HUMAN;RAB12_HUMAN;RAB13_HUMAN;RAB14_HUMA...  1.813375     1   \n",
       "1637  RAB10_HUMAN;RAB12_HUMAN;RAB13_HUMAN;RAB14_HUMA...  1.566739     2   \n",
       "1628  R4RL1_HUMAN;R4RL2_HUMAN;R7BP_HUMAN;RAB10_HUMAN...  1.481529     3   \n",
       "1658  RAB5A_HUMAN;RAB5B_HUMAN;RAB5C_HUMAN;RAC1_HUMAN...  0.420358     1   \n",
       "1655                            RDH10_HUMAN;RDH11_HUMAN -0.295674     2   \n",
       "1664  RAD1_HUMAN;RAD50_HUMAN;RAD9A_HUMAN;RAD9B_HUMAN...  0.258264     3   \n",
       "1688  RAB10_HUMAN;RAB12_HUMAN;RAB13_HUMAN;RAB14_HUMA...  1.732938     1   \n",
       "1686  RAB10_HUMAN;RAB12_HUMAN;RAB13_HUMAN;RAB14_HUMA...  1.711823     2   \n",
       "1698  RA51B_HUMAN;RA51C_HUMAN;RA51D_HUMAN;RA54B_HUMA...  1.616251     3   \n",
       "1705  RAB10_HUMAN;RAB12_HUMAN;RAB13_HUMAN;RAB14_HUMA...  1.711823     1   \n",
       "1706  RA1L2_HUMAN;RALYL_HUMAN;RALY_HUMAN;RAVR1_HUMAN...  0.904136     2   \n",
       "1710  RADIL_HUMAN;RAIN_HUMAN;RAPH1_HUMAN;RASF1_HUMAN...  0.229997     3   \n",
       "1750  RAB10_HUMAN;RAB12_HUMAN;RAB13_HUMAN;RAB14_HUMA...  1.327358     1   \n",
       "1739  QSOX1_HUMAN;R144A_HUMAN;R4RL1_HUMAN;R4RL2_HUMA...  1.132108     2   \n",
       "1722  QSOX1_HUMAN;R144A_HUMAN;R4RL1_HUMAN;R4RL2_HUMA...  0.965222     3   \n",
       "1769  RAB5A_HUMAN;RAB5B_HUMAN;RAB5C_HUMAN;RAC1_HUMAN...  0.467539     1   \n",
       "1772  RAB5A_HUMAN;RAB5B_HUMAN;RAB5C_HUMAN;RAF1_HUMAN...  0.206597     2   \n",
       "1770  RABP1_HUMAN;RABP2_HUMAN;RAF1_HUMAN;RARB_HUMAN;...  0.195912     3   \n",
       "\n",
       "      funcEnum                                        category  etype  \n",
       "35        6181                Gene Ontology biological process    -21  \n",
       "36        6182                Gene Ontology biological process    -21  \n",
       "69       11464                Gene Ontology biological process    -21  \n",
       "266      24383                Gene Ontology cellular component    -22  \n",
       "502      25542                Gene Ontology cellular component    -22  \n",
       "605      26100                Gene Ontology cellular component    -22  \n",
       "845      34160                Gene Ontology molecular function    -23  \n",
       "848      34673                Gene Ontology molecular function    -23  \n",
       "835      31219                Gene Ontology molecular function    -23  \n",
       "1230     38946                          Brenda Tissue Ontology    -25  \n",
       "912      35211                          Brenda Tissue Ontology    -25  \n",
       "1077     36214                          Brenda Tissue Ontology    -25  \n",
       "1302     40326                                Disease Ontology    -26  \n",
       "1303     40329                                Disease Ontology    -26  \n",
       "1444     44049                                Disease Ontology    -26  \n",
       "1625     48078                                UniProt keywords    -51  \n",
       "1637     48335                                UniProt keywords    -51  \n",
       "1628     48173                                UniProt keywords    -51  \n",
       "1658     49148  KEGG (Kyoto Encyclopedia of Genes and Genomes)    -52  \n",
       "1655     49101  KEGG (Kyoto Encyclopedia of Genes and Genomes)    -52  \n",
       "1664     49194  KEGG (Kyoto Encyclopedia of Genes and Genomes)    -52  \n",
       "1688     53757                                        INTERPRO    -54  \n",
       "1686     50868                                        INTERPRO    -54  \n",
       "1698     72546                                        INTERPRO    -54  \n",
       "1705     86737                         PFAM (Protein FAMilies)    -55  \n",
       "1706     86742                         PFAM (Protein FAMilies)    -55  \n",
       "1710     87413                         PFAM (Protein FAMilies)    -55  \n",
       "1750   3506275                                        Reactome    -57  \n",
       "1739   3505944                                        Reactome    -57  \n",
       "1722   3505460                                        Reactome    -57  \n",
       "1769   3515661                                    WikiPathways    -58  \n",
       "1772   3515699                                    WikiPathways    -58  \n",
       "1770   3515676                                    WikiPathways    -58  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"etype\").head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fn_userinput = os.path.join(variables.EXAMPLE_FOLDER, \"Example_1_Yeast_acetylation_abundance_correction.txt\")\n",
    "# df = pd.read_csv(fn_userinput, sep='\\t')\n",
    "# fg = df.loc[df[\"Foreground\"].notnull(), \"Foreground\"].tolist() # redundant UniProt accessions\n",
    "# UniProtID_2_test_list = list(query.map_secondary_2_primary_ANs(fg).values()) # no more redundancy\n",
    "# assert len(UniProtID_2_test_list) == 1159\n",
    "\n",
    "# fg_scores_matrix, list_of_rowIndices_fg = slice_ScoresMatrix_for_given_ENSP(UniProtID_2_test_list, ENSP_2_rowIndex_dict, CSC_ENSPencoding_2_FuncEnum)\n",
    "\n",
    "# funcEnum_2_scores_dict = {}\n",
    "# missingScores_list = []\n",
    "# for UniProtID in UniProtID_2_test_list:\n",
    "#     try:\n",
    "#         funcEnum_arr, score_arr = ENSP_2_tuple_funcEnum_score_dict[UniProtID]\n",
    "#     except KeyError: #?\n",
    "#         missingScores_list.append(UniProtID)\n",
    "#         continue\n",
    "#     for funcEnum, score in zip(funcEnum_arr, score_arr):\n",
    "#         if funcEnum not in funcEnum_2_scores_dict:\n",
    "#             funcEnum_2_scores_dict[funcEnum] = [score]\n",
    "#         else:\n",
    "#             funcEnum_2_scores_dict[funcEnum].append(score)\n",
    "\n",
    "# m = fg_scores_matrix\n",
    "# counter = 0\n",
    "# for i in range(len(m.indptr[:-1])):  # get column values\n",
    "#     index_row_start = m.indptr[i]\n",
    "#     index_row_stop = m.indptr[i + 1]\n",
    "#     if index_row_start == index_row_stop:\n",
    "#         continue\n",
    "#     funcEnum = i\n",
    "#     scores_list_sparse = sorted(m.data[index_row_start:index_row_stop])\n",
    "#     scores_list_ff = sorted(funcEnum_2_scores_dict[funcEnum])    \n",
    "#     assert len(scores_list_sparse) == len(scores_list_ff)\n",
    "#     assert scores_list_sparse == scores_list_ff\n",
    "#     counter += 1\n",
    "# print(\"# of tests {}\".format(counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "funcEnum_2_scores_dict_bg[funcEnum]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(missingScores_list), missingScores_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_list_sparse, scores_list_ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_userinput = os.path.join(variables.EXAMPLE_FOLDER, \"Example_1_Yeast_acetylation_abundance_correction.txt\")\n",
    "df = pd.read_csv(fn_userinput, sep='\\t')\n",
    "fg = df.loc[df[\"Foreground\"].notnull(), \"Foreground\"].tolist()\n",
    "d = list(query.map_secondary_2_primary_ANs(fg).values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniprotid = 'YD21B_YEAST'\n",
    "ENSP_2_tuple_funcEnum_score_dict[\"ARV1_ARATH\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs.to_csv(\"~/Downloads/Example_1_Yeast_acetylation_abundance_correction_OUTPUT_SCIPY.txt\", sep=\"\\t\", header=True, index=False)\n",
    "dfc.to_csv(\"~/Downloads/Example_1_Yeast_acetylation_abundance_correction_OUTPUT_CYTHON.txt\", sep=\"\\t\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(ENSP_2_tuple_funcEnum_score_dict.keys())[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(fg), len(set(fg)))\n",
    "fg[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = fg_scores_matrix_data\n",
    "# indptr = fg_scores_matrix_indptr\n",
    "# for i in range(len(indptr[:-1])):  # get column values\n",
    "#     index_row_start = indptr[i]\n",
    "#     index_row_stop = indptr[i + 1]\n",
    "#     if index_row_start == index_row_stop:\n",
    "#         continue\n",
    "#     funcEnum = i\n",
    "#     scores_list_sparse = sorted(data[index_row_start:index_row_stop])\n",
    "#     scores_list_ff = sorted(funcEnum_2_scores_dict_fg[funcEnum])\n",
    "#     assert len(scores_list_sparse) ==\n",
    "#     len(scores_list_ff)\n",
    "#     assert scores_list_sparse == scores_list_ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(scores_list_sparse), len(scores_list_ff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "funcEnum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "funcEnum = 256 # Nucleus\n",
    "sum(funcEnum_2_scores_dict_fg[funcEnum] > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foreground_n, background_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ui.foreground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pqo.taxid_2_proteome_count[559292]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfc.groupby(\"etype\")[\"term\"].count())\n",
    "print(dfs.groupby(\"etype\")[\"term\"].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfc[dfc[\"etype\"] == -20].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[dfs[\"term\"] == \"GOCC:0005634\"].FG_IDs.values[0] == dfc[dfc[\"term\"] == \"GOCC:0005634\"].FG_IDs.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dfs[dfs[\"term\"] == \"GOCC:0005634\"].FG_IDs.values[0].split(\";\")), len(dfc[dfc[\"term\"] == \"GOCC:0005634\"].FG_IDs.values[0].split(\";\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[dfs[\"term\"] == \"GOCC:0005634\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc[dfc[\"term\"] == \"GOCC:0005634\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.986195 - 0.950679"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs.groupby(\"etype\").term.count(), dfc.groupby(\"etype\").term.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "126/177"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfs[dfs[\"etype\"] == -20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfc = df.copy()\n",
    "# dfc.groupby(\"etype\").head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfs = df.copy()\n",
    "# dfs.groupby(\"etype\").head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[dfs[\"etype\"] == -20].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc[dfc[\"etype\"] == -20].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yeast acetylation, underrepresented, scipy\n",
    "print(df.shape)\n",
    "print(df.groupby(\"etype\")[\"term\"].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yeast acetylation, underrepresented, cython\n",
    "print(df.shape)\n",
    "print(df.groupby(\"etype\")[\"term\"].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yeast acetylation, both, scipy\n",
    "print(df.shape)\n",
    "print(df.groupby(\"etype\")[\"term\"].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yeast acetylation, both, cython\n",
    "print(df.shape)\n",
    "print(df.groupby(\"etype\")[\"term\"].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yeast acetylation, overrepresented, cython\n",
    "print(df.shape)\n",
    "print(df.groupby(\"etype\")[\"term\"].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"etype\"] == -51]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"etype\").head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problematic call\n",
    "foreground_input = '511145.b1260%0d511145.b1261%0d511145.b1262%0d511145.b1263%0d511145.b1264%0d511145.b1812%0d511145.b2551%0d511145.b3117%0d511145.b3772%0d511145.b1015%0d511145.b2585'\n",
    "foreground_input = foreground_input.split(\"%0d\")\n",
    "background_input = []\n",
    "\n",
    "enrichment_method = \"genome\"\n",
    "args_dict = {}\n",
    "args_dict[\"enrichment_method\"] = enrichment_method\n",
    "args_dict[\"taxid\"] = 511145\n",
    "args_dict[\"FDR_cutoff\"] = 0.05\n",
    "args_dict[\"p_value_cutoff\"] = 0.01\n",
    "args_dict[\"limit_2_entity_type\"] = None # \"-20;-25;-26\" #\"-21;-22;-23;-51;-52;-53;-54;-55;-56-57;-58\"\n",
    "args_dict[\"filter_PMID_top_n\"] = 100\n",
    "args_dict[\"filter_foreground_count_one\"] = False\n",
    "args_dict[\"filter_parents\"] = False\n",
    "args_dict[\"go_slim_subset\"] = None # \"generic\"\n",
    "args_dict[\"o_or_u_or_both\"] = \"both\" # \"both\" \"underrepresented\" \"overrepresented\"\n",
    "args_dict[\"multiple_testing_per_etype\"] = True\n",
    "args_dict[\"privileged\"] = True\n",
    "args_dict[\"score_cutoff\"] = 0\n",
    "args_dict[\"caller_identity\"] = \"11_0\"\n",
    "taxid = args_dict[\"taxid\"]\n",
    "debug = False\n",
    "profile = False\n",
    "simplified_output = False\n",
    "args_dict[\"simplified_output\"] = simplified_output\n",
    "args_dict[\"STRING_beta\"] = True\n",
    "KS_method = \"cy\"\n",
    "# result = requests.post(url_, params={\"output_format\": \"tsv\", \"enrichment_method\": \"genome\", \"taxid\": 511145, \"caller_identity\": \"11_0\", \"STRING_beta\": True, \n",
    "#                                      'FDR_cutoff': '0.05'}, data={\"foreground\": fg, \"background\": bg})\n",
    "ui = userinput.Userinput(pqo, fn=None, foreground_string=userinput.stringify_for_Userinput(foreground_input), background_string=userinput.stringify_for_Userinput(background_input), args_dict=args_dict)\n",
    "preloaded_objects_per_analysis = pqo.get_preloaded_objects_per_analysis()\n",
    "if debug:\n",
    "    funcEnum_2_scores_dict_bg, foreground_n, background_n, fg_scores_matrix_data, fg_scores_matrix_indptr, bg_scores_matrix_data, bg_scores_matrix_indptr, p_values, cond_multitest, effectSizes, p_value_cutoff, funcEnum_count_foreground, funcEnum_count_background, over_under_int_arr, o_or_u_or_both_encoding, em, filter_foreground_count_one = run_enrichment_cy(ncbi, ui, preloaded_objects_per_analysis, static_preloaded_objects, low_memory=True, debug=debug, KS_method=KS_method, ENSP_2_tuple_funcEnum_score_dict=ENSP_2_tuple_funcEnum_score_dict)\n",
    "else:\n",
    "    df = run_enrichment_cy(ncbi, ui, preloaded_objects_per_analysis, static_preloaded_objects, low_memory=True, debug=debug, KS_method=KS_method, ENSP_2_tuple_funcEnum_score_dict=ENSP_2_tuple_funcEnum_score_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"etype\").head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# from io import StringIO\n",
    "# import pandas as pd\n",
    "# # call api_help for help and argument defaults\n",
    "# response = requests.get(r\"https://agotool.org/api_help\")\n",
    "# print(response.json())\n",
    "# url_ = r\"https://agotool.org/api\"\n",
    "# # url_ = r\"http://localhost:5000/api\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENSPs = ['4932.YAR019C', '4932.YFR028C', '4932.YGR092W', '4932.YHR152W', '4932.YIL106W', '4932.YJL076W',\n",
    "#      '4932.YLR079W', '4932.YML064C', '4932.YMR055C', '4932.YOR373W', '4932.YPR119W']\n",
    "# fg = \"%0d\".join(ENSPs)\n",
    "# result = requests.post(url_,\n",
    "#                    params={\"output_format\": \"tsv\",\n",
    "#                            \"enrichment_method\": \"genome\",\n",
    "#                            \"taxid\": 559292, \"STRING_beta\": True}, \n",
    "#                        # UniProt reference proteomes uses \"Saccharomyces cerevisiae S288C\" with Taxid 559292 as a pan proteome instead of 4932 (TaxID on taxonomic rank of species).\n",
    "#                    data={\"foreground\": fg})\n",
    "# result = result.text\n",
    "# df = pd.read_csv(StringIO(result), sep='\\t')\n",
    "# df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# from io import StringIO\n",
    "# import pandas as pd\n",
    "\n",
    "# url_ = r\"https://agotool.org/api\"\n",
    "# ENSPs = ['4932.YAR019C', '4932.YFR028C', '4932.YGR092W', '4932.YHR152W', '4932.YIL106W', '4932.YJL076W',\n",
    "#      '4932.YLR079W', '4932.YML064C', '4932.YMR055C', '4932.YOR373W', '4932.YPR119W']\n",
    "# fg = \"%0d\".join(ENSPs)\n",
    "# result = requests.post(url_,\n",
    "#                    params={\"output_format\": \"tsv\",\n",
    "#                            \"enrichment_method\": \"genome\",\n",
    "#                            \"taxid\": 559292, \"STRING_beta\": False}, \n",
    "#                        # UniProt reference proteomes uses \"Saccharomyces cerevisiae S288C\" with Taxid 559292 as a pan proteome instead of 4932 (TaxID on taxonomic rank of species).\n",
    "#                    data={\"foreground\": fg})\n",
    "# result = result.text\n",
    "# df = pd.read_csv(StringIO(result), sep='\\t')\n",
    "# df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo PyTests 2 write\n",
    "# compare ENSP_2_tuple_funcEnum_score_dict with Sparse Matrix (funcEnum_2_scores_dict_fg, funcEnum_2_scores_dict_bg). \n",
    "#   For any given input (of taxid 9606) check that FG_count <= BG_count\n",
    "#   funcEnums of FG must also be in BG\n",
    "#   scores of FG must also be in BG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# for given Protein what functions are associated?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg_scores_matrix, list_of_rowIndices_fg = slice_ScoresMatrix_for_given_ENSP(protein_ans_fg, ENSP_2_rowIndex_dict, CSC_ENSPencoding_2_FuncEnum)\n",
    "fg_scores_matrix_data = fg_scores_matrix.data\n",
    "fg_scores_matrix_indptr = fg_scores_matrix.indptr\n",
    "set_fg_counts(fg_scores_matrix_data, fg_scores_matrix_indptr, funcEnum_count_foreground, filter_foreground_count_one)\n",
    "# add_funcEnums_2_dict(protein_ans_fg, ENSP_2_functionEnumArray_dict, ENSP_2_tuple_funcEnum_score_dict)\n",
    "add_funcEnums_2_dict_CSC(protein_ans_fg, ENSP_2_functionEnumArray_dict, ENSP_2_rowIndex_dict, CSR_ENSPencoding_2_FuncEnum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How can the FG_count always be as high as FG_n?\n",
    "# Why is BG_count not >= as FG_count? --> PyTest\n",
    "funcEnum_2_scores_dict_bg = Taxid_2_FunctionEnum_2_Scores_dict[9606]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e.g. GOCC:0043226; 1893 (funcEnum) with 59 BG_count, but 97 FG_count and enrichment_method \"genome\"\n",
    "# --> PYTEST: FG_count should always be <= BG_count\n",
    "# CHECK:\n",
    "# Which files are in the pipeline? \n",
    "    # - Lars download with ENSPs\n",
    "    # - translated to UniProtIDs, scaled values from float to int and backtracked\n",
    "    # - counted per TaxID\n",
    "    \n",
    "# Which ENSPs are associated with GOCC:0043226 in original Lars download? \n",
    "# Which UniProtIDs are associated with GOCC:0043226 in original Lars download?\n",
    "# How many and which"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg_scores_matrix, list_of_rowIndices_fg = slice_ScoresMatrix_for_given_ENSP(protein_ans_fg, ENSP_2_rowIndex_dict, CSC_ENSPencoding_2_FuncEnum)\n",
    "fg_scores_matrix_data = fg_scores_matrix.data\n",
    "fg_scores_matrix_indptr = fg_scores_matrix.indptr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ui.df_orig.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collect_scores_per_term_limit_2_inclusionTerms(protein_ans_fg, ENSP_2_tuple_funcEnum_score_dict, funcEnums_2_include_set, list_2_array=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prot_noFunc_list, scores_list = [], []\n",
    "funcEnum = 1893\n",
    "protein_ans_fg = ui.get_all_individual_foreground_ANs()\n",
    "for prot in protein_ans_fg:\n",
    "    try:\n",
    "        funcEnum_arr, score_arr = ENSP_2_tuple_funcEnum_score_dict[prot]\n",
    "    except:\n",
    "        prot_noFunc_list.append(prot)\n",
    "        continue\n",
    "    x = np.where(funcEnum_arr == funcEnum)[0]\n",
    "    if x.shape[0] == 0:\n",
    "        print(\"\")\n",
    "        continue\n",
    "    else:\n",
    "        index_ = x[0]\n",
    "    scores_list.append(score_arr[index_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(scores_list), len(prot_noFunc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "funcEnum_arr, score_arr = ENSP_2_tuple_funcEnum_score_dict[\"GPT_HUMAN\"]\n",
    "np.where(funcEnum_arr == funcEnum)\n",
    "# index_ = np.where(funcEnum_arr == funcEnum)[0][0]\n",
    "# print(score_arr[index_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cProfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del run_cythonized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import run_cythonized\n",
    "reload(run_cythonized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import cProfile\n",
    "# cProfile.run('run_cythonized.run_genome_cy(taxid, protein_ans, background_n, preloaded_objects_per_analysis, static_preloaded_objects, args_dict, low_memory=False)', sort='time') > prof_temp.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## line profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## https://stackoverflow.com/questions/28301931/how-to-profile-cython-functions-line-by-line\n",
    "## add this to Jupyter Notebook\n",
    "#%%cython -f --compile-args=-DCYTHON_TRACE=1\n",
    "#import Cython\n",
    "######################################\n",
    "### profiling # Set compiler directives (cf. http://docs.cython.org/src/reference/compilation.html)\n",
    "import line_profiler\n",
    "directive_defaults = Cython.Compiler.Options.get_directive_defaults() ### from Cython.Compiler.Options import directive_defaults # deprecated\n",
    "directive_defaults['linetrace'] = True\n",
    "directive_defaults['binding'] = True\n",
    "######################################\n",
    "\n",
    "## then run this to profile\n",
    "# %load_ext line_profiler\n",
    "import line_profiler\n",
    "\n",
    "fn_userinput = r\"/Users/dblyon/modules/cpr/agotool/data/exampledata/ExampleData_for_testing.txt\"\n",
    "foreground_input = [\"HBA_HUMAN\", \"HBB_HUMAN\", \"HBD_HUMAN\", \"HBE_HUMAN\"]\n",
    "taxid = 9606\n",
    "from_file = False\n",
    "\n",
    "args_dict = {}\n",
    "args_dict[\"enrichment_method\"] = \"genome\"\n",
    "args_dict[\"FDR_cutoff\"] = 0.05\n",
    "args_dict[\"p_value_cutoff\"] = 0.01\n",
    "args_dict[\"limit_2_entity_type\"] = \"-20;-25;-21\" # \"-20;-21;-22;-23;-25;-26\" # None #\"-21;-22;-23\"\n",
    "args_dict[\"filter_PMID_top_n\"] = 50\n",
    "args_dict[\"filter_foreground_count_one\"] = True\n",
    "args_dict[\"filter_parents\"] = True\n",
    "args_dict[\"go_slim_subset\"] = None # \"generic\"\n",
    "args_dict[\"taxid\"] = taxid\n",
    "args_dict[\"o_or_u_or_both\"] = \"both\" # \"both\" \"underrepresented\"\n",
    "args_dict[\"multiple_testing_per_etype\"] = True\n",
    "args_dict[\"privileged\"] = True\n",
    "\n",
    "background_input = query.get_proteins_of_taxid(taxid, read_from_flat_files=True)\n",
    "if from_file:\n",
    "    ui = userinput.Userinput(pqo, fn_userinput, args_dict=args_dict)\n",
    "else:\n",
    "    ui = userinput.Userinput(pqo, fn=None, foreground_string=userinput.stringify_for_Userinput(foreground_input), background_string=userinput.stringify_for_Userinput(background_input), args_dict=args_dict)\n",
    "ncbi = pqo.ncbi\n",
    "\n",
    "preloaded_objects_per_analysis = pqo.get_preloaded_objects_per_analysis()\n",
    "profile = line_profiler.LineProfiler(run_enrichment_cy)\n",
    "profile.runcall(run_enrichment_cy, ncbi, ui, preloaded_objects_per_analysis, static_preloaded_objects, low_memory=True)\n",
    "profile.print_stats()\n",
    "# > 70% of time spent on KS (Hemoglobin foreground, genome background). 76.7 (only categories with scores), 69.8 (all categories) \n",
    "#  --> test KS funtion alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### get objects for code block below\n",
    "foreground_input = [\"HBA_HUMAN\", \"HBB_HUMAN\", \"HBD_HUMAN\", \"HBE_HUMAN\"] # example 1: Human hemoglobin, genome\n",
    "enrichment_method = \"genome\" # \"characterize_foreground\" \"abundance_correction\" \"compare_samples\" \"genome\" \"compare_groups\"\n",
    "from_file = False\n",
    "args_dict = {}\n",
    "args_dict[\"enrichment_method\"] = enrichment_method\n",
    "args_dict[\"taxid\"] = 9606\n",
    "args_dict[\"FDR_cutoff\"] = 0.05\n",
    "args_dict[\"p_value_cutoff\"] = 0.01\n",
    "args_dict[\"limit_2_entity_type\"] = \"-20;-25;-26\" #\"-20;-25;-21\" # \"-20;-21;-22;-23;-25;-26\" # None #\"-21;-22;-23\"\n",
    "args_dict[\"filter_PMID_top_n\"] = 50\n",
    "args_dict[\"filter_foreground_count_one\"] = True\n",
    "args_dict[\"filter_parents\"] = True\n",
    "args_dict[\"go_slim_subset\"] = None # \"generic\"\n",
    "args_dict[\"o_or_u_or_both\"] = \"overrepresented\" # \"both\" \"underrepresented\"\n",
    "args_dict[\"multiple_testing_per_etype\"] = True\n",
    "args_dict[\"privileged\"] = True\n",
    "args_dict[\"score_cutoff\"] = 0\n",
    "args_dict[\"foreground_replicates\"] = 10\n",
    "args_dict[\"background_replicates\"] = 10\n",
    "taxid = args_dict[\"taxid\"]\n",
    "background_input = query.get_proteins_of_taxid(taxid, read_from_flat_files=True)\n",
    "if from_file:\n",
    "    ui = userinput.Userinput(pqo, fn_userinput, args_dict=args_dict)\n",
    "else:\n",
    "    ui = userinput.Userinput(pqo, fn=None, foreground_string=userinput.stringify_for_Userinput(foreground_input), background_string=userinput.stringify_for_Userinput(background_input), args_dict=args_dict)\n",
    "ncbi = pqo.ncbi\n",
    "preloaded_objects_per_analysis = pqo.get_preloaded_objects_per_analysis()\n",
    "foreground_n, background_n, funcEnum_2_scores_dict_fg, funcEnum_2_scores_dict_bg, p_values, cond_multitest, effectSizes, p_value_cutoff, funcEnum_count_foreground, funcEnum_count_background, over_under_int_arr, o_or_u_or_both_encoding = run_enrichment_cy(ncbi, ui, preloaded_objects_per_analysis, static_preloaded_objects, low_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import distributions\n",
    "def ks_2samp_dbl(data1, data2):\n",
    "    data1 = np.sort(data1)\n",
    "    data2 = np.sort(data2)\n",
    "    data1 = np.array(data1)\n",
    "    data2 = np.array(data2)\n",
    "    n1 = data1.shape[0]\n",
    "    n2 = data2.shape[0]\n",
    "    data_all = np.concatenate([data1, data2])\n",
    "    cdf1 = np.searchsorted(data1, data_all, side='right') / n1\n",
    "    cdf2 = np.searchsorted(data2, data_all, side='right') / n2\n",
    "    d = np.max(np.absolute(cdf1 - cdf2))\n",
    "    # Note: d absolute not signed distance\n",
    "    en = np.sqrt(n1 * n2 / (n1 + n2))\n",
    "    try:\n",
    "        prob = distributions.kstwobign.sf((en + 0.12 + 0.11 / en) * d)\n",
    "    # except Exception:\n",
    "        # warnings.warn('This should not happen! Please open an issue at '\n",
    "        #             'https://github.com/scipy/scipy/issues and provide the code '\n",
    "        #            'you used to trigger this warning.\\n')\n",
    "        # prob = 1.0\n",
    "    except:\n",
    "        print(\"This shouldn't happen\")\n",
    "        raise StopIteration\n",
    "\n",
    "    # return Ks_2sampResult(d, prob)\n",
    "    return d, prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### fill with zeros for proper calculation and performance evaluation\n",
    "funcEnum = 68613\n",
    "scores_fg = funcEnum_2_scores_dict_fg[funcEnum]\n",
    "scores_bg = funcEnum_2_scores_dict_bg[funcEnum]\n",
    "scores_bg = list(scores_bg) # for genome method --> not the place to do this        \n",
    "len_scores_fg = len(scores_fg)\n",
    "number_of_zeros_2_fill = foreground_n - len_scores_fg\n",
    "if number_of_zeros_2_fill > 0:\n",
    "    scores_fg = [0]*number_of_zeros_2_fill + scores_fg\n",
    "len_scores_bg = len(scores_bg)\n",
    "number_of_zeros_2_fill = background_n - len_scores_bg\n",
    "if number_of_zeros_2_fill > 0:\n",
    "    scores_bg = [0]*number_of_zeros_2_fill + scores_bg    \n",
    "data1, data2 = scores_fg, scores_bg\n",
    "\n",
    "d_dbl, prob_dbl = ks_2samp_dbl(data1, data2)\n",
    "d, prob = stats.ks_2samp(data1, data2, alternative=\"two-sided\", mode=\"asymp\")\n",
    "print(d_dbl, prob_dbl)\n",
    "assert d_dbl == d\n",
    "# assert prob_dbl == prob\n",
    "prob_dbl == prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_of_floats_2_R_style(vals, max_num_vals_per_line=100):\n",
    "    vals = [str(ele) for ele in vals]\n",
    "    string_2_return = \"<-c(\"\n",
    "    while len(vals) > 0:\n",
    "        string_2_return += \"{},\\n\".format(\", \".join(vals[:max_num_vals_per_line]))\n",
    "        vals = vals[max_num_vals_per_line:]\n",
    "    return string_2_return[:-2] + \")\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformation_to_randomize_sort_order(fg, bg):\n",
    "    # value = value * ((double) 1.0 + ((double) rand()) / (((double) RAND_MAX) * (double) 1000.0)); // transformation of fold_change values in order to randomize sort order in case of ties\n",
    "    np.random.seed(12345)\n",
    "#     fg = [value * (1.0 + np.random.randint(0, 2147483647) / (2147483647.0 * 1000.0)) for value in fg]\n",
    "    # bg = [value * (1.0 + np.random.randint(0, 2147483647) / (2147483647.0 * 1000.0)) for value in bg]\n",
    "    fg = [value + np.random.randint(0, 2147483647) / (2147483647.0 * 1000.0) for value in fg]\n",
    "    bg = [value + np.random.randint(0, 2147483647) / (2147483647.0 * 1000.0) for value in bg]\n",
    "    return fg, bg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "funcEnum = 68613\n",
    "scores_fg = funcEnum_2_scores_dict_fg[funcEnum]\n",
    "scores_bg = funcEnum_2_scores_dict_bg[funcEnum]\n",
    "print(stats.ks_2samp(scores_fg, scores_bg, alternative=\"two-sided\", mode=\"exact\"))\n",
    "scores_fg, scores_bg = transformation_to_randomize_sort_order(scores_fg, scores_bg)\n",
    "print(stats.ks_2samp(scores_fg, scores_bg, alternative=\"two-sided\", mode=\"exact\"))\n",
    "print(stats.ks_2samp(data1, data2, alternative=\"two-sided\", mode=\"exact\"))\n",
    "data1, data2 = transformation_to_randomize_sort_order(data1, data2)\n",
    "print(stats.ks_2samp(data1, data2, alternative=\"two-sided\", mode=\"exact\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "dfx = pd.DataFrame()\n",
    "dfx[\"bg\"] = pd.Series(scores_bg)\n",
    "dfx[\"bg\"].hist(cumulative=True, density=1, bins=100, alpha=0.2)\n",
    "dfx[\"fg\"] = pd.Series(scores_fg)\n",
    "dfx[\"fg\"].hist(cumulative=True, density=1, bins=100, alpha=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fg_and_bg_2_DF_melt_and_add_ranks(fg, bg):\n",
    "    dfx = pd.DataFrame()\n",
    "    dfx[\"bg\"] = pd.Series(bg)\n",
    "    dfx[\"fg\"] = pd.Series(fg)\n",
    "    # transform dataframe to long format\n",
    "    dfxm = dfx.melt(value_vars=[\"fg\", \"bg\"], var_name=\"FG_BG\", value_name=\"score\")\n",
    "    dfxm = dfxm[dfxm[\"score\"].notnull()]\n",
    "    dfxm = dfxm.sort_values([\"score\", \"FG_BG\"], ascending=[True, False]).reset_index(drop=True)\n",
    "    dfxm[\"rank\"] = dfxm[\"score\"].rank(method=\"first\")\n",
    "    return dfxm\n",
    "# scores_fg = funcEnum_2_scores_dict_fg[funcEnum]\n",
    "# scores_bg = funcEnum_2_scores_dict_bg[funcEnum]\n",
    "# dfxm = fg_and_bg_2_DF_melt_and_add_ranks(scores_fg, scores_bg)\n",
    "# print(stats.ks_2samp(scores_fg, scores_bg, alternative=\"two-sided\", mode=\"exact\"))\n",
    "# stats.ks_2samp(dfxm.loc[dfxm[\"FG_BG\"] == \"fg\", \"score\"].to_list(), dfxm.loc[dfxm[\"FG_BG\"] == \"bg\", \"score\"].to_list(), alternative=\"two-sided\", mode=\"exact\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores_fg = funcEnum_2_scores_dict_fg[funcEnum]\n",
    "# sorted(scores_fg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Print profiling statistics using the `line_profiler` API\n",
    "### 'run_cythonized.run_genome_cy(taxid, protein_ans, background_n, preloaded_objects_per_analysis, static_preloaded_objects, args_dict, low_memory=False)'\n",
    "profile = line_profiler.LineProfiler(run_genome_cy)\n",
    "profile.runcall(run_genome_cy, taxid, protein_ans, background_n, preloaded_objects_per_analysis, static_preloaded_objects, args_dict, low_memory=False)\n",
    "profile.print_stats()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python agotool2",
   "language": "python",
   "name": "agotool2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "182px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
