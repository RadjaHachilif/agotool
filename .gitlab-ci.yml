stages:
  - build_monthly
  - test
  - deploy

variables:
  PYTHON: "/home/gitlab-runner/anaconda3/envs/snake/bin/python"
  SNAKEMAKE: "/home/gitlab-runner/anaconda3/envs/snake/bin/snakemake"
  

before_script:
    - export DATE=$(date +"%Y_%m_%d_%I_%M_%p")
    - export TAR_FILE_NAME='bak_aGOtool_flatfiles_$DATE.tar'
    - echo $TAR_FILE_NAME

initial_testing:
  stage: test
  tags:
    - aquarius
  script:
    - echo "$(date)"
    - $PYTHON -V
    - $SNAKEMAKE --version
    - echo "$USER"
    - echo $HOSTNAME
    - echo $DATE
    - echo $TAR_FILE_NAME
    - echo "bak_aGOtool_flatfiles_$DATE.tar"

job:on-schedule:
  only:
    - schedules
  stage: build_monthly
  tags:
    - aquarius
  script:
    - echo "$(date)"
    # - $PYTHON -c "print('scheduled pipeline job here. Let's get this done!')"


#     ### tar and compress previous files for backup
# echo "\n### tar and compress previous files for backup\n"
# TAR_FILE_NAME=bak_aGOtool_flatfiles_$(date +"%Y_%m_%d_%I_%M_%p").tar
# cd /mnt/mnemo5/dblyon/agotool/data/PostgreSQL/tables
# ### create tar of relevant flat files

# find . -maxdepth 1 -name '*.npy' -o -name '*_UPS_FIN*' | xargs tar cvf $TAR_FILE_NAME
# check_exit_status
# ### compress for quick transfer and backup, this can run in the background since it's independent of snakemake
# pbzip2 -p10 $TAR_FILE_NAME &
# check_exit_status

# ### run snakemake pipeline
# echo "\n### run snakemake pipeline\n"
# cd /mnt/mnemo5/dblyon/agotool/app/python
# /mnt/mnemo5/dblyon/install/anaconda3/envs/snake/bin/snakemake -l | tr '\n' ' ' | xargs /mnt/mnemo5/dblyon/install/anaconda3/envs/snake/bin/snakemake -j 10 -F
# check_exit_status
  
